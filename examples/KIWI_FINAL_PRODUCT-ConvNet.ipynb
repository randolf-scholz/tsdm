{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc22d517-c76d-4da2-ac57-ab077be3396f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InteractiveShell.ast_node_interactivity='last_expr_or_assign'  # always print last expr.\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "from time import perf_counter, time\n",
    "from typing import Any, NamedTuple\n",
    "\n",
    "# enable JIT compilation - must be done before loading torch!\n",
    "os.environ[\"PYTORCH_JIT\"] = \"1\"\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "# logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "880c03d7-324c-4bc8-ae50-5392d4ff4642",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchinfo\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "TARGET = \"Fluo_GFP\"\n",
    "SPLIT = 0\n",
    "\n",
    "RUN_NAME = f\"{TARGET}-{SPLIT}-More_params\"  # | input(\"enter name for run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20e1c36b-b316-486d-bf09-724a98b0f477",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from abc import ABC, abstractmethod\n",
    "from collections import defaultdict, namedtuple\n",
    "from collections.abc import Callable, Collection, Hashable, Iterable, Mapping, Sequence\n",
    "from functools import singledispatchmethod\n",
    "from typing import Any, Final, Generic, Literal, Optional, Union, overload\n",
    "from torch import jit\n",
    "\n",
    "from torchinfo import summary\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas.api.types\n",
    "import torch\n",
    "from numpy.typing import NDArray\n",
    "from pandas import (\n",
    "    NA,\n",
    "    DataFrame,\n",
    "    DatetimeIndex,\n",
    "    Index,\n",
    "    MultiIndex,\n",
    "    Series,\n",
    "    Timedelta,\n",
    "    Timestamp,\n",
    ")\n",
    "from pandas.core.indexes.frozen import FrozenList\n",
    "from torch import Tensor, nn\n",
    "\n",
    "from tsdm.datasets import KIWI_RUNS, TimeTensor\n",
    "from tsdm.encoders.modular import *\n",
    "from tsdm.encoders.modular import BaseEncoder\n",
    "from tsdm.tasks import KIWI_FINAL_PRODUCT\n",
    "from tsdm.util.types import PathType\n",
    "from tsdm.util.types.abc import HashableType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "464673c5-e855-4a21-b089-eb02aa58c584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable benchmarking for variable sized input\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75c73e6-8f71-4570-ae16-0f01889052b3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Initialize Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0cfe050-72d6-46c0-b062-e1dbf7ebc93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DTYPE = torch.float32\n",
    "\n",
    "task = KIWI_FINAL_PRODUCT(\n",
    "    train_batch_size=BATCH_SIZE,\n",
    "    eval_batch_size=2048,\n",
    "    target=TARGET,\n",
    ")\n",
    "\n",
    "DATASET = task.dataset\n",
    "ts = task.timeseries\n",
    "md = task.metadata\n",
    "NUM_PTS, NUM_DIM = ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18b50197-2d48-4bd7-8369-049e6daaa781",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts, md = task.splits[SPLIT, \"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d800fc2-1c80-4193-881e-eb94c1875d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = KIWI_FINAL_PRODUCT()\n",
    "ts = task.timeseries.sort_index(axis=\"index\").sort_index(axis=\"columns\")\n",
    "channel_freq = pd.notna(ts).mean().sort_values()\n",
    "fast_channels = FrozenList(channel_freq[channel_freq >= 0.1].index)\n",
    "slow_channels = FrozenList(channel_freq[channel_freq < 0.1].index)\n",
    "FAST = ts[fast_channels].dropna(how=\"all\")\n",
    "SLOW = ts[slow_channels].dropna(how=\"all\")\n",
    "groups = {\"slow\": slow_channels, \"fast\": fast_channels}\n",
    "FAST_DIM = len(fast_channels)\n",
    "SLOW_DIM = len(slow_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b13c4151-e995-4b1e-8d71-4237969d8a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ts.loc[510, 16871]\n",
    "encoder = ChainedEncoder(\n",
    "    TensorEncoder(),\n",
    "    ValueEncoder(\"float32\") | ValueEncoder(\"float32\"),\n",
    "    TripletEncoder() | TripletEncoder(),\n",
    "    FrameSplitter(groups, dropna=True),\n",
    "    FrameEncoder(\n",
    "        Standardizer(),\n",
    "        index_encoders={\n",
    "            \"measurement_time\": MinMaxScaler() @ TimeDeltaEncoder(unit=\"s\")\n",
    "        },\n",
    "    ),\n",
    ")\n",
    "encoder.fit(ts.reset_index([0, 1], drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ed6eaec-73a8-45a6-ac47-61c69d7dad09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e689d15e-3c91-40cf-a18c-b4d973a97cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Conv1d\n",
    "from tsdm.models.generic.conv1d import ConvBlock\n",
    "from tsdm.models.generic.rezero import ReZero\n",
    "from tsdm.models import GroupedSetFuncTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7194fbb7-36c1-4108-978a-5169922aaa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsdm.models import MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "650ee3a6-80e5-40db-8742-b8f4bdfc14c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_encoder = MLP(SLOW_DIM + 2, 32)\n",
    "\n",
    "x = encoded[0]\n",
    "\n",
    "slow_encoder(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4094aab7-d3bf-4e5d-993c-c675eea9d653",
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_encoder = nn.Sequential(\n",
    "    nn.Conv1d(\n",
    "        FAST_DIM + 2, 32, kernel_size=8, padding=\"same\", padding_mode=\"replicate\"\n",
    "    ),\n",
    "    ReZero(ConvBlock(32), ConvBlock(32), ConvBlock(32)),\n",
    "    nn.AvgPool1d(16),\n",
    ")\n",
    "\n",
    "x = encoded[1].T.unsqueeze(0)  # N × Cin × L\n",
    "\n",
    "x = fast_encoder(x)\n",
    "\n",
    "x = x.squeeze(0).T\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2bb71808-7a16-4822-9a0c-04e647809f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "torchinfo.summary(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c4330224-f60a-489b-bd15-81ff97fffcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_encoder = MLP(SLOW_DIM + 2 + 8, 32)\n",
    "\n",
    "fast_encoder = nn.Sequential(\n",
    "    nn.Conv1d(\n",
    "        FAST_DIM + 2+ 8, 32, kernel_size=8, padding=\"same\", padding_mode=\"replicate\"\n",
    "    ),\n",
    "    ReZero(ConvBlock(32), ConvBlock(32), ConvBlock(32)),\n",
    "    nn.AvgPool1d(16),\n",
    ")\n",
    "\n",
    "model = GroupedSetFuncTS(\n",
    "    25,\n",
    "    1,\n",
    "    fast_encoder=fast_encoder,\n",
    "    slow_encoder=slow_encoder,\n",
    "    latent_size=256,\n",
    "    dim_keys=128,\n",
    "    dim_vals=128,\n",
    "    dim_deepset=128,\n",
    "    dim_time=8,\n",
    ")\n",
    "model.to(device=DEVICE, dtype=DTYPE)\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "327ffac3-9ad8-4d56-a545-9589078af079",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(encoded[0], encoded[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc445848-2fa8-437f-a659-4ced12d6a637",
   "metadata": {},
   "source": [
    "## Initialize Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8dd0b432-67ee-4e0b-ab5c-ef0dbd3eaa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = ChainedEncoder(\n",
    "    TensorEncoder(),\n",
    "    ValueEncoder(\"float32\") | ValueEncoder(\"float32\"),\n",
    "    TripletEncoder() | TripletEncoder(),\n",
    "    FrameSplitter(groups, dropna=True),\n",
    "    FrameEncoder(\n",
    "        index_encoders={\n",
    "            \"measurement_time\": MinMaxScaler() @ TimeDeltaEncoder(unit=\"s\")\n",
    "        },\n",
    "    ),\n",
    "    Standardizer(),\n",
    ")\n",
    "encoder.fit(ts.reset_index([0, 1], drop=True))\n",
    "task.target_idx = task.timeseries.columns.get_loc(task.target)\n",
    "target_encoder = TensorEncoder() @ FloatEncoder() @ encoder[-1][task.target_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b5e60a-4bc6-4671-9872-82ff8d437619",
   "metadata": {},
   "source": [
    "## Define Batching Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88eccd0c-6f15-4f18-8d5a-0300b2216be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batch(NamedTuple):\n",
    "    index: Tensor\n",
    "    timeseries: Tensor\n",
    "    metadata: Tensor\n",
    "    targets: Tensor\n",
    "    encoded_targets: Tensor\n",
    "\n",
    "    def __repr__(self):\n",
    "        return repr_mapping(\n",
    "            self._asdict(), title=self.__class__.__name__, repr_fun=repr_array\n",
    "        )\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def mycollate(batch: list):\n",
    "    index = []\n",
    "    timeseries = []\n",
    "    metadata = []\n",
    "    targets = []\n",
    "    encoded_targets = []\n",
    "\n",
    "    for idx, (ts_data, (md_data, target)) in batch:\n",
    "        index.append(torch.tensor(idx[0]))\n",
    "        timeseries.append(encoder.encode(ts_data))\n",
    "        metadata.append(md_data)\n",
    "        targets.append(target)\n",
    "        encoded_targets.append(target_encoder.encode(target))\n",
    "\n",
    "    index = torch.stack(index)\n",
    "    targets = pandas.concat(targets)\n",
    "    encoded_targets = torch.concat(encoded_targets)\n",
    "\n",
    "    return Batch(index, timeseries, metadata, targets, encoded_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7ad313-0bca-47ae-a23d-05c1430fb739",
   "metadata": {},
   "source": [
    "## Initialize Loss & Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c89a3b59-6ef4-4b41-b53e-9b23ef5bbafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOSS = task.test_metric.to(device=DEVICE)\n",
    "metrics = {key: jit.script(LOSSES[key]()) for key in (\"RMSE\", \"MSE\", \"MAE\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfde25ec-dea8-462e-9164-45dff7fd7859",
   "metadata": {},
   "source": [
    "## Initialize DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f62fa2-dc36-455e-91cf-6b46b8b0e6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINLOADER = task.get_dataloader(\n",
    "    (SPLIT, \"train\"),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=mycollate,\n",
    "    pin_memory=True,\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    # num_workers=6,\n",
    "    num_workers=os.cpu_count() // 4,\n",
    "    persistent_workers=True,\n",
    ")\n",
    "\n",
    "\n",
    "EVALLOADER = task.get_dataloader(\n",
    "    (SPLIT, \"train\"),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=mycollate,\n",
    "    pin_memory=True,\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    # num_workers=6,\n",
    "    num_workers=os.cpu_count() // 4,\n",
    "    persistent_workers=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1996de-7202-46f1-8c42-70d7622db779",
   "metadata": {},
   "source": [
    "## Hyperparamters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeaef85b-c8a3-4cb5-a6ad-bf6312f6f6e8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "OPTIMIZER_CONFIG = {\n",
    "    \"__name__\": \"AdamW\",\n",
    "    \"lr\": 0.001,\n",
    "    \"betas\": (0.9, 0.999),\n",
    "    \"eps\": 1e-08,\n",
    "    \"weight_decay\": 0.001,\n",
    "    \"amsgrad\": False,\n",
    "}\n",
    "\n",
    "LR_SCHEDULER_CONFIG = {\n",
    "    \"__name__\": \"ReduceLROnPlateau\",\n",
    "    \"mode\": \"min\",\n",
    "    # (str) – One of min, max. In min mode, lr will be reduced when the quantity monitored has stopped decreasing; in max mode it will be reduced when the quantity monitored has stopped increasing. Default: ‘min’.\n",
    "    \"factor\": 0.1,\n",
    "    # (float) – Factor by which the learning rate will be reduced. new_lr = lr * factor. Default: 0.1.\n",
    "    \"patience\": 10,\n",
    "    # (int) – Number of epochs with no improvement after which learning rate will be reduced. For example, if patience = 2, then we will ignore the first 2 epochs with no improvement, and will only decrease the LR after the 3rd epoch if the loss still hasn’t improved then. Default: 10.\n",
    "    \"threshold\": 0.0001,\n",
    "    # (float) – Threshold for measuring the new optimum, to only focus on significant changes. Default: 1e-4.\n",
    "    \"threshold_mode\": \"rel\",\n",
    "    # (str) – One of rel, abs. In rel mode, dynamic_threshold = best * ( 1 + threshold ) in ‘max’ mode or best * ( 1 - threshold ) in min mode. In abs mode, dynamic_threshold = best + threshold in max mode or best - threshold in min mode. Default: ‘rel’.\n",
    "    \"cooldown\": 0,\n",
    "    # (int) – Number of epochs to wait before resuming normal operation after lr has been reduced. Default: 0.\n",
    "    \"min_lr\": 1e-08,\n",
    "    # (float or list) – A scalar or a list of scalars. A lower bound on the learning rate of all param groups or each group respectively. Default: 0.\n",
    "    \"eps\": 1e-08,\n",
    "    # (float) – Minimal decay applied to lr. If the difference between new and old lr is smaller than eps, the update is ignored. Default: 1e-8.\n",
    "    \"verbose\": True\n",
    "    # (bool) – If True, prints a message to stdout for each update. Default: False.\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c913f4-ea56-4e3c-ae29-2bf615e3464c",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba10ccb-933b-431a-98a2-0ab0dcc36170",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsdm.models import SetFuncTS\n",
    "\n",
    "MODEL = SetFuncTS\n",
    "model = MODEL(17, 1, latent_size=256, dim_keys=128, dim_vals=128, dim_deepset=128)\n",
    "model.to(device=DEVICE, dtype=DTYPE)\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844d9c1c-4c7c-419b-9dd4-d1ef6fce83fa",
   "metadata": {},
   "source": [
    "### Warmup - test forward / backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0824374-d35f-48b7-b023-667d89627610",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(TRAINLOADER))\n",
    "y = model.forward_batch(batch.timeseries)\n",
    "torch.linalg.norm(y).backward()\n",
    "model.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83e71ba-af79-4c01-a587-3785154e4036",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Initalize Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c34d87a-a015-46c7-8448-19731bbf7d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsdm.optimizers import LR_SCHEDULERS, OPTIMIZERS\n",
    "from tsdm.util import initialize_from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbabd0e-473c-4900-ae00-1819f116c96a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "OPTIMIZER_CONFIG |= {\"params\": model.parameters()}\n",
    "optimizer = initialize_from(OPTIMIZERS, **OPTIMIZER_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2613d2-d67a-4c2f-964d-244209514118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_scheduler = initialize_from(\n",
    "#     LR_SCHEDULERS, LR_SCHEDULER_CONFIG | {\"optimizer\": optimizer}\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5892b9-c3ad-4b3b-992e-e082b600227c",
   "metadata": {},
   "source": [
    "## Logging Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2919d5f-1d1f-4147-aacf-3e50d09230ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsdm.logutils import compute_metrics\n",
    "\n",
    "# def log_all(i, model, writer, optimizer):\n",
    "#     kernel = model.system.kernel.clone().detach().cpu()\n",
    "#     log_kernel_information(i, writer, kernel, histograms=True)\n",
    "#     log_optimizer_state(i, writer, optimizer, histograms=True)\n",
    "\n",
    "\n",
    "def log_hparams(i, writer, *, metric_dict, hparam_dict):\n",
    "    hparam_dict |= {\"epoch\": i}\n",
    "    metric_dict = add_prefix(metric_dict, \"hparam\")\n",
    "    writer.add_hparams(hparam_dict=hparam_dict, metric_dict=metric_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d902635f-ae08-43aa-b60b-d21805d83f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_START = tsdm.util.now()\n",
    "CHECKPOINTDIR = Path(\n",
    "    f\"checkpoints/{MODEL.__name__}/{DATASET.name}/{RUN_NAME}/{RUN_START}\"\n",
    ")\n",
    "CHECKPOINTDIR.mkdir(parents=True, exist_ok=True)\n",
    "LOGGING_DIR = f\"runs/{MODEL.__name__}/{DATASET.name}/{RUN_NAME}/{RUN_START}\"\n",
    "writer = SummaryWriter(LOGGING_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62361bf2-16b2-46b0-bc69-71bee7045422",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63df8057-0535-4479-957e-79f45b4840c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_all_predictions(model, dataloader):\n",
    "    ys = []\n",
    "    yhats = []\n",
    "    for batch in tqdm(dataloader, leave=False):\n",
    "        # ts = batch.timeseries\n",
    "        # inputs = [(t.to(device=DEVICE),v.to(device=DEVICE), m.to(device=DEVICE)) for t,v,m in ts]\n",
    "        # yhats.append(model.batch_forward(inputs))\n",
    "        yhats.append(model.forward_batch(batch.timeseries))\n",
    "        ys.append(batch.encoded_targets.to(device=DEVICE))\n",
    "    y = torch.cat(ys)\n",
    "    yhat = torch.cat(yhats)\n",
    "    y = torch.tensor(target_encoder.decode(y))\n",
    "    yhat = torch.tensor(target_encoder.decode(yhat))\n",
    "    return y, yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f8e9b5-c185-4ee6-8192-6a27c9a30708",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "i = -1\n",
    "epoch = 1\n",
    "\n",
    "with torch.no_grad():\n",
    "    for key, dloader in {\"train\": TRAINLOADER, \"test\": EVALLOADER}.items():\n",
    "        y, ŷ = get_all_predictions(model, dloader)\n",
    "        assert torch.isfinite(y).all()\n",
    "        log_metrics(epoch, writer, metrics=metrics, targets=y, predics=ŷ, prefix=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a639555f-58dd-4830-b0a7-0f20e0c565a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in optimizer.param_groups:\n",
    "    g[\"lr\"] = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e9b5c3-8da4-4e5b-b4a5-f0dfac9ff450",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for epoch in (epochs := range(epoch, epoch + 1000)):\n",
    "    batching_time = perf_counter()\n",
    "    for batch in (batches := tqdm(TRAINLOADER, leave=False)):\n",
    "        batching_time = perf_counter() - batching_time\n",
    "        i += 1\n",
    "        # Optimization step\n",
    "        model.zero_grad(set_to_none=True)\n",
    "        targets = batch.encoded_targets.to(device=DEVICE)\n",
    "\n",
    "        # forward\n",
    "        forward_time = perf_counter()\n",
    "        predics = model.forward_batch(batch.timeseries)\n",
    "        loss = LOSS(targets, predics)\n",
    "        forward_time = perf_counter() - forward_time\n",
    "\n",
    "        # backward\n",
    "        backward_time = perf_counter()\n",
    "        loss.backward()\n",
    "        backward_time = perf_counter() - backward_time\n",
    "\n",
    "        # step\n",
    "        optimizer.step()\n",
    "\n",
    "        # batch logging\n",
    "        with torch.no_grad():\n",
    "            logging_time = time()\n",
    "            if torch.any(~torch.isfinite(loss)):\n",
    "                raise RuntimeError(\"NaN/INF-value encountered!!\")\n",
    "\n",
    "            log_metrics(\n",
    "                i,\n",
    "                writer,\n",
    "                metrics=metrics,\n",
    "                targets=targets.clone(),\n",
    "                predics=predics.clone(),\n",
    "                prefix=\"batch\",\n",
    "            )\n",
    "            log_optimizer_state(i, writer, optimizer, prefix=\"batch\")\n",
    "\n",
    "            # lval = loss.clone().detach().cpu().numpy()\n",
    "            # gval = grad_norm(list(model.parameters())).clone().detach().cpu().numpy()\n",
    "            logging_time = time() - logging_time\n",
    "\n",
    "        batches.set_postfix(\n",
    "            # loss=f\"{lval:.2e}\",\n",
    "            # gnorm=f\"{gval:.2e}\",\n",
    "            epoch=epoch,\n",
    "            Δt_forward=f\"{forward_time:.1f}\",\n",
    "            Δt_backward=f\"{backward_time:.1f}\",\n",
    "            Δt_logging=f\"{logging_time:.1f}\",\n",
    "            Δt_batching=f\"{batching_time:.1f}\",\n",
    "        )\n",
    "        batching_time = perf_counter()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # end-of-epoch logging\n",
    "        for key, dloader in {\"train\": TRAINLOADER, \"test\": EVALLOADER}.items():\n",
    "            y, ŷ = get_all_predictions(model, dloader)\n",
    "            assert torch.isfinite(y).all()\n",
    "            log_metrics(\n",
    "                epoch, writer, metrics=metrics, targets=y, predics=ŷ, prefix=key\n",
    "            )\n",
    "\n",
    "        # Model Checkpoint\n",
    "        torch.jit.save(model, CHECKPOINTDIR.joinpath(f\"{MODEL.__name__}-{epoch}\"))\n",
    "        torch.save(\n",
    "            {\n",
    "                \"optimizer\": optimizer,\n",
    "                \"epoch\": epoch,\n",
    "                \"batch\": i,\n",
    "            },\n",
    "            CHECKPOINTDIR.joinpath(f\"{optimizer.__class__.__name__}-{epoch}\"),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce010b67-97ab-4e30-8fab-31340163fe6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise StopIteration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605bef8a-a964-4dbe-b071-2e3e468b28c6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Post Training Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea7e528-85a7-416e-b7b9-5a7e979ab466",
   "metadata": {},
   "source": [
    "# Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ecaa8f-b919-4ff9-8373-5ac01694cbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.profiler import ProfilerActivity, profile, record_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c844c142-b28d-49eb-8271-9892968ce862",
   "metadata": {},
   "outputs": [],
   "source": [
    "with profile(\n",
    "    activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
    "    record_shapes=True,\n",
    "    profile_memory=True,\n",
    ") as prof:\n",
    "    model(times, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe31e70-550f-4cfd-b73e-3a026786a390",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa42321-19e6-4e2e-9722-02abfe93519e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001aa24d-ed1c-4af8-b50a-c9b94b14bcad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

r"""Implementations of loss functions.

Notes
-----
Contains losses in functional form.
  - See `tsdm.losses` for modular implementations.
"""

__all__ = [
    # Callback Protocol
    "Metric",
    # Functions
    "nd",
    "nrmse",
    "rmse",
    "q_quantile",
    "q_quantile_loss",
]


import torch
from torch import Tensor, jit
from typing_extensions import Protocol, runtime_checkable


@runtime_checkable
class Metric(Protocol):
    """Represents a metric."""

    def __call__(self, targets: Tensor, predictions: Tensor, /) -> Tensor:
        """Compute the loss."""
        ...


@jit.script
def nd(x: Tensor, xhat: Tensor, eps: float = 2**-24) -> Tensor:
    r"""Compute the normalized deviation score.

    .. math:: ğ–­ğ–£(xï¼ŒxÌ‚) â‰” \frac{âˆ‘_{tk} |xÌ‚_{tk} - x_{tk}|}{âˆ‘_{tk} |x_{tk}|}

    TODO: How to distinguish batch univariate vs single multivariate?
    => Batch makes little sense since all could have different length!

    References:
        - | Temporal Regularized Matrix Factorization for High-dimensional Time Series Prediction
          | Hsiang-Fu Yu, Nikhil Rao, Inderjit S. Dhillon
          | Advances in Neural Information Processing Systems 29 (NIPS 2016)
          | https://papers.nips.cc/paper/2016/hash/85422afb467e9456013a2a51d4dff702-Abstract.html
        - | N-BEATS: Neural basis expansion analysis for interpretable time series forecasting
          | https://openreview.net/forum?id=r1ecqn4YwB
    """
    res = torch.sum(torch.abs(xhat - x), dim=(-2, -1))
    mag = torch.sum(torch.abs(x), dim=(-2, -1))
    mag = torch.maximum(mag, torch.tensor(eps, dtype=x.dtype, device=x.device))
    return torch.mean(res / mag)  # get rid of any batch dimensions


@jit.script
def nrmse(x: Tensor, xhat: Tensor, eps: float = 2**-24) -> Tensor:
    r"""Compute the normalized deviation score.

    .. math:: ğ–­ğ–±ğ–¬ğ–²ğ–¤(xï¼ŒxÌ‚) â‰” \frac{\sqrt{\frac{1}{T}âˆ‘_{tk}|xÌ‚_{tk} - x_{tk}|^2}}{âˆ‘_{tk}|x_{tk}|}

    References:
        - | Temporal Regularized Matrix Factorization for High-dimensional Time Series Prediction
          | Hsiang-Fu Yu, Nikhil Rao, Inderjit S. Dhillon
          | Advances in Neural Information Processing Systems 29 (NIPS 2016)
          | https://papers.nips.cc/paper/2016/hash/85422afb467e9456013a2a51d4dff702-Abstract.html
    """
    res = torch.sqrt(torch.sum(torch.abs(xhat - x) ** 2, dim=(-2, -1)))
    mag = torch.sum(torch.abs(x), dim=(-2, -1))
    mag = torch.maximum(mag, torch.tensor(eps, dtype=x.dtype, device=x.device))
    return torch.mean(res / mag)  # get rid of any batch dimensions


@jit.script
def q_quantile(x: Tensor, xhat: Tensor, q: float = 0.5) -> Tensor:
    r"""Return the q-quantile.

    .. math:: ğ–¯_q(xï¼ŒxÌ‚) â‰” \begin{cases}\hfill qâ‹…|x-xÌ‚|:& xâ‰¥xÌ‚ \\ (1-q)â‹…|x-xÌ‚|:& xâ‰¤xÌ‚ \end{cases}

    References:
        - | Deep State Space Models for Time Series Forecasting
          | Syama Sundar Rangapuram, Matthias W. Seeger, Jan Gasthaus, Lorenzo Stella, Yuyang Wang,
            Tim Januschowski
          | Advances in Neural Information Processing Systems 31 (NeurIPS 2018)
          | https://papers.nips.cc/paper/2018/hash/5cf68969fb67aa6082363a6d4e6468e2-Abstract.html
    """
    residual = x - xhat
    return torch.max((q - 1) * residual, q * residual)  # simplified formula


@jit.script
def q_quantile_loss(x: Tensor, xhat: Tensor, q: float = 0.5) -> Tensor:
    r"""Return the q-quantile loss.

    .. math:: ğ–°ğ–«_q(xï¼ŒxÌ‚) â‰” 2\frac{âˆ‘_{tk}ğ–¯_q(x_{tk}ï¼ŒxÌ‚_{tk})}{âˆ‘_{tk}|x_{tk}|}

    References:
        - | Deep State Space Models for Time Series Forecasting
          | Syama Sundar Rangapuram, Matthias W. Seeger, Jan Gasthaus, Lorenzo Stella, Yuyang Wang,
            Tim Januschowski
          | Advances in Neural Information Processing Systems 31 (NeurIPS 2018)
          | https://papers.nips.cc/paper/2018/hash/5cf68969fb67aa6082363a6d4e6468e2-Abstract.html
    """
    return 2 * torch.sum(q_quantile(x, xhat, q)) / torch.sum(torch.abs(x))


@jit.script
def rmse(x: Tensor, xhat: Tensor) -> Tensor:
    r"""Compute the RMSE.

    .. math:: ğ—‹ğ—†ğ—Œğ–¾(xï¼ŒxÌ‚) â‰” \sqrt{ğ”¼[â€–x - xÌ‚â€–^2]}
    """
    return torch.sqrt(torch.mean((x - xhat) ** 2))

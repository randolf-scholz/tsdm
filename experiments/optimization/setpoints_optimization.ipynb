{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20191951-beec-414a-b3c6-89dca8277ad2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T16:07:08.188967Z",
     "iopub.status.busy": "2022-11-17T16:07:08.188820Z",
     "iopub.status.idle": "2022-11-17T16:07:09.139922Z",
     "shell.execute_reply": "2022-11-17T16:07:09.139472Z",
     "shell.execute_reply.started": "2022-11-17T16:07:08.188923Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%config InteractiveShell.ast_node_interactivity='last_expr_or_assign'\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from pandas import DataFrame, Index, MultiIndex\n",
    "from torch import Tensor\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b7f6d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T16:07:09.141014Z",
     "iopub.status.busy": "2022-11-17T16:07:09.140769Z",
     "iopub.status.idle": "2022-11-17T16:07:09.793291Z",
     "shell.execute_reply": "2022-11-17T16:07:09.792721Z",
     "shell.execute_reply.started": "2022-11-17T16:07:09.141001Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tsdm.models.pretrained import LinODEnet\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "pretrained = LinODEnet(device=DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc23284-7aa7-4eaf-a390-f0b3094b83f1",
   "metadata": {},
   "source": [
    "# Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d695b42b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T16:07:09.794053Z",
     "iopub.status.busy": "2022-11-17T16:07:09.793801Z",
     "iopub.status.idle": "2022-11-17T16:07:10.943698Z",
     "shell.execute_reply": "2022-11-17T16:07:10.943185Z",
     "shell.execute_reply.started": "2022-11-17T16:07:09.794041Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = pretrained[\"model\"]\n",
    "summary(model, depth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5582e16-b07b-4271-a06d-00272e0ac33f",
   "metadata": {},
   "source": [
    "# Load the Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3394a469-5536-4368-a314-3ec62252a425",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T16:07:10.944396Z",
     "iopub.status.busy": "2022-11-17T16:07:10.944234Z",
     "iopub.status.idle": "2022-11-17T16:07:10.972946Z",
     "shell.execute_reply": "2022-11-17T16:07:10.972473Z",
     "shell.execute_reply.started": "2022-11-17T16:07:10.944385Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder = pretrained[\"encoder\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d376fc-4558-431d-8c18-7b6e15e2e2b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T16:07:10.973525Z",
     "iopub.status.busy": "2022-11-17T16:07:10.973388Z",
     "iopub.status.idle": "2022-11-17T16:07:10.999365Z",
     "shell.execute_reply": "2022-11-17T16:07:10.998948Z",
     "shell.execute_reply.started": "2022-11-17T16:07:10.973514Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "USED_COLUMNS = Index(encoder[-1].column_encoders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee48a27c-6d8f-46f3-8171-cbeca80dfafa",
   "metadata": {},
   "source": [
    "# Load the Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8936a115-0c8e-4170-97c3-8c182faa692a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T16:07:11.000076Z",
     "iopub.status.busy": "2022-11-17T16:07:10.999932Z",
     "iopub.status.idle": "2022-11-17T16:07:11.223656Z",
     "shell.execute_reply": "2022-11-17T16:07:11.223079Z",
     "shell.execute_reply.started": "2022-11-17T16:07:11.000064Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = pretrained[\"optimizer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddf97cf-f11e-485f-af68-2d1ee907ec6d",
   "metadata": {},
   "source": [
    "# Load the pickled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f438255-f022-4177-a563-954cbf021c07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T16:07:11.225927Z",
     "iopub.status.busy": "2022-11-17T16:07:11.225640Z",
     "iopub.status.idle": "2022-11-17T16:07:11.249108Z",
     "shell.execute_reply": "2022-11-17T16:07:11.248622Z",
     "shell.execute_reply.started": "2022-11-17T16:07:11.225884Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_dataframes_from_pickle(\n",
    "    filename: str,\n",
    ") -> tuple[DataFrame, DataFrame, DataFrame]:\n",
    "    with open(filename, \"rb\") as file:\n",
    "        data = pickle.load(file)\n",
    "\n",
    "    \"\"\"Returns DataFrames from pickle\"\"\"\n",
    "    timeseries_dict = {\n",
    "        key: tables[\"measurements_aggregated\"] for key, tables in data.items()\n",
    "    }\n",
    "    timeseries = pd.concat(timeseries_dict, names=[\"experiment_id\"])\n",
    "\n",
    "    metadata_dict = {\n",
    "        key: tables[\"measurements_aggregated\"] for key, tables in data.items()\n",
    "    }\n",
    "    metadata = pd.concat(metadata_dict, names=[\"experiment_id\"])\n",
    "\n",
    "    setpoints_dict = {\n",
    "        key: tables[\"measurements_aggregated\"] for key, tables in data.items()\n",
    "    }\n",
    "    setpoints = pd.concat(setpoints_dict, names=[\"experiment_id\"])\n",
    "\n",
    "    return timeseries, metadata, setpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1136313b-a4ad-4400-916f-fbb5737673e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T16:07:11.249881Z",
     "iopub.status.busy": "2022-11-17T16:07:11.249733Z",
     "iopub.status.idle": "2022-11-17T16:07:11.316815Z",
     "shell.execute_reply": "2022-11-17T16:07:11.316405Z",
     "shell.execute_reply.started": "2022-11-17T16:07:11.249869Z"
    }
   },
   "outputs": [],
   "source": [
    "TS, MD, SP = make_dataframes_from_pickle(\"example_510.pk\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8897f75-ee88-410e-aa7c-a4f04fd07878",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Clean the timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291d732f-d992-4eb2-b43c-9b0eec3ba8b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T16:07:11.317561Z",
     "iopub.status.busy": "2022-11-17T16:07:11.317396Z",
     "iopub.status.idle": "2022-11-17T16:07:11.341478Z",
     "shell.execute_reply": "2022-11-17T16:07:11.340861Z",
     "shell.execute_reply.started": "2022-11-17T16:07:11.317548Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_timeseries(ts: DataFrame) -> DataFrame:\n",
    "    \"\"\"Select the correct columns\"\"\"\n",
    "    columns = ts.columns\n",
    "    used_columns = list(columns.intersection(USED_COLUMNS))\n",
    "    drop_columns = list(columns.difference(USED_COLUMNS))\n",
    "    miss_columns = list(USED_COLUMNS.difference(columns))\n",
    "\n",
    "    # drop unused columns\n",
    "    print(f\">>> Dropping columns {drop_columns}\")\n",
    "    ts = ts.loc[:, used_columns]\n",
    "\n",
    "    # fill up missing columns\n",
    "    print(f\">>> Adding columns {miss_columns}\")\n",
    "    ts.loc[:, miss_columns] = float(\"nan\")\n",
    "\n",
    "    # corerctly order columns\n",
    "    ts = ts[list(USED_COLUMNS)].copy()\n",
    "\n",
    "    # fixing timestamp_type\n",
    "    ts = ts.reset_index(\"measurement_time\")\n",
    "    if ts[\"measurement_time\"].dtype != \"timdedelta64\":\n",
    "        print(\">>> Converting float (seconds) to timedelta64\")\n",
    "        ts[\"measurement_time\"] = ts[\"measurement_time\"] * np.timedelta64(1, \"s\")\n",
    "    ts = ts.set_index([\"measurement_time\"], append=True)\n",
    "    return ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d965316a-ac26-4e4b-bdd0-9ddfd1849f93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T16:07:11.342518Z",
     "iopub.status.busy": "2022-11-17T16:07:11.342165Z",
     "iopub.status.idle": "2022-11-17T16:07:11.393945Z",
     "shell.execute_reply": "2022-11-17T16:07:11.393411Z",
     "shell.execute_reply.started": "2022-11-17T16:07:11.342486Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TS = clean_timeseries(TS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0756df-1cb7-4b24-962a-61a349553b17",
   "metadata": {},
   "source": [
    "# get predictions with loop  - slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42b7832-3288-4810-9e6e-0eb003546d5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T16:07:11.394836Z",
     "iopub.status.busy": "2022-11-17T16:07:11.394637Z",
     "iopub.status.idle": "2022-11-17T16:08:41.396566Z",
     "shell.execute_reply": "2022-11-17T16:08:41.396030Z",
     "shell.execute_reply.started": "2022-11-17T16:07:11.394823Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_predictions(ts: DataFrame):\n",
    "    if isinstance(ts.index, MultiIndex):\n",
    "        names = ts.index.names[:-1]\n",
    "        keys = ts.index.droplevel(-1).unique()\n",
    "        frame_dict = {key: get_predictions(ts.loc[key]) for key in keys}\n",
    "        return pd.concat(frame_dict, names=names)\n",
    "\n",
    "    T, X = encoder.encode(ts).values()\n",
    "    T = T.to(device=DEVICE)\n",
    "    X = X.to(device=DEVICE)\n",
    "    XHAT = model(T, X)\n",
    "    return encoder.decode({\"T\": T, \"X\": XHAT})\n",
    "\n",
    "\n",
    "preds = get_predictions(TS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf7cf3f-a53e-43ca-b6c1-842f97275981",
   "metadata": {},
   "source": [
    "## Predict in Batch Mode - Way Faster!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3c13af-05c3-4ad0-b88f-3011463a2b30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T16:08:41.397352Z",
     "iopub.status.busy": "2022-11-17T16:08:41.397220Z",
     "iopub.status.idle": "2022-11-17T16:08:48.860730Z",
     "shell.execute_reply": "2022-11-17T16:08:48.860091Z",
     "shell.execute_reply.started": "2022-11-17T16:08:41.397340Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_predictions_batch(ts: DataFrame) -> Tensor:\n",
    "    if isinstance(ts.index, MultiIndex):\n",
    "        names = ts.index.names[:-1]\n",
    "        sizes = ts.groupby(names).size()\n",
    "        T, X = encoder.encode(ts).values()\n",
    "        T = T.to(device=DEVICE)\n",
    "        X = X.to(device=DEVICE)\n",
    "        T_list = torch.split(T, sizes.to_list())\n",
    "        X_list = torch.split(X, sizes.to_list())\n",
    "        T = pad_sequence(T_list, batch_first=True, padding_value=torch.nan)\n",
    "        X = pad_sequence(X_list, batch_first=True, padding_value=torch.nan)\n",
    "\n",
    "        XHAT = model(T, X)\n",
    "\n",
    "        predictions = (\n",
    "            {\"T\": t[:size], \"X\": xhat[:size]} for t, xhat, size in zip(T, XHAT, sizes)\n",
    "        )\n",
    "        d = {key: encoder.decode(pred) for key, pred in zip(sizes.index, predictions)}\n",
    "        return pd.concat(d, names=names)\n",
    "    return get_predictions(ts)\n",
    "\n",
    "\n",
    "get_predictions_batch(TS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

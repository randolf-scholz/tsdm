{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Forecast plot given a stored model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T10:02:45.798405Z",
     "iopub.status.busy": "2022-11-16T10:02:45.798283Z",
     "iopub.status.idle": "2022-11-16T10:02:46.057251Z",
     "shell.execute_reply": "2022-11-16T10:02:46.056725Z",
     "shell.execute_reply.started": "2022-11-16T10:02:45.798370Z"
    }
   },
   "outputs": [],
   "source": [
    "%config InteractiveShell.ast_node_interactivity='last_expr_or_assign'  # always print last expr.\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import logging\n",
    "\n",
    "# logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T10:02:46.058151Z",
     "iopub.status.busy": "2022-11-16T10:02:46.058007Z",
     "iopub.status.idle": "2022-11-16T10:02:46.715742Z",
     "shell.execute_reply": "2022-11-16T10:02:46.715332Z",
     "shell.execute_reply.started": "2022-11-16T10:02:46.058141Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(\"bmh\")\n",
    "plt.rcParams[\"axes.axisbelow\"] = True\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "import pandas\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Index, Series, Timedelta, Timestamp\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "np.set_printoptions()\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "import torchinfo\n",
    "from torch import Tensor, jit, tensor\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enter Path and Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T10:02:46.716343Z",
     "iopub.status.busy": "2022-11-16T10:02:46.716171Z",
     "iopub.status.idle": "2022-11-16T10:02:46.731019Z",
     "shell.execute_reply": "2022-11-16T10:02:46.730593Z",
     "shell.execute_reply.started": "2022-11-16T10:02:46.716333Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ID = (449, 15653)  # the Run_id / Experiment_id we want to plot.\n",
    "# files:  2021-11-12T00:52:10 2021-11-12T00:51:55 2021-11-12T00:51:48\n",
    "# \"checkpoints/2021-11-15T12:05:00/LinODEnet-0\"\n",
    "# \"checkpoints/LinODEnet/KIWI_RUNS/skew_allways/2021-11-15T16:05:41/LinODEnet-0\"\n",
    "# \"adam/2021-11-15T20:38:52/LinODEnet-0\"\n",
    "PATH = \"/home/rscholz/Projects/KIWI/tsdm/experiments/kiwi/checkpoints/KIWI/LinODEnet/2022-11-16T01:55:32/f=0_bs=64_lr=0.001_hs=60_ls=128/\"\n",
    "NAME = \"RecursiveScriptModule-24-3168\"\n",
    "# the model checkpoint, should be a zip-archive created by torch.save / torch.jit.save\n",
    "MODEL_FILE = PATH + NAME\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "DTYPE = torch.float32\n",
    "NAN = tensor(float(\"nan\"), dtype=DTYPE, device=DEVICE)\n",
    "PRD_HORIZON = \"3h\"\n",
    "OBS_HORIZON = \"2h\"\n",
    "# HORIZON = \"3h\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intialize the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T10:02:46.731603Z",
     "iopub.status.busy": "2022-11-16T10:02:46.731435Z",
     "iopub.status.idle": "2022-11-16T10:02:47.927925Z",
     "shell.execute_reply": "2022-11-16T10:02:47.927524Z",
     "shell.execute_reply.started": "2022-11-16T10:02:46.731591Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tsdm.tasks import KiwiTask\n",
    "\n",
    "task = KiwiTask(\n",
    "    sampler_kwargs=dict(\n",
    "        forecasting_horizon=PRD_HORIZON,\n",
    "        observation_horizon=OBS_HORIZON,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T10:02:47.928554Z",
     "iopub.status.busy": "2022-11-16T10:02:47.928358Z",
     "iopub.status.idle": "2022-11-16T10:02:48.026221Z",
     "shell.execute_reply": "2022-11-16T10:02:48.025816Z",
     "shell.execute_reply.started": "2022-11-16T10:02:47.928542Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = torch.jit.load(MODEL_FILE, torch.device(\"cpu\"))\n",
    "torchinfo.summary(model, depth=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T10:02:48.026825Z",
     "iopub.status.busy": "2022-11-16T10:02:48.026708Z",
     "iopub.status.idle": "2022-11-16T10:02:51.057548Z",
     "shell.execute_reply": "2022-11-16T10:02:51.057022Z",
     "shell.execute_reply.started": "2022-11-16T10:02:48.026814Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# assert ID in task.splits[(0, \"train\")][0].index\n",
    "TRAINLOADER = task.dataloaders[(0, \"train\")]\n",
    "EVALLOADER = task.dataloaders[(0, \"test\")]\n",
    "\n",
    "ts = task.dataset[ID].timeseries\n",
    "\n",
    "dloader = TRAINLOADER\n",
    "split = task.splits[(0, \"test\")][ID]\n",
    "encoder = task.encoders[(0, \"test\")]\n",
    "sampler = task.samplers[(0, \"test\")][ID]\n",
    "sampler.shuffle = False\n",
    "\n",
    "from tsdm.tasks import TimeSeriesSampleGenerator\n",
    "\n",
    "generator = TimeSeriesSampleGenerator(\n",
    "    split,\n",
    "    observables=task.observables,\n",
    "    targets=task.targets,\n",
    "    covariates=task.covariates,\n",
    ")\n",
    "\n",
    "\n",
    "def collate_fn(inputs: list[object]):\n",
    "\n",
    "    xs = []\n",
    "    ys = []\n",
    "\n",
    "    for obj in inputs:\n",
    "        xs.append(encoder.encode(obj.inputs.x))\n",
    "        ys.append(encoder.encode(obj.targets.y))\n",
    "\n",
    "    return xs, ys\n",
    "\n",
    "\n",
    "# dataloader = DataLoader(generator, sampler=sampler, collate_fn = lambda x: [y[0] for y in x])\n",
    "samples = [generator[key] for key in sampler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T10:02:51.058767Z",
     "iopub.status.busy": "2022-11-16T10:02:51.058645Z",
     "iopub.status.idle": "2022-11-16T10:02:51.922115Z",
     "shell.execute_reply": "2022-11-16T10:02:51.921726Z",
     "shell.execute_reply.started": "2022-11-16T10:02:51.058756Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample = samples[0]\n",
    "tx, x = encoder.encode(sample.inputs.x).values()\n",
    "tx, x = encoder.encode(sample.inputs.x).values()\n",
    "ty, y = encoder.encode(sample.targets.y).values()\n",
    "yhat = model(tx, x)\n",
    "reconstructed = encoder.decode({\"T\": tx, \"X\": yhat})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T10:02:51.922797Z",
     "iopub.status.busy": "2022-11-16T10:02:51.922635Z",
     "iopub.status.idle": "2022-11-16T10:02:51.943250Z",
     "shell.execute_reply": "2022-11-16T10:02:51.942795Z",
     "shell.execute_reply.started": "2022-11-16T10:02:51.922785Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "reconstructed.index  # .loc[: task.observation_horizon]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Function for Batch post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T10:02:51.944198Z",
     "iopub.status.busy": "2022-11-16T10:02:51.943892Z",
     "iopub.status.idle": "2022-11-16T10:02:51.971676Z",
     "shell.execute_reply": "2022-11-16T10:02:51.970925Z",
     "shell.execute_reply.started": "2022-11-16T10:02:51.944173Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prep_batch(batch: tuple[Tensor, Tensor]):\n",
    "    \"\"\"Get batch and create model inputs and targets.\"\"\"\n",
    "    T, X = batch\n",
    "    targets = X[..., task.observation_horizon :, task.targets.index].clone()\n",
    "    # assert targets.shape == (BATCH_SIZE, PRD_HORIZON, len(TASK.targets))\n",
    "    originals = X.clone()\n",
    "    inputs = X.clone()\n",
    "    inputs[:, task.observation_horizon :, task.targets.index] = NAN\n",
    "    inputs[:, task.observation_horizon :, task.observables.index] = NAN\n",
    "    # assert inputs.shape == (BATCH_SIZE, HORIZON, NUM_DIM)\n",
    "    return T, inputs, targets, originals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Helper function to create the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T10:02:51.972638Z",
     "iopub.status.busy": "2022-11-16T10:02:51.972458Z",
     "iopub.status.idle": "2022-11-16T10:02:52.001485Z",
     "shell.execute_reply": "2022-11-16T10:02:52.000920Z",
     "shell.execute_reply.started": "2022-11-16T10:02:51.972622Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_plot(axes, task, sample):\n",
    "    \"\"\"Helper function to create plot automatically.\"\"\"\n",
    "    # batch = slices[0]\n",
    "    tx, x = encoder.encode(sample.inputs.x).values()\n",
    "    ty, y = encoder.encode(sample.targets.y).values()\n",
    "    yhat = model(tx, x)\n",
    "    reconstructed = encoder.decode({\"T\": tx, \"X\": yhat})\n",
    "    mask = sample.inputs.x.notna() | sample.targets.y.notna()\n",
    "\n",
    "    time = reconstructed.index.to_series()\n",
    "    t0 = time.iloc[0]\n",
    "    t1 = t0 + pd.Timedelta(task.observation_horizon)\n",
    "    t2 = t1 + pd.Timedelta(task.forecasting_horizon)\n",
    "\n",
    "    for ax, target in zip(axes.flatten(), task.targets):\n",
    "        # color = next(ax._get_lines.prop_cycler)[\"color\"]\n",
    "        ax.plot(\n",
    "            time.loc[t0:t1],\n",
    "            reconstructed.loc[t0:t1, target],\n",
    "            ls=\":\",\n",
    "            lw=2,\n",
    "            color=\"y\",\n",
    "        )\n",
    "        ax.plot(\n",
    "            time.loc[t1:t2],\n",
    "            reconstructed.loc[t1:t2, target],\n",
    "            ls=\"-\",\n",
    "            lw=2,\n",
    "            color=\"r\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Raw data plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T10:02:52.002454Z",
     "iopub.status.busy": "2022-11-16T10:02:52.002230Z",
     "iopub.status.idle": "2022-11-16T10:02:53.272723Z",
     "shell.execute_reply": "2022-11-16T10:02:53.272085Z",
     "shell.execute_reply.started": "2022-11-16T10:02:52.002438Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=3, ncols=3, sharex=True, figsize=(16, 8), constrained_layout=True\n",
    ")\n",
    "\n",
    "for ax, target in zip(axes.flatten(), task.targets):\n",
    "    data = ts[target]\n",
    "    times = ts.index.values\n",
    "    mask = ~np.isnan(data)\n",
    "    ax.plot(\n",
    "        times[mask],\n",
    "        data[mask],\n",
    "        ls=\":\",\n",
    "        lw=0.5,\n",
    "        marker=\".\",\n",
    "        ms=6,\n",
    "    )\n",
    "    ax.legend([f\"{target} - observations\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the model Forecast Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T10:02:53.273682Z",
     "iopub.status.busy": "2022-11-16T10:02:53.273488Z",
     "iopub.status.idle": "2022-11-16T10:02:59.972299Z",
     "shell.execute_reply": "2022-11-16T10:02:59.971625Z",
     "shell.execute_reply.started": "2022-11-16T10:02:53.273666Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "grid = np.linspace(0, len(samples) - 1, num=3, dtype=int)\n",
    "# grid = [0]\n",
    "batch = [samples[key] for key in grid]\n",
    "\n",
    "for sample in batch:\n",
    "    make_plot(axes, task, sample)\n",
    "\n",
    "fig.savefig(f\"{NAME.replace(r'/', r'_')}_{PRD_HORIZON}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T10:02:59.973333Z",
     "iopub.status.busy": "2022-11-16T10:02:59.973113Z",
     "iopub.status.idle": "2022-11-16T10:03:00.142764Z",
     "shell.execute_reply": "2022-11-16T10:03:00.139636Z",
     "shell.execute_reply.started": "2022-11-16T10:02:59.973306Z"
    }
   },
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating per-channel plots for all channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-11-16T10:03:00.143286Z",
     "iopub.status.idle": "2022-11-16T10:03:00.143540Z",
     "shell.execute_reply": "2022-11-16T10:03:00.143429Z",
     "shell.execute_reply.started": "2022-11-16T10:03:00.143417Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_plot(axes, task, batch, target):\n",
    "    \"\"\"Helper function to create plot automatically.\"\"\"\n",
    "    # batch = slices[0]\n",
    "    times, inputs, targets, originals = (x.to(device=\"cpu\") for x in prep_batch(batch))\n",
    "    outputs = model(times, inputs)\n",
    "\n",
    "    times = times[0].detach().cpu()\n",
    "    inputs = inputs[0].detach().cpu()\n",
    "    outputs = outputs[0].detach().cpu()\n",
    "    targets = targets[0].detach().cpu()\n",
    "    originals = originals[0].detach().cpu()\n",
    "\n",
    "    times.shape, outputs.shape, inputs.shape, targets.shape, originals.shape\n",
    "    reconstructed = encoder.decode((times, outputs)).astype(\"float32\")\n",
    "\n",
    "    data = originals[:, idx]\n",
    "    mask = ~np.isnan(data)\n",
    "    ax.plot(\n",
    "        reconstructed.index[: task.observation_horizon],\n",
    "        reconstructed.iloc[: task.observation_horizon, idx],\n",
    "        ls=\":\",\n",
    "        lw=0.1,\n",
    "        color=\"r\",\n",
    "    )\n",
    "    ax.plot(\n",
    "        reconstructed.index[task.observation_horizon - 1 :],\n",
    "        reconstructed.iloc[task.observation_horizon - 1 :, idx],\n",
    "        ls=\"-\",\n",
    "        lw=2,\n",
    "        color=\"r\",\n",
    "    )\n",
    "    print(reconstructed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-11-16T10:03:00.144679Z",
     "iopub.status.idle": "2022-11-16T10:03:00.144939Z",
     "shell.execute_reply": "2022-11-16T10:03:00.144824Z",
     "shell.execute_reply.started": "2022-11-16T10:03:00.144812Z"
    }
   },
   "outputs": [],
   "source": [
    "columns = task.dataset.timeseries.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-11-16T10:03:00.145990Z",
     "iopub.status.idle": "2022-11-16T10:03:00.146238Z",
     "shell.execute_reply": "2022-11-16T10:03:00.146122Z",
     "shell.execute_reply.started": "2022-11-16T10:03:00.146112Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=2, ncols=2, sharex=True, figsize=(16, 8), constrained_layout=True\n",
    ")\n",
    "\n",
    "for target in task.targets.items():\n",
    "    data = ts[target]\n",
    "    times = ts.index.values\n",
    "    mask = ~np.isnan(data)\n",
    "    ax.plot(\n",
    "        times[mask],\n",
    "        data[mask],\n",
    "        ls=\":\",\n",
    "        lw=0.5,\n",
    "        marker=\".\",\n",
    "        ms=6,\n",
    "    )\n",
    "    ax.legend([f\"{target} - observations\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

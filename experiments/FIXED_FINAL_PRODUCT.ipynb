{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc22d517-c76d-4da2-ac57-ab077be3396f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InteractiveShell.ast_node_interactivity='last_expr_or_assign'  # always print last expr.\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "from time import perf_counter, time\n",
    "from typing import Any, NamedTuple\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# enable JIT compilation - must be done before loading torch!\n",
    "os.environ[\"PYTORCH_JIT\"] = \"1\"\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "# logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "880c03d7-324c-4bc8-ae50-5392d4ff4642",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchinfo\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "TARGET = \"OD600\"\n",
    "SPLIT = 0\n",
    "\n",
    "RUN_NAME = f\"{TARGET}-{SPLIT}-More_params\"  # | input(\"enter name for run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "20e1c36b-b316-486d-bf09-724a98b0f477",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas\n",
    "from linodenet.models import LinODE, LinODECell, LinODEnet\n",
    "from linodenet.models.filters import SequentialFilter\n",
    "from linodenet.projections.functional import skew_symmetric, symmetric\n",
    "from numpy.typing import NDArray\n",
    "from pandas import DataFrame, Index, Series, Timedelta, Timestamp\n",
    "from torch import Tensor, jit, nn, tensor\n",
    "from torch.optim import SGD, Adam, AdamW\n",
    "from torch.utils.data import BatchSampler, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchinfo import summary\n",
    "from tqdm import tqdm, trange\n",
    "from typing import Union, Optional\n",
    "from collections.abc import *\n",
    "\n",
    "import tsdm\n",
    "from tsdm.datasets import DATASETS\n",
    "from tsdm.encoders.functional import time2float\n",
    "from tsdm.encoders.modular import *\n",
    "from tsdm.logutils import (\n",
    "    log_kernel_information,\n",
    "    log_metrics,\n",
    "    log_model_state,\n",
    "    log_optimizer_state,\n",
    ")\n",
    "from tsdm.losses import LOSSES\n",
    "from tsdm.random.samplers import *\n",
    "from tsdm.tasks import KIWI_FINAL_PRODUCT\n",
    "from tsdm.utils import grad_norm, multi_norm\n",
    "from tsdm.utils.strings import *\n",
    "\n",
    "np.set_printoptions(4, linewidth=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "464673c5-e855-4a21-b089-eb02aa58c584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable benchmarking for variable sized input\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75c73e6-8f71-4570-ae16-0f01889052b3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Initialize Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0cfe050-72d6-46c0-b062-e1dbf7ebc93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DTYPE = torch.float32\n",
    "\n",
    "task = KIWI_FINAL_PRODUCT(\n",
    "    train_batch_size=BATCH_SIZE,\n",
    "    eval_batch_size=2048,\n",
    "    target=TARGET,\n",
    ")\n",
    "\n",
    "DATASET = task.dataset\n",
    "ts = task.timeseries\n",
    "md = task.metadata\n",
    "NUM_PTS, NUM_DIM = ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e314057-f294-4b76-9c28-438fa107070e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.core.indexes.frozen import FrozenList\n",
    "\n",
    "task = KIWI_FINAL_PRODUCT()\n",
    "ts = task.timeseries.sort_index(axis=\"index\").sort_index(axis=\"columns\")\n",
    "channel_freq = pd.notna(ts).mean().sort_values()\n",
    "fast_channels = FrozenList(channel_freq[channel_freq >= 0.1].index)\n",
    "slow_channels = FrozenList(channel_freq[channel_freq < 0.1].index)\n",
    "FAST = ts[fast_channels].dropna(how=\"all\")\n",
    "SLOW = ts[slow_channels].dropna(how=\"all\")\n",
    "groups = {\"fast\": fast_channels, \"slow\": slow_channels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "23799e99-d52f-4d87-a71a-198184592442",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrameSplitter(BaseEncoder, Mapping):\n",
    "    r\"\"\"Split a DataFrame into multiple groups.\n",
    "\n",
    "    The special value ``...`` (:class:`Ellipsis`) can be used to indicate\n",
    "    that all other columns belong to this group.\n",
    "\n",
    "    This function can be used on index columns as well.\n",
    "    \"\"\"\n",
    "\n",
    "    column_columns: Index\n",
    "    column_dtypes: Series\n",
    "    column_indices: list[int]\n",
    "\n",
    "    index_columns: Index\n",
    "    index_dtypes = Series\n",
    "    index_indices: list[int]\n",
    "\n",
    "    # FIXME: Union[types.EllipsisType, set[Hashable]] in 3.10\n",
    "    groups: dict[Hashable, Union[Hashable, list[Hashable]]]\n",
    "    group_indices: dict[Hashable, list[int]]\n",
    "\n",
    "    indices: dict[Hashable, list[int]]\n",
    "    has_ellipsis: bool = False\n",
    "    ellipsis: Optional[Hashable] = None\n",
    "\n",
    "    permutation: list[int]\n",
    "    inverse_permutation: list[int]\n",
    "\n",
    "    # @property\n",
    "    # def names(self) -> set[Hashable]:\n",
    "    #     r\"\"\"Return the union of all groups.\"\"\"\n",
    "    #     sets: list[set] = [\n",
    "    #         set(obj) if isinstance(obj, Iterable) else {Ellipsis}\n",
    "    #         for obj in self.groups.values()\n",
    "    #     ]\n",
    "    #     union: set[Hashable] = set.union(*sets)\n",
    "    #     assert sum(len(u) for u in sets) == len(union), \"Duplicate columns!\"\n",
    "    #     return union\n",
    "\n",
    "    def __init__(self, groups: Iterable[Hashable]) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        if not isinstance(groups, Mapping):\n",
    "            groups = dict(enumerate(groups))\n",
    "\n",
    "        self.groups = {}\n",
    "        for key, obj in groups.items():\n",
    "            if obj is Ellipsis:\n",
    "                self.groups[key] = obj\n",
    "                self.ellipsis = key\n",
    "                self.has_ellipsis = True\n",
    "            elif isinstance(obj, str) or not isinstance(obj, Iterable):\n",
    "                self.groups[key] = [obj]\n",
    "            else:\n",
    "                self.groups[key] = list(obj)\n",
    "\n",
    "    def __repr__(self):\n",
    "        r\"\"\"Return a string representation of the object.\"\"\"\n",
    "        return repr_mapping(self)\n",
    "\n",
    "    def __len__(self):\n",
    "        r\"\"\"Return the number of groups.\"\"\"\n",
    "        return len(self.groups)\n",
    "\n",
    "    def __iter__(self):\n",
    "        r\"\"\"Iterate over the groups.\"\"\"\n",
    "        return iter(self.groups)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        r\"\"\"Return the group.\"\"\"\n",
    "        return self.groups[item]\n",
    "\n",
    "    def fit(self, data: DataFrame, /) -> None:\n",
    "        r\"\"\"Fit the encoder.\"\"\"\n",
    "        index = data.index.to_frame()\n",
    "        self.column_dtypes = data.dtypes\n",
    "        self.column_columns = data.columns\n",
    "        self.index_columns = index.columns\n",
    "        self.index_dtypes = index.dtypes\n",
    "\n",
    "        assert not (\n",
    "            j := set(self.index_columns) & set(self.column_columns)\n",
    "        ), f\"index columns and data columns must be disjoint {j}!\"\n",
    "\n",
    "        data = data.copy().reset_index()\n",
    "\n",
    "        def get_idx(cols: Any) -> list[int]:\n",
    "            return [data.columns.get_loc(i) for i in cols]\n",
    "\n",
    "        self.indices: dict[Hashable, int] = dict(enumerate(data.columns))\n",
    "        self.group_indices: dict[Hashable, list[int]] = {}\n",
    "        self.column_indices = get_idx(self.column_columns)\n",
    "        self.index_indices = get_idx(self.index_columns)\n",
    "\n",
    "        # replace ellipsis indices\n",
    "        if self.has_ellipsis:\n",
    "            # FIXME EllipsisType in 3.10\n",
    "            fixed_cols = set().union(\n",
    "                *(\n",
    "                    set(cols)  # type: ignore[arg-type]\n",
    "                    for cols in self.groups.values()\n",
    "                    if cols is not Ellipsis\n",
    "                )\n",
    "            )\n",
    "            ellipsis_columns = [c for c in data.columns if c not in fixed_cols]\n",
    "            self.groups[self.ellipsis] = ellipsis_columns\n",
    "\n",
    "        # set column indices\n",
    "        self.permutation = []\n",
    "        for group, columns in self.groups.items():\n",
    "            if columns is Ellipsis:\n",
    "                continue\n",
    "            self.group_indices[group] = get_idx(columns)\n",
    "            self.permutation += self.group_indices[group]\n",
    "        self.inverse_permutation = np.argsort(self.permutation).tolist()\n",
    "        # sorted(p.copy(), key=p.__getitem__)\n",
    "\n",
    "    def encode(self, data: DataFrame, /) -> tuple[DataFrame, ...]:\n",
    "        r\"\"\"Encode the data.\"\"\"\n",
    "        # copy the frame and add index as columns.\n",
    "        data = data.reset_index()  # prepend index as columns!\n",
    "        data_columns = set(data.columns)\n",
    "\n",
    "        assert data_columns <= set(self.indices.values()), (\n",
    "            f\"Unknown columns {data_columns - set(self.indices)}.\"\n",
    "            \"If you want to encode unknown columns add a group ``...`` (Ellipsis).\"\n",
    "        )\n",
    "\n",
    "        encoded = []\n",
    "        for columns in self.groups.values():\n",
    "            encoded.append(data[columns].squeeze(axis=\"columns\"))\n",
    "        return tuple(encoded)\n",
    "\n",
    "    def decode(self, data: tuple[DataFrame, ...], /) -> DataFrame:\n",
    "        r\"\"\"Decode the data.\"\"\"\n",
    "        data = tuple(DataFrame(x) for x in data)\n",
    "        joined = pd.concat(data, axis=\"columns\")\n",
    "\n",
    "        # unshuffle the columns, restoring original order\n",
    "        joined = joined.iloc[..., self.inverse_permutation]\n",
    "\n",
    "        # Assemble the columns\n",
    "        columns = joined.iloc[..., self.column_indices]\n",
    "        columns.columns = self.column_columns\n",
    "        columns = columns.astype(self.column_dtypes)\n",
    "        columns = columns.squeeze(axis=\"columns\")\n",
    "\n",
    "        # assemble the index\n",
    "        index = joined.iloc[..., self.index_indices]\n",
    "        index.columns = self.index_columns\n",
    "        index = index.astype(self.index_dtypes)\n",
    "        index = index.squeeze(axis=\"columns\")\n",
    "\n",
    "        if isinstance(index, Series):\n",
    "            decoded = columns.set_index(index)\n",
    "        else:\n",
    "            decoded = columns.set_index(MultiIndex.from_frame(index))\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0734be14-1c9b-4c1d-9650-a75ef68ae1e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbcd3b62-e8f6-45fd-a9e5-e38b1482b050",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = FrameSplitter({\"a\": fast_channels, \"b\": slow_channels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43a53fa5-56b3-4940-a64f-301eb56f5969",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(ts.DOT.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87ee9b7f-5119-49af-bddb-87ffe77294a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(ts.DOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92332faf-9f8b-4af0-851f-852667d7fca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc.encode(ts)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9384c16c-3be9-4d35-91ee-e753cfa98555",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = FrameEncoder(\n",
    "    column_encoders={\n",
    "        fast_channels: Standardizer(),\n",
    "        slow_channels: MinMaxScaler(),\n",
    "    },\n",
    "    index_encoders={\n",
    "        \"run_id\": IntEncoder(),\n",
    "        \"experiment_id\": IntEncoder(),\n",
    "        \"measurement_time\": TimeDeltaEncoder(),\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6afd54e-0e02-4a21-b6b9-97a30eaa897a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder = ChainedEncoder(\n",
    "    #\n",
    "    TensorEncoder(),\n",
    "    FrameSplitter([\"value\", \"measurement_time\", ...]),\n",
    "    # FrameSplitter([...]),\n",
    "    TripletEncoder(),\n",
    "    FrameEncoder(\n",
    "        Standardizer(),\n",
    "        index_encoders=MinMaxScaler() @ TimeDeltaEncoder(unit=\"s\"),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e7d19a-7e05-4441-a179-398d5355b722",
   "metadata": {},
   "source": [
    "## Encoded SetFuncTS\n",
    "\n",
    "- We partition the channels $P = \\{pₖ∣k=1:K\\}$, where $pₖ≠∅$, $pᵢ∩pⱼ = ∅$ and $⋃ₖpₖ = \\{1,…, n\\}$\n",
    "\n",
    "- Model receives separate Tensors per group, encode them into shared dimension.\n",
    "\n",
    "- Special attention to the case when a groups has a single channel: do we give the useless one-hot?\n",
    "\n",
    "- When using weight sharing, all indicator variables need to be passed!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d8f1725-1f51-48d8-841d-b69941016616",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = ts.reset_index([0, 1], drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "229bf6dd-a4fa-4b98-996a-cd338fad9914",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.fit(demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "213b4c7f-08e4-45c9-a6eb-a8fa65c9a451",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = encoder.encode(demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e23af2b4-c96f-4a59-a4b3-59d7ff66d040",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = encoder.decode(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d0ba16c-a997-48af-973b-b2e10a5df8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas.testing.assert_frame_equal(demo, decoded, atol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c719f42-a4fe-4d0f-a4e8-b01637cfc6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder[-1].column_encoders[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b5e60a-4bc6-4671-9872-82ff8d437619",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define Batching Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c87c925-a98f-4f70-addd-c10861b538cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_index = ts.columns.get_loc(task.target)\n",
    "target_encoder = encoder[-1].column_encoders[target_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a463f976-c300-4d15-9324-58fb2f45bf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batch(NamedTuple):\n",
    "    timeseries: list[Tensor]\n",
    "    targets: NDArray\n",
    "    encoded_targets: NDArray\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def mycollate(samples: list[tuple]) -> tuple[list[Tensor], NDArray, NDArray]:\n",
    "    timeseries = []\n",
    "    targets = []\n",
    "    encoded_targets = []\n",
    "\n",
    "    for idx, (ts_data, md_data), target, originals in samples:\n",
    "        timeseries.append(encoder.encode(ts_data))\n",
    "        targets.append(target)\n",
    "        encoded_targets.append(target_encoder.encode(target))\n",
    "\n",
    "    # timeseries = torch.cat(timeseries)\n",
    "    targets = np.stack(targets)\n",
    "    encoded_targets = torch.tensor(encoded_targets)\n",
    "\n",
    "    return Batch(timeseries, targets, encoded_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "668020a7-b58c-4844-9192-dd078cfd7a7a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "dloader = task.get_dataloader((SPLIT, \"train\"), batch_size=6, shuffle=True)\n",
    "batch = next(iter(dloader))\n",
    "sample = batch[0]\n",
    "mycollate(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7ad313-0bca-47ae-a23d-05c1430fb739",
   "metadata": {},
   "source": [
    "## Initialize Loss & Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c89a3b59-6ef4-4b41-b53e-9b23ef5bbafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOSS = task.test_metric.to(device=DEVICE)\n",
    "metrics = {key: jit.script(LOSSES[key]()) for key in (\"RMSE\", \"MSE\", \"MAE\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfde25ec-dea8-462e-9164-45dff7fd7859",
   "metadata": {},
   "source": [
    "## Initialize DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c7338c5-6e93-4592-b5da-504aaf95b815",
   "metadata": {},
   "outputs": [],
   "source": [
    "task.final_product_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f07dda4b-660f-4e0e-b3f6-d1db58d1f7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "md[\"target_value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b1f62fa2-dc36-455e-91cf-6b46b8b0e6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINLOADER = task.get_dataloader(\n",
    "    (SPLIT, \"train\"),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=mycollate,\n",
    "    pin_memory=True,\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=8,\n",
    "    # num_workers=os.cpu_count() // 4,\n",
    "    persistent_workers=True,\n",
    ")\n",
    "\n",
    "\n",
    "EVALLOADER = task.get_dataloader(\n",
    "    (SPLIT, \"test\"),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=mycollate,\n",
    "    pin_memory=True,\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=8,\n",
    "    # num_workers=os.cpu_count() // 4,\n",
    "    persistent_workers=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1996de-7202-46f1-8c42-70d7622db779",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Hyperparamters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eeaef85b-c8a3-4cb5-a6ad-bf6312f6f6e8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "OPTIMIZER_CONFIG = {\n",
    "    \"__name__\": \"AdamW\",\n",
    "    \"lr\": 0.001,\n",
    "    \"betas\": (0.9, 0.999),\n",
    "    \"eps\": 1e-08,\n",
    "    \"weight_decay\": 0.001,\n",
    "    \"amsgrad\": False,\n",
    "}\n",
    "\n",
    "LR_SCHEDULER_CONFIG = {\n",
    "    \"__name__\": \"ReduceLROnPlateau\",\n",
    "    \"mode\": \"min\",\n",
    "    # (str) – One of min, max. In min mode, lr will be reduced when the quantity monitored has stopped decreasing; in max mode it will be reduced when the quantity monitored has stopped increasing. Default: ‘min’.\n",
    "    \"factor\": 0.1,\n",
    "    # (float) – Factor by which the learning rate will be reduced. new_lr = lr * factor. Default: 0.1.\n",
    "    \"patience\": 10,\n",
    "    # (int) – Number of epochs with no improvement after which learning rate will be reduced. For example, if patience = 2, then we will ignore the first 2 epochs with no improvement, and will only decrease the LR after the 3rd epoch if the loss still hasn’t improved then. Default: 10.\n",
    "    \"threshold\": 0.0001,\n",
    "    # (float) – Threshold for measuring the new optimum, to only focus on significant changes. Default: 1e-4.\n",
    "    \"threshold_mode\": \"rel\",\n",
    "    # (str) – One of rel, abs. In rel mode, dynamic_threshold = best * ( 1 + threshold ) in ‘max’ mode or best * ( 1 - threshold ) in min mode. In abs mode, dynamic_threshold = best + threshold in max mode or best - threshold in min mode. Default: ‘rel’.\n",
    "    \"cooldown\": 0,\n",
    "    # (int) – Number of epochs to wait before resuming normal operation after lr has been reduced. Default: 0.\n",
    "    \"min_lr\": 1e-08,\n",
    "    # (float or list) – A scalar or a list of scalars. A lower bound on the learning rate of all param groups or each group respectively. Default: 0.\n",
    "    \"eps\": 1e-08,\n",
    "    # (float) – Minimal decay applied to lr. If the difference between new and old lr is smaller than eps, the update is ignored. Default: 1e-8.\n",
    "    \"verbose\": True\n",
    "    # (bool) – If True, prints a message to stdout for each update. Default: False.\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c913f4-ea56-4e3c-ae29-2bf615e3464c",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ba10ccb-933b-431a-98a2-0ab0dcc36170",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsdm.models import SetFuncTS\n",
    "\n",
    "MODEL = SetFuncTS\n",
    "model = MODEL(17, 1, latent_size=256, dim_keys=128, dim_vals=128, dim_deepset=128)\n",
    "model.to(device=DEVICE, dtype=DTYPE)\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844d9c1c-4c7c-419b-9dd4-d1ef6fce83fa",
   "metadata": {},
   "source": [
    "### Warmup - test forward / backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d0824374-d35f-48b7-b023-667d89627610",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(TRAINLOADER))\n",
    "y = model.forward_batch(batch.timeseries)\n",
    "torch.linalg.norm(y).backward()\n",
    "model.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83e71ba-af79-4c01-a587-3785154e4036",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Initalize Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c34d87a-a015-46c7-8448-19731bbf7d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsdm.optimizers import LR_SCHEDULERS, OPTIMIZERS\n",
    "from tsdm.utils import initialize_from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "efbabd0e-473c-4900-ae00-1819f116c96a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "OPTIMIZER_CONFIG |= {\"params\": model.parameters()}\n",
    "optimizer = initialize_from(OPTIMIZERS, **OPTIMIZER_CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9afe97-5756-4863-b42e-eafccc66eba6",
   "metadata": {},
   "source": [
    "## Load Existing Model instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9f2613d2-d67a-4c2f-964d-244209514118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load existing model & optimizer\n",
    "# from pathlib import Path\n",
    "\n",
    "# model_path = Path(\n",
    "#     \"/home/rscholz/Projects/KIWI/tsdm/examples/\"\n",
    "#     \"checkpoints/SetFuncTS/KIWI_RUNS/OD600-0-More_params/2022-02-07T00:55:25\"\n",
    "# )\n",
    "# model_name = \"SetFuncTS\"\n",
    "# optim_name = \"AdamW\"\n",
    "# model_versions = {}\n",
    "# optim_versions = {}\n",
    "\n",
    "# for file in model_path.iterdir():\n",
    "#     name, version = file.stem.split(\"-\")\n",
    "#     if name == model_name:\n",
    "#         model_versions[int(version)] = file\n",
    "#     if name == optim_name:\n",
    "#         optim_versions[int(version)] = file\n",
    "\n",
    "# MODEL = model_versions[max(model_versions)]\n",
    "# model = jit.load(MODEL)\n",
    "# MODEL = SetFuncTS\n",
    "# OPTIM = optim_versions[max(optim_versions)]\n",
    "# optim = torch.load(OPTIM)\n",
    "\n",
    "# epoch = optim[\"epoch\"]\n",
    "# batch_num = optim[\"batch\"]\n",
    "# optim = optim[\"optimizer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5892b9-c3ad-4b3b-992e-e082b600227c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Logging Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2919d5f-1d1f-4147-aacf-3e50d09230ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsdm.logutils import compute_metrics\n",
    "\n",
    "# def log_all(i, model, writer, optimizer):\n",
    "#     kernel = model.system.kernel.clone().detach().cpu()\n",
    "#     log_kernel_information(i, writer, kernel, histograms=True)\n",
    "#     log_optimizer_state(i, writer, optimizer, histograms=True)\n",
    "\n",
    "\n",
    "def log_hparams(i, writer, *, metric_dict, hparam_dict):\n",
    "    hparam_dict |= {\"epoch\": i}\n",
    "    metric_dict = add_prefix(metric_dict, \"hparam\")\n",
    "    writer.add_hparams(hparam_dict=hparam_dict, metric_dict=metric_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d902635f-ae08-43aa-b60b-d21805d83f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_START = tsdm.utils.now()\n",
    "CHECKPOINTDIR = Path(\n",
    "    f\"checkpoints/{MODEL.__name__}/{DATASET.name}/{RUN_NAME}/{RUN_START}\"\n",
    ")\n",
    "CHECKPOINTDIR.mkdir(parents=True, exist_ok=True)\n",
    "LOGGING_DIR = f\"runs/{MODEL.__name__}/{DATASET.name}/{RUN_NAME}/{RUN_START}\"\n",
    "writer = SummaryWriter(LOGGING_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62361bf2-16b2-46b0-bc69-71bee7045422",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63df8057-0535-4479-957e-79f45b4840c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_all_predictions(model, dataloader):\n",
    "    ys = []\n",
    "    yhats = []\n",
    "    for batch in tqdm(dataloader, leave=False):\n",
    "        # ts = batch.timeseries\n",
    "        # inputs = [(t.to(device=DEVICE),v.to(device=DEVICE), m.to(device=DEVICE)) for t,v,m in ts]\n",
    "        # yhats.append(model.batch_forward(inputs))\n",
    "        yhats.append(model.forward_batch(batch.timeseries))\n",
    "        ys.append(batch.encoded_targets.to(device=DEVICE))\n",
    "    y = torch.cat(ys).cpu().numpy()\n",
    "    yhat = torch.cat(yhats).cpu().numpy()\n",
    "    y = torch.tensor(target_encoder.decode(y))\n",
    "    yhat = torch.tensor(target_encoder.decode(yhat))\n",
    "    return y, yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5574c9-2363-4512-bfd3-0a8596e79774",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "98f8e9b5-c185-4ee6-8192-6a27c9a30708",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "i = 0  # batch_num\n",
    "epoch = 0  # epoch\n",
    "\n",
    "with torch.no_grad():\n",
    "    for key, dloader in {\"train\": TRAINLOADER, \"test\": EVALLOADER}.items():\n",
    "        y, ŷ = get_all_predictions(model, dloader)\n",
    "        assert torch.isfinite(y).all()\n",
    "        log_metrics(\n",
    "            epoch, writer=writer, metrics=metrics, targets=y, predics=ŷ, prefix=key\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e9b5c3-8da4-4e5b-b4a5-f0dfac9ff450",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for epoch in (epochs := range(epoch, epoch + 1000)):\n",
    "    if epoch == 1000:\n",
    "        for g in optimizer.param_groups:\n",
    "            g[\"lr\"] = 0.0001\n",
    "    batching_time = perf_counter()\n",
    "    for batch in (batches := tqdm(TRAINLOADER, leave=False)):\n",
    "        batching_time = perf_counter() - batching_time\n",
    "        i += 1\n",
    "        # Optimization step\n",
    "        model.zero_grad(set_to_none=True)\n",
    "        targets = batch.encoded_targets.to(device=DEVICE)\n",
    "\n",
    "        # forward\n",
    "        forward_time = perf_counter()\n",
    "        predics = model.forward_batch(batch.timeseries)\n",
    "        loss = LOSS(targets, predics)\n",
    "        forward_time = perf_counter() - forward_time\n",
    "\n",
    "        # backward\n",
    "        backward_time = perf_counter()\n",
    "        loss.backward()\n",
    "        backward_time = perf_counter() - backward_time\n",
    "\n",
    "        # step\n",
    "        optimizer.step()\n",
    "\n",
    "        # batch logging\n",
    "        with torch.no_grad():\n",
    "            logging_time = time()\n",
    "            if torch.any(~torch.isfinite(loss)):\n",
    "                raise RuntimeError(\"NaN/INF-value encountered!!\")\n",
    "\n",
    "            log_metrics(\n",
    "                i,\n",
    "                writer=writer,\n",
    "                metrics=metrics,\n",
    "                targets=targets.clone(),\n",
    "                predics=predics.clone(),\n",
    "                prefix=\"batch\",\n",
    "            )\n",
    "            log_optimizer_state(i, writer=writer, optimizer=optimizer, prefix=\"batch\")\n",
    "\n",
    "            # lval = loss.clone().detach().cpu().numpy()\n",
    "            # gval = grad_norm(list(model.parameters())).clone().detach().cpu().numpy()\n",
    "            logging_time = time() - logging_time\n",
    "\n",
    "        batches.set_postfix(\n",
    "            # loss=f\"{lval:.2e}\",\n",
    "            # gnorm=f\"{gval:.2e}\",\n",
    "            epoch=epoch,\n",
    "            Δt_forward=f\"{forward_time:.1f}\",\n",
    "            Δt_backward=f\"{backward_time:.1f}\",\n",
    "            Δt_logging=f\"{logging_time:.1f}\",\n",
    "            Δt_batching=f\"{batching_time:.1f}\",\n",
    "        )\n",
    "        batching_time = perf_counter()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # end-of-epoch logging\n",
    "        for key, dloader in {\"train\": TRAINLOADER, \"test\": EVALLOADER}.items():\n",
    "            y, ŷ = get_all_predictions(model, dloader)\n",
    "            assert torch.isfinite(y).all()\n",
    "            log_metrics(\n",
    "                epoch, writer=writer, metrics=metrics, targets=y, predics=ŷ, prefix=key\n",
    "            )\n",
    "\n",
    "        # Model Checkpoint\n",
    "        torch.jit.save(model, CHECKPOINTDIR.joinpath(f\"{MODEL.__name__}-{epoch}\"))\n",
    "        torch.save(\n",
    "            {\n",
    "                \"optimizer\": optimizer,\n",
    "                \"optimizer_state\": optimizer.state_dict(),\n",
    "                \"epoch\": epoch,\n",
    "                \"batch\": i,\n",
    "            },\n",
    "            CHECKPOINTDIR.joinpath(f\"{optimizer.__class__.__name__}-{epoch}\"),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88751536-3498-4f4a-a3e9-303a95a27cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "predics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce010b67-97ab-4e30-8fab-31340163fe6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise StopIteration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605bef8a-a964-4dbe-b071-2e3e468b28c6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Post Training Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea7e528-85a7-416e-b7b9-5a7e979ab466",
   "metadata": {},
   "source": [
    "# Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ecaa8f-b919-4ff9-8373-5ac01694cbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.profiler import ProfilerActivity, profile, record_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c844c142-b28d-49eb-8271-9892968ce862",
   "metadata": {},
   "outputs": [],
   "source": [
    "with profile(\n",
    "    activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
    "    record_shapes=True,\n",
    "    profile_memory=True,\n",
    ") as prof:\n",
    "    model(times, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe31e70-550f-4cfd-b73e-3a026786a390",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa42321-19e6-4e2e-9722-02abfe93519e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001aa24d-ed1c-4af8-b50a-c9b94b14bcad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

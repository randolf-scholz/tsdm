{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc22d517-c76d-4da2-ac57-ab077be3396f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InteractiveShell.ast_node_interactivity='last_expr_or_assign'  # always print last expr.\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import logging\n",
    "\n",
    "# logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "880c03d7-324c-4bc8-ae50-5392d4ff4642",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# enable JIT compilation - must be done before loading torch!\n",
    "os.environ[\"PYTORCH_JIT\"] = \"1\"\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "RUN_NAME = \"SurrLoss+Sequential_Filter\"  # | input(\"enter name for run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20e1c36b-b316-486d-bf09-724a98b0f477",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from time import perf_counter, time\n",
    "from typing import Any\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas\n",
    "import torch\n",
    "import torchinfo\n",
    "from linodenet.models import LinODE, LinODECell, LinODEnet\n",
    "from linodenet.projections.functional import skew_symmetric, symmetric\n",
    "from linodenet.models.filters import SequentialFilter\n",
    "from pandas import DataFrame, Index, Series, Timedelta, Timestamp\n",
    "from torch import Tensor, jit, nn, tensor\n",
    "from torch.optim import SGD, Adam, AdamW\n",
    "from torch.utils.data import BatchSampler, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import tsdm\n",
    "from tsdm.datasets import DATASETS\n",
    "from tsdm.encoders.functional import time2float\n",
    "from tsdm.logutils import (\n",
    "    log_kernel_information,\n",
    "    log_metrics,\n",
    "    log_model_state,\n",
    "    log_optimizer_state,\n",
    ")\n",
    "from tsdm.losses import LOSSES\n",
    "from tsdm.tasks import KIWI_RUNS_TASK\n",
    "from tsdm.util import grad_norm, multi_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec5a3d3d-86fe-4283-8a75-4a80a8e3d139",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75c73e6-8f71-4570-ae16-0f01889052b3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Initialize Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10ccb53e-8b33-45be-902f-575f1ed5afc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DTYPE = torch.float32\n",
    "NAN = tensor(float(\"nan\"), dtype=DTYPE, device=DEVICE)\n",
    "BATCH_SIZE = 256\n",
    "FORECAST_ALL = True\n",
    "\n",
    "# on average ca 30s between timestamps, i.e. 2 obs = 1min\n",
    "# let's increase horizon. OBS: 240 = 2h, PRD = 120 = 1h\n",
    "PRD_HORIZON = 120\n",
    "OBS_HORIZON = 240\n",
    "HORIZON = SEQLEN = OBS_HORIZON + PRD_HORIZON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0cfe050-72d6-46c0-b062-e1dbf7ebc93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = KIWI_RUNS_TASK(\n",
    "    forecasting_horizon=PRD_HORIZON,\n",
    "    observation_horizon=OBS_HORIZON,\n",
    "    train_batch_size=BATCH_SIZE,\n",
    "    eval_batch_size=2048,\n",
    ")\n",
    "\n",
    "DATASET = task.dataset\n",
    "ts = task.timeseries\n",
    "md = task.metadata\n",
    "NUM_PTS, NUM_DIM = ts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7ad313-0bca-47ae-a23d-05c1430fb739",
   "metadata": {},
   "source": [
    "## Initialize Loss & Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3d7548b-4c5b-4916-87e8-14f865ef4e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_LOSS = task.test_metric  # .to(device=DEVICE)\n",
    "metrics = {key: LOSSES[key] for key in (\"ND\", \"NRMSE\", \"MSE\", \"MAE\")}\n",
    "# assert any(isinstance(TASK.test_metric, metric) for metric in metrics.values())\n",
    "metrics = {key: LOSSES[key]() for key in (\"ND\", \"NRMSE\", \"MSE\", \"MAE\")} | {\n",
    "    \"WRMSE\": TASK_LOSS\n",
    "}\n",
    "\n",
    "# LOSS = TASK_LOSS\n",
    "# Let's try something else\n",
    "LOSS = metrics[\"NRMSE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d923e61-10d9-4720-a856-88372a8b9c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "task.loss_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfde25ec-dea8-462e-9164-45dff7fd7859",
   "metadata": {},
   "source": [
    "## Initialize DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1f62fa2-dc36-455e-91cf-6b46b8b0e6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINLOADERS = task.batchloaders\n",
    "TRAINLOADER = TRAINLOADERS[(0, \"train\")]\n",
    "EVALLOADERS = task.dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83ef7a34-67b5-449c-9072-fe955d49be81",
   "metadata": {},
   "outputs": [],
   "source": [
    "task.timeseries.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1996de-7202-46f1-8c42-70d7622db779",
   "metadata": {},
   "source": [
    "## Hyperparamters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eeaef85b-c8a3-4cb5-a6ad-bf6312f6f6e8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def join_dicts(d: dict[str, Any]) -> dict[str, Any]:\n",
    "    \"\"\"Recursively join dict by composing keys with '/'.\"\"\"\n",
    "    result = {}\n",
    "    for key, val in d.items():\n",
    "        if isinstance(val, dict):\n",
    "            result |= join_dicts(\n",
    "                {f\"{key}/{subkey}\": item for subkey, item in val.items()}\n",
    "            )\n",
    "        else:\n",
    "            result[key] = val\n",
    "    return result\n",
    "\n",
    "\n",
    "def add_prefix(d: dict[str, Any], /, prefix: str) -> dict[str, Any]:\n",
    "    return {f\"{prefix}/{key}\": item for key, item in d.items()}\n",
    "\n",
    "\n",
    "# OPTIMIZER_CONIFG = {\n",
    "#     \"__name__\": \"SGD\",\n",
    "#     \"lr\": 0.001,\n",
    "#     \"momentum\": 0,\n",
    "#     \"dampening\": 0,\n",
    "#     \"weight_decay\": 0,\n",
    "#     \"nesterov\": False,\n",
    "# }\n",
    "\n",
    "# OPTIMIZER_CONFIG = {\n",
    "#     \"__name__\": \"Adam\",\n",
    "#     \"lr\": 0.01,\n",
    "#     \"betas\": (0.9, 0.999),\n",
    "#     \"eps\": 1e-08,\n",
    "#     \"weight_decay\": 0,\n",
    "#     \"amsgrad\": False,\n",
    "# }\n",
    "\n",
    "\n",
    "OPTIMIZER_CONFIG = {\n",
    "    \"__name__\": \"AdamW\",\n",
    "    \"lr\": 0.001,\n",
    "    \"betas\": (0.9, 0.999),\n",
    "    \"eps\": 1e-08,\n",
    "    \"weight_decay\": 0.001,\n",
    "    \"amsgrad\": False,\n",
    "}\n",
    "\n",
    "\n",
    "SYSTEM = {\n",
    "    \"__name__\": \"LinODECell\",\n",
    "    \"input_size\": int,\n",
    "    \"kernel_initialization\": \"skew-symmetric\",\n",
    "}\n",
    "\n",
    "EMBEDDING = {\n",
    "    \"__name__\": \"ConcatEmbedding\",\n",
    "    \"input_size\": int,\n",
    "    \"hidden_size\": int,\n",
    "}\n",
    "FILTER = {\n",
    "    \"__name__\": \"SequentialFilter\",\n",
    "    \"input_size\": int,\n",
    "    \"hidden_size\": int,\n",
    "    \"autoregressive\": True,\n",
    "}\n",
    "\n",
    "# FILTER = {\n",
    "#     \"__name__\": \"RecurrentCellFilter\",\n",
    "#     \"concat\": True,\n",
    "#     \"input_size\": int,\n",
    "#     \"hidden_size\": int,\n",
    "#     \"autoregressive\": True,\n",
    "#     \"Cell\": {\n",
    "#         \"__name__\": \"GRUCell\",\n",
    "#         \"input_size\": int,\n",
    "#         \"hidden_size\": int,\n",
    "#         \"bias\": True,\n",
    "#         \"device\": None,\n",
    "#         \"dtype\": None,\n",
    "#     },\n",
    "# }\n",
    "from linodenet.models.encoders import ResNet, iResNet\n",
    "\n",
    "# ENCODER = {\"__name__\": \"ResNet\", \"__module__\": \"linodenet.models.encoders\",\"input_size\": int, \"nblocks\": 5, \"rezero\": True}\n",
    "# DECODER = {\"__name__\": \"ResNet\", \"__module__\": \"linodenet.models.encoders\",\"input_size\": int, \"nblocks\": 5, \"rezero\": True}\n",
    "\n",
    "\n",
    "LR_SCHEDULER_CONFIG = {\n",
    "    \"__name__\": \"ReduceLROnPlateau\",\n",
    "    \"mode\": \"min\",\n",
    "    # (str) – One of min, max. In min mode, lr will be reduced when the quantity monitored has stopped decreasing; in max mode it will be reduced when the quantity monitored has stopped increasing. Default: ‘min’.\n",
    "    \"factor\": 0.1,\n",
    "    # (float) – Factor by which the learning rate will be reduced. new_lr = lr * factor. Default: 0.1.\n",
    "    \"patience\": 10,\n",
    "    # (int) – Number of epochs with no improvement after which learning rate will be reduced. For example, if patience = 2, then we will ignore the first 2 epochs with no improvement, and will only decrease the LR after the 3rd epoch if the loss still hasn’t improved then. Default: 10.\n",
    "    \"threshold\": 0.0001,\n",
    "    # (float) – Threshold for measuring the new optimum, to only focus on significant changes. Default: 1e-4.\n",
    "    \"threshold_mode\": \"rel\",\n",
    "    # (str) – One of rel, abs. In rel mode, dynamic_threshold = best * ( 1 + threshold ) in ‘max’ mode or best * ( 1 - threshold ) in min mode. In abs mode, dynamic_threshold = best + threshold in max mode or best - threshold in min mode. Default: ‘rel’.\n",
    "    \"cooldown\": 0,\n",
    "    # (int) – Number of epochs to wait before resuming normal operation after lr has been reduced. Default: 0.\n",
    "    \"min_lr\": 1e-08,\n",
    "    # (float or list) – A scalar or a list of scalars. A lower bound on the learning rate of all param groups or each group respectively. Default: 0.\n",
    "    \"eps\": 1e-08,\n",
    "    # (float) – Minimal decay applied to lr. If the difference between new and old lr is smaller than eps, the update is ignored. Default: 1e-8.\n",
    "    \"verbose\": True\n",
    "    # (bool) – If True, prints a message to stdout for each update. Default: False.\n",
    "}\n",
    "\n",
    "MODEL_CONFIG = {\n",
    "    \"__name__\": \"LinODEnet\",\n",
    "    \"input_size\": NUM_DIM,\n",
    "    \"hidden_size\": 128,\n",
    "    \"embedding_type\": \"concat\",\n",
    "    \"Filter\": SequentialFilter.HP,\n",
    "    \"System\": SYSTEM,\n",
    "    \"Encoder\": ResNet.HP,\n",
    "    \"Decoder\": ResNet.HP,\n",
    "    \"Embedding\": EMBEDDING,\n",
    "}\n",
    "\n",
    "\n",
    "HPARAMS = join_dicts(\n",
    "    {\n",
    "        \"Optimizer\": OPTIMIZER_CONFIG,\n",
    "        \"LR_Scheduler\": LR_SCHEDULER_CONFIG,\n",
    "        \"Model\": MODEL_CONFIG,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ef80f24-0d93-426e-9596-c496435ad32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet(input_size=12, rezero=True)\n",
    "torchinfo.summary(model, depth=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32262eb-5d33-49fa-b68d-e2688ac618fe",
   "metadata": {},
   "source": [
    "## Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3e09543-0692-4f23-af83-912d14a18ac7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL = LinODEnet\n",
    "model = MODEL(**MODEL_CONFIG)\n",
    "model.to(device=DEVICE, dtype=DTYPE)\n",
    "torchinfo.summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2533e9ec-c827-4dc3-a236-790c41b2febe",
   "metadata": {},
   "source": [
    "### Initialized Kernel statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6cd49d0-de91-437b-bd10-86d4521a24bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "expA = torch.matrix_exp(model.kernel)\n",
    "for o in (-np.infty, -2, -1, 1, 2, np.infty, \"fro\", \"nuc\"):\n",
    "    val = torch.linalg.matrix_norm(model.kernel, ord=o).item()\n",
    "    val2 = torch.linalg.matrix_norm(expA, ord=o).item()\n",
    "    o = str(o)\n",
    "    print(f\"{o=:6s}\\t {val=:10.6f} \\t {val2=:10.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83e71ba-af79-4c01-a587-3785154e4036",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Initalize Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c34d87a-a015-46c7-8448-19731bbf7d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsdm.optimizers import OPTIMIZERS, LR_SCHEDULERS\n",
    "from tsdm.util import initialize_from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "efbabd0e-473c-4900-ae00-1819f116c96a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "OPTIMIZER_CONFIG |= {\"params\": model.parameters()}\n",
    "optimizer = initialize_from(OPTIMIZERS, **OPTIMIZER_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41b73651-55c4-4883-8ce9-0bb44ee7330b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f30b4014-0c62-4d7d-a1c9-f2ea8a444605",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTIMIZER_CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f2613d2-d67a-4c2f-964d-244209514118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_scheduler = initialize_from(\n",
    "#     LR_SCHEDULERS, LR_SCHEDULER_CONFIG | {\"optimizer\": OPTIMIZER_CONFIG}\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3e8ab3-a104-4492-b68a-d7f67e739921",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2de2a66d-5536-40d9-a209-11ba8d133a99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch = next(iter(TRAINLOADER))\n",
    "T, X = batch\n",
    "targets = X[..., OBS_HORIZON:, task.targets.index].clone()\n",
    "# assert targets.shape == (BATCH_SIZE, PRD_HORIZON, len(TASK.targets))\n",
    "\n",
    "inputs = X.clone()\n",
    "inputs[:, OBS_HORIZON:, task.targets.index] = NAN\n",
    "inputs[:, OBS_HORIZON:, task.observables.index] = NAN\n",
    "# assert inputs.shape == (BATCH_SIZE, HORIZON, NUM_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88ea547d-d10e-420e-8f93-5a32069d99fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "targets = X[..., OBS_HORIZON:, task.targets.index].clone()\n",
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "20388705-69a4-4765-bde4-d27527def516",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_batch(batch: tuple[Tensor, Tensor]):\n",
    "    \"\"\"Get batch and create model inputs and targets\"\"\"\n",
    "    T, X = batch\n",
    "    T = T.cuda(non_blocking=True)\n",
    "    X = X.cuda(non_blocking=True)\n",
    "    originals = X\n",
    "    targets = X[..., OBS_HORIZON:, task.targets.index].clone()\n",
    "    # assert targets.shape == (BATCH_SIZE, PRD_HORIZON, len(TASK.targets))\n",
    "\n",
    "    inputs = X.clone()\n",
    "    inputs[:, OBS_HORIZON:, task.targets.index] = NAN\n",
    "    inputs[:, OBS_HORIZON:, task.observables.index] = NAN\n",
    "    # assert inputs.shape == (BATCH_SIZE, HORIZON, NUM_DIM)\n",
    "    return T, inputs, targets, originals\n",
    "\n",
    "\n",
    "def get_all_preds(model, dataloader):\n",
    "    y, yhat = [], []\n",
    "    for batch in (pbar := tqdm(dataloader, leave=False)):\n",
    "        with torch.no_grad():\n",
    "            model.zero_grad()\n",
    "            times, inputs, targets, originals = prep_batch(batch)\n",
    "            outputs = model(times, inputs)\n",
    "            predics = outputs[:, OBS_HORIZON:, task.targets.index]\n",
    "            # display(outputs)\n",
    "            # display(targets)\n",
    "            loss = LOSS(targets, predics)\n",
    "            y.append(targets.clone().detach().cpu())\n",
    "            yhat.append(predics.clone().detach().cpu())\n",
    "        if pbar.n == 5:\n",
    "            break\n",
    "\n",
    "    targets, predics = torch.cat(y, dim=0), torch.cat(yhat, dim=0)\n",
    "    mask = torch.isnan(targets)\n",
    "    targets[mask] = torch.tensor(0.0)\n",
    "    predics[mask] = torch.tensor(0.0)\n",
    "    # scale = 1/torch.mean(mask.to(dtype=torch.float32))\n",
    "    # targets *= scale\n",
    "    # predics *= scale\n",
    "    return targets, predics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5892b9-c3ad-4b3b-992e-e082b600227c",
   "metadata": {},
   "source": [
    "## Logging Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2919d5f-1d1f-4147-aacf-3e50d09230ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsdm.logutils import compute_metrics\n",
    "\n",
    "\n",
    "def log_all(i, model, writer, optimizer):\n",
    "    kernel = model.system.kernel.clone().detach().cpu()\n",
    "    log_kernel_information(i, writer, kernel, histograms=True)\n",
    "    log_optimizer_state(i, writer, optimizer, histograms=True)\n",
    "\n",
    "\n",
    "def log_hparams(i, writer, *, metric_dict, hparam_dict):\n",
    "    hparam_dict |= {\"epoch\": i}\n",
    "    metric_dict = add_prefix(metric_dict, \"hparam\")\n",
    "    writer.add_hparams(hparam_dict=hparam_dict, metric_dict=metric_dict)\n",
    "\n",
    "\n",
    "print(\"WARMUP\")\n",
    "\n",
    "t = torch.randn(3, NUM_DIM).to(DEVICE)\n",
    "x = torch.randn(3, 1, NUM_DIM).to(device=DEVICE)\n",
    "y = model(t, x)\n",
    "torch.linalg.norm(y).backward()\n",
    "model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d902635f-ae08-43aa-b60b-d21805d83f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_START = tsdm.util.now()\n",
    "CHECKPOINTDIR = Path(\n",
    "    f\"checkpoints/{MODEL.__name__}/{DATASET.name}/{RUN_NAME}/{RUN_START}\"\n",
    ")\n",
    "CHECKPOINTDIR.mkdir(parents=True, exist_ok=True)\n",
    "LOGGING_DIR = f\"runs/{MODEL.__name__}/{DATASET.name}/{RUN_NAME}/{RUN_START}\"\n",
    "writer = SummaryWriter(LOGGING_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62361bf2-16b2-46b0-bc69-71bee7045422",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "98f8e9b5-c185-4ee6-8192-6a27c9a30708",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = -1\n",
    "epoch = 1\n",
    "\n",
    "with torch.no_grad():\n",
    "    # log optimizer state first !!!\n",
    "    # log_optimizer_state(epoch, writer, optimizer, histograms=True)\n",
    "    log_kernel_information(\n",
    "        epoch, writer=writer, kernel=model.system.kernel, histograms=True\n",
    "    )\n",
    "\n",
    "    for key in ((0, \"train\"), (0, \"test\")):\n",
    "        dataloader = EVALLOADERS[key]\n",
    "        y, ŷ = get_all_preds(model, dataloader)\n",
    "        assert torch.isfinite(y).all()\n",
    "        log_metrics(\n",
    "            epoch, writer=writer, metrics=metrics, targets=y, predics=ŷ, prefix=key[1]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a639555f-58dd-4830-b0a7-0f20e0c565a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in optimizer.param_groups:\n",
    "    g[\"lr\"] = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f5b6d250-20cb-479c-bd55-27dfe9c47bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = task.preprocessor\n",
    "\n",
    "target_idx = ts.columns.get_loc(\"OD600\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2df72a89-6113-42cd-9476-360cd766d778",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_encoder = encoder[-1].column_encoders[0][target_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a6c4090f-005a-4c8e-b3c9-7ab118eba91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"encoder.pickle\", \"wb\") as file:\n",
    "    pickle.dump(task.preprocessor, file)\n",
    "\n",
    "with open(\"target_encoder.pickle\", \"wb\") as file:\n",
    "    pickle.dump(target_encoder, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "97e9b5c3-8da4-4e5b-b4a5-f0dfac9ff450",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for epoch in (epochs := trange(epoch, 100)):\n",
    "    batching_time = perf_counter()\n",
    "    for batch in (batches := tqdm(TRAINLOADER, leave=False)):\n",
    "        batching_time = perf_counter() - batching_time\n",
    "        i += 1\n",
    "        # Optimization step\n",
    "        model.zero_grad(set_to_none=True)\n",
    "        times, inputs, targets, originals = prep_batch(batch)\n",
    "\n",
    "        forward_time = perf_counter()\n",
    "        outputs = model(times, inputs)\n",
    "        forward_time = perf_counter() - forward_time\n",
    "        predics = outputs[:, OBS_HORIZON:, task.targets.index]\n",
    "        mask = torch.isnan(targets)\n",
    "        targets[mask] = torch.tensor(0.0)\n",
    "        predics[mask] = torch.tensor(0.0)\n",
    "        mask = torch.isnan(originals)\n",
    "        originals[mask] = torch.tensor(0.0)\n",
    "        outputs[mask] = torch.tensor(0.0)\n",
    "\n",
    "        if not FORECAST_ALL:\n",
    "            # get rid of nan-values in the targets.\n",
    "            loss = LOSS(targets, predics)\n",
    "        else:\n",
    "            loss = LOSS(originals, outputs)\n",
    "\n",
    "        # # compensate NaN-Value with upscaling\n",
    "        # scale = 1/torch.mean(mask.to(dtype=torch.float32))\n",
    "        # targets *= scale\n",
    "        # predics *= scale\n",
    "\n",
    "        backward_time = perf_counter()\n",
    "        loss.backward()\n",
    "        backward_time = perf_counter() - backward_time\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        # batch logging\n",
    "        with torch.no_grad():\n",
    "            logging_time = time()\n",
    "            if torch.any(torch.isnan(loss)):\n",
    "                raise RuntimeError(\"NaN-value encountered!!\")\n",
    "\n",
    "            log_metrics(\n",
    "                i,\n",
    "                writer=writer,\n",
    "                metrics=metrics,\n",
    "                targets=targets.clone(),\n",
    "                predics=predics.clone(),\n",
    "                prefix=\"batch\",\n",
    "            )\n",
    "            log_optimizer_state(i, writer=writer, optimizer=optimizer, prefix=\"batch\")\n",
    "\n",
    "            # lval = loss.clone().detach().cpu().numpy()\n",
    "            # gval = grad_norm(list(model.parameters())).clone().detach().cpu().numpy()\n",
    "            logging_time = time() - logging_time\n",
    "\n",
    "        batches.set_postfix(\n",
    "            # loss=f\"{lval:.2e}\",\n",
    "            # gnorm=f\"{gval:.2e}\",\n",
    "            Δt_forward=f\"{forward_time:.1f}\",\n",
    "            Δt_backward=f\"{backward_time:.1f}\",\n",
    "            Δt_logging=f\"{logging_time:.1f}\",\n",
    "            Δt_batching=f\"{batching_time:.1f}\",\n",
    "        )\n",
    "        batching_time = perf_counter()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # log optimizer state first !!!\n",
    "        log_optimizer_state(epoch, writer=writer, optimizer=optimzier, histograms=True)\n",
    "        log_kernel_information(\n",
    "            epoch, writer=writer, kernel=model.system.kernel, histograms=True\n",
    "        )\n",
    "\n",
    "        for key in ((0, \"train\"), (0, \"test\")):\n",
    "            dataloader = EVALLOADERS[key]\n",
    "            y, ŷ = get_all_preds(model, dataloader)\n",
    "            metric_values = compute_metrics(metrics, targets=y, predics=ŷ)\n",
    "            log_metrics(\n",
    "                epoch,\n",
    "                writer=writer,\n",
    "                metrics=metrics,\n",
    "                values=metric_values,\n",
    "                prefix=key[1],\n",
    "            )\n",
    "            # log_hparams(epoch, writer, metric_dict=metric_values, hparam_dict=HPARAMS)\n",
    "\n",
    "        # Model Checkpoint\n",
    "        torch.jit.save(model, CHECKPOINTDIR.joinpath(f\"{MODEL.__name__}-{epoch}\"))\n",
    "        torch.save(\n",
    "            {\n",
    "                \"optimizer\": optimizer,\n",
    "                \"epoch\": epoch,\n",
    "                \"batch\": i,\n",
    "            },\n",
    "            CHECKPOINTDIR.joinpath(f\"{optimizer.__class__.__name__}-{epoch}\"),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce010b67-97ab-4e30-8fab-31340163fe6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise StopIteration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605bef8a-a964-4dbe-b071-2e3e468b28c6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Post Training Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e06d49-e5a7-4a0a-8933-9e5bc90ae2dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "buffers = dict(model.named_buffers())\n",
    "set(buffers.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56a1195-df32-40f2-9cbf-fa77a5c0e449",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "timedeltas = model.timedeltas.detach().cpu()\n",
    "xhat_pre = model.xhat_pre.detach().cpu()\n",
    "xhat_post = model.xhat_post.detach().cpu()\n",
    "zhat_pre = model.zhat_pre.detach().cpu()\n",
    "zhat_post = model.zhat_post.detach().cpu()\n",
    "xhat_pre.shape, xhat_post.shape, zhat_pre.shape, zhat_post.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc1d958-5d17-4a53-82eb-2821d8cc2b57",
   "metadata": {},
   "source": [
    "## Relative size change xhat_pre ⟶ xhat_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d726cd8-e8b0-4936-9ff9-4980eed3641a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.style.use(\"bmh\")\n",
    "\n",
    "BATCH_DIM, LEN, DIM = tuple(xhat_pre.shape)\n",
    "n, m = model.input_size, model.hidden_size\n",
    "\n",
    "\n",
    "def gmean(x, dim=(), p=2):\n",
    "    \"\"\"Geometric mean\"\"\"\n",
    "    return torch.exp(torch.mean(torch.log(torch.abs(x) ** p), dim=dim) ** (1 / p))\n",
    "\n",
    "\n",
    "predata = xhat_pre\n",
    "postdata = xhat_post\n",
    "\n",
    "xpretotalmag = torch.mean(\n",
    "    torch.linalg.norm(xhat_pre, dim=-1) / torch.linalg.norm(xhat_pre[:, [0]], dim=-1),\n",
    "    dim=0,\n",
    ").squeeze()\n",
    "\n",
    "xpsttotalmag = torch.mean(\n",
    "    torch.linalg.norm(xhat_post, dim=-1) / torch.linalg.norm(xhat_post[:, [0]], dim=-1),\n",
    "    dim=0,\n",
    ").squeeze()\n",
    "\n",
    "zpretotalmag = torch.mean(\n",
    "    torch.linalg.norm(zhat_pre, dim=-1) / torch.linalg.norm(zhat_pre[:, [0]], dim=-1),\n",
    "    dim=0,\n",
    ").squeeze()\n",
    "\n",
    "zpsttotalmag = torch.mean(\n",
    "    torch.linalg.norm(zhat_post, dim=-1) / torch.linalg.norm(zhat_post[:, [0]], dim=-1),\n",
    "    dim=0,\n",
    ").squeeze()\n",
    "\n",
    "xpremag = torch.mean(\n",
    "    torch.linalg.norm(xhat_pre[..., 1:, :], dim=-1)\n",
    "    / torch.linalg.norm(xhat_pre[..., :-1, :], dim=-1),\n",
    "    dim=0,\n",
    ")\n",
    "xpstmag = torch.mean(\n",
    "    torch.linalg.norm(xhat_post[..., 1:, :], dim=-1)\n",
    "    / torch.linalg.norm(xhat_post[..., :-1, :], dim=-1),\n",
    "    dim=0,\n",
    ")\n",
    "zpremag = torch.mean(\n",
    "    torch.linalg.norm(zhat_pre[..., 1:, :], dim=-1)\n",
    "    / torch.linalg.norm(zhat_pre[..., :-1, :], dim=-1),\n",
    "    dim=0,\n",
    ")\n",
    "zpstmag = torch.mean(\n",
    "    torch.linalg.norm(zhat_post[..., 1:, :], dim=-1)\n",
    "    / torch.linalg.norm(zhat_post[..., :-1, :], dim=-1),\n",
    "    dim=0,\n",
    ")\n",
    "\n",
    "system_mag = torch.linalg.norm(zhat_pre[:, 1:], dim=-1) / torch.linalg.norm(\n",
    "    zhat_post[:, :-1], dim=-1\n",
    ")\n",
    "system_mag = torch.cat([torch.ones(BATCH_DIM, 1), system_mag], dim=-1)\n",
    "combine_mag = torch.linalg.norm(zhat_post, dim=-1) / torch.linalg.norm(zhat_pre, dim=-1)\n",
    "# system_mag = torch.cat([torch.ones(BATCH_DIM, 1), system_mag], dim=-1)\n",
    "decoder_mag = gmean(xhat_pre, dim=-1) / gmean(zhat_pre, dim=-1)\n",
    "filter_mag = gmean(xhat_post, dim=-1) / gmean(xhat_pre, dim=-1)\n",
    "encoder_mag = gmean(zhat_post, dim=-1) / gmean(xhat_post, dim=-1)\n",
    "\n",
    "filter_mag = torch.mean(filter_mag, dim=0)\n",
    "system_mag = torch.mean(system_mag, dim=0)\n",
    "combine_mag = torch.mean(combine_mag, dim=0)\n",
    "decoder_mag = torch.mean(decoder_mag, dim=0)\n",
    "encoder_mag = torch.mean(encoder_mag, dim=0)\n",
    "\n",
    "fig, ax = plt.subplots(\n",
    "    ncols=4, nrows=3, figsize=(12, 8), sharey=\"row\", constrained_layout=True\n",
    ")\n",
    "\n",
    "ax[0, 0].semilogy(xpretotalmag)\n",
    "ax[0, 0].set_title(r\"Rel. Magnitude change $\\hat{x}_0  \\rightarrow \\hat{x}_{t+1}  $\")\n",
    "ax[0, 1].semilogy(xpsttotalmag)\n",
    "ax[0, 1].set_title(r\"Rel. Magnitude change $\\hat{x}_0' \\rightarrow \\hat{x}_{t+1}' $\")\n",
    "ax[0, 2].semilogy(zpretotalmag)\n",
    "ax[0, 2].set_title(r\"Rel. Magnitude change $\\hat{z}_0  \\rightarrow \\hat{z}_{t+1}  $\")\n",
    "ax[0, 3].semilogy(zpsttotalmag)\n",
    "ax[0, 3].set_title(r\"Rel. Magnitude change $\\hat{z}_0' \\rightarrow \\hat{z}_{t+1}' $\")\n",
    "\n",
    "ax[1, 0].semilogy(xpremag)\n",
    "ax[1, 0].set_title(r\"Rel. Magnitude change $\\hat{x}_t  \\rightarrow \\hat{x}_{t+1}  $\")\n",
    "ax[1, 1].semilogy(xpstmag)\n",
    "ax[1, 1].set_title(r\"Rel. Magnitude change $\\hat{x}_t' \\rightarrow \\hat{x}_{t+1}' $\")\n",
    "ax[1, 2].semilogy(zpremag)\n",
    "ax[1, 2].set_title(r\"Rel. Magnitude change $\\hat{z}_t  \\rightarrow \\hat{z}_{t+1}  $\")\n",
    "ax[1, 3].semilogy(zpstmag)\n",
    "ax[1, 3].set_title(r\"Rel. Magnitude change $\\hat{z}_t' \\rightarrow \\hat{z}_{t+1}' $\")\n",
    "\n",
    "ax[2, 0].semilogy(decoder_mag)\n",
    "ax[2, 0].set_title(r\"Rel. magnitude change $\\hat{z}_t  \\rightarrow \\hat{x}_t$\")\n",
    "ax[2, 1].semilogy(filter_mag)\n",
    "ax[2, 1].set_title(r\"Relative magnitude change $\\hat{x}_t  \\rightarrow \\hat{x}_t'$\")\n",
    "# ax[1, 2].semilogy(encoder_mag)\n",
    "# ax[1, 2].set_title(r\"Relative magnitude change $\\hat{x}_t' \\rightarrow \\hat{z}_t'$\")\n",
    "ax[2, 2].semilogy(encoder_mag)\n",
    "ax[2, 2].set_title(r\"Rel. magnitude change $\\hat{x}_t' \\rightarrow \\hat{z}_t'$\")\n",
    "ax[2, 3].semilogy(system_mag)\n",
    "ax[2, 3].set_title(r\"Rel. magnitude change $\\hat{x}_t' \\rightarrow \\hat{z}_t'$\")\n",
    "# ax[2, 3].semilogy(combine_mag)\n",
    "# ax[2, 3].set_title(r\"Rel. magnitude change $\\hat{z}_t \\rightarrow \\hat{z}_{t}'$\")\n",
    "# ax[2, 0].set_yscale(\"log\")\n",
    "fig.savefig(f\"{RUN_NAME}_encoder_stats_post_training.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a47ec8-e0b4-452f-bfae-af9ab14249dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2aa7207f-63e6-4b42-9222-dfe8fc4244ef",
   "metadata": {},
   "source": [
    "# distribution plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9f5e1f-0a3d-489b-aa2b-f22ece4a8e07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xhat_pre_mean = torch.mean(xhat_pre, dim=-1).mean(dim=0)\n",
    "xhat_pre_stdv = torch.std(xhat_pre, dim=-1).mean(dim=0)\n",
    "xhat_post_mean = torch.mean(xhat_post, dim=-1).mean(dim=0)\n",
    "xhat_post_stdv = torch.std(xhat_post, dim=-1).mean(dim=0)\n",
    "zhat_pre_mean = torch.mean(zhat_pre, dim=-1).mean(dim=0)\n",
    "zhat_pre_stdv = torch.std(zhat_pre, dim=-1).mean(dim=0)\n",
    "zhat_post_mean = torch.mean(zhat_post, dim=-1).mean(dim=0)\n",
    "zhat_post_stdv = torch.std(zhat_post, dim=-1).mean(dim=0)\n",
    "\n",
    "tuples = [\n",
    "    (r\"$\\hat{x}$\", xhat_pre_mean, xhat_pre_stdv),\n",
    "    (r\"$\\hat{x}'$\", xhat_post_mean, xhat_post_stdv),\n",
    "    (r\"$\\hat{z}$\", zhat_pre_mean, zhat_pre_stdv),\n",
    "    (r\"$\\hat{x}'$\", zhat_post_mean, zhat_post_stdv),\n",
    "]\n",
    "\n",
    "S = np.arange(len(xhat_pre_mean));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be405b1-c73e-4d69-a0e5-c8332da558e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(\n",
    "    nrows=2, ncols=2, constrained_layout=True, figsize=(8, 5), sharex=True, sharey=True\n",
    ")\n",
    "\n",
    "for ax, (key, mean, std) in zip(axes.flatten(), tuples):\n",
    "    color = next(ax._get_lines.prop_cycler)[\"color\"]\n",
    "    ax.plot(S, mean, color=color)\n",
    "    ax.fill_between(S, mean + std, mean - std, alpha=0.3)\n",
    "    ax.set_title(key)\n",
    "    ax.set_yscale(\"symlog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8169540-97c2-450a-80c4-28481ab643cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "xhat_pre[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1802cd-5aeb-444b-88bb-7308b979745c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xhat_pre[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5058d041-7d34-4424-88ac-a6dbe28e0a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xhat_pre[0, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4305323-0cd4-4d96-aa25-ad557e365dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "xhat_pre[0, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08e62ed-a0cf-43d5-993f-203f0c8f0154",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = torch.randn(10_000, m, device=\"cuda\")\n",
    "dummy2 = model.encoder(dummy)\n",
    "dummy1 = torch.linalg.norm(dummy, dim=-1) / m\n",
    "dummy2 = torch.linalg.norm(dummy2, dim=-1) / m\n",
    "chg = (dummy2 / dummy1).clone().detach().cpu().numpy()\n",
    "plt.hist(chg, bins=\"auto\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b58cd37-ce79-4fdd-9002-f263ea6edfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "expA = torch.matrix_exp(model.kernel)\n",
    "\n",
    "for o in (-np.infty, -2, -1, 1, 2, np.infty, \"fro\", \"nuc\"):\n",
    "    val = torch.linalg.matrix_norm(model.kernel, ord=o).item()\n",
    "    val2 = torch.linalg.matrix_norm(expA, ord=o).item()\n",
    "    o = str(o)\n",
    "    print(f\"{o=:6s}\\t {val=:10.6f} \\t {val2=:10.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00386475-06da-4385-a713-c8d8f37f3422",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "\n",
    "mat = model.kernel.clone().detach().cpu()\n",
    "mat = 0.5 + (mat - mat.mean()) / (6 * mat.std())\n",
    "# mat = kernel.clip(0, 1)\n",
    "colormap = cm.get_cmap(\"seismic\")\n",
    "mat = colormap(mat)\n",
    "plt.imshow(mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea7e528-85a7-416e-b7b9-5a7e979ab466",
   "metadata": {},
   "source": [
    "# Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ecaa8f-b919-4ff9-8373-5ac01694cbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.profiler import ProfilerActivity, profile, record_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c844c142-b28d-49eb-8271-9892968ce862",
   "metadata": {},
   "outputs": [],
   "source": [
    "with profile(\n",
    "    activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
    "    record_shapes=True,\n",
    "    profile_memory=True,\n",
    ") as prof:\n",
    "    model(times, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe31e70-550f-4cfd-b73e-3a026786a390",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa42321-19e6-4e2e-9722-02abfe93519e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001aa24d-ed1c-4af8-b50a-c9b94b14bcad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

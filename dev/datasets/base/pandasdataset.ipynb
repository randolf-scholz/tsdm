{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20191951-beec-414a-b3c6-89dca8277ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InteractiveShell.ast_node_interactivity='last_expr_or_assign'  # always print last expr.\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b7f6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from abc import ABC\n",
    "from collections.abc import Mapping, Sequence\n",
    "from hashlib import sha256\n",
    "from pathlib import Path\n",
    "from typing import Any, Optional, TypeAlias\n",
    "\n",
    "import pandas\n",
    "from pandas import DataFrame, Index, Series\n",
    "\n",
    "from tsdm.datasets.base import BaseDataset\n",
    "from tsdm.utils.types import KeyVar, Nested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e1c40c-f097-4cbe-83a2-cf9de2fb0aa7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tsdm\n",
    "\n",
    "ds = tsdm.datasets.KIWI_RUNS(initialize=False)\n",
    "ds.download_table.__doc__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d695b42b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PandasObject: TypeAlias = Index | Series | DataFrame\n",
    "DATASET_OBJECT: TypeAlias = Series | DataFrame\n",
    "r\"\"\"Type hint for pandas objects.\"\"\"\n",
    "\n",
    "\n",
    "class PandasDataset(BaseDataset, ABC, Mapping[KeyVar, PandasObject]):\n",
    "    r\"\"\"Base class for datasets that consist of multiple pandas objects.\n",
    "\n",
    "    - Each subclass must contain a dictionary `tables`, so that keys(), values(), etc.\n",
    "    point to this dictionary\n",
    "    - Each subclass optionally may behave like a dataclass, i.e. all tables are reachable\n",
    "    as lazily loaded properties.\n",
    "    - Each table should have a hash value stored that can be compared against when loading it.\n",
    "\n",
    "    -\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    DEFAULT_FILE_FORMAT: str = \"parquet\"\n",
    "    r\"\"\"Default format for the dataset.\"\"\"\n",
    "    RAWDATA_SHA256: Optional[str | Mapping[str, str]] = None\n",
    "    r\"\"\"SHA256 hash value of the raw data file(s).\"\"\"\n",
    "    RAWDATA_SHAPE: Optional[tuple[int, ...] | Mapping[str, tuple[int, ...]]] = None\n",
    "    r\"\"\"Reference shape of the raw data file(s).\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def serialize(frame: DATASET_OBJECT, path: Path, /, **kwargs: Any) -> None:\n",
    "        r\"\"\"Serialize the dataset.\"\"\"\n",
    "        file_type = path.suffix\n",
    "        assert file_type.startswith(\".\"), \"File must have a suffix!\"\n",
    "        file_type = file_type[1:]\n",
    "\n",
    "        if isinstance(frame, Series):\n",
    "            frame = frame.to_frame()\n",
    "\n",
    "        if hasattr(frame, f\"to_{file_type}\"):\n",
    "            pandas_writer = getattr(frame, f\"to_{file_type}\")\n",
    "            pandas_writer(path, **kwargs)\n",
    "            return\n",
    "\n",
    "        raise NotImplementedError(f\"No loader for {file_type=}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def deserialize(path: Path, /, *, squeeze: bool = True) -> DATASET_OBJECT:\n",
    "        r\"\"\"Deserialize the dataset.\"\"\"\n",
    "        file_type = path.suffix\n",
    "        assert file_type.startswith(\".\"), \"File must have a suffix!\"\n",
    "        file_type = file_type[1:]\n",
    "\n",
    "        if hasattr(pandas, f\"read_{file_type}\"):\n",
    "            pandas_loader = getattr(pandas, f\"read_{file_type}\")\n",
    "            pandas_object = pandas_loader(path)\n",
    "            return pandas_object.squeeze() if squeeze else pandas_object\n",
    "\n",
    "        raise NotImplementedError(f\"No loader for {file_type=}\")\n",
    "\n",
    "    def validate(\n",
    "        self,\n",
    "        filespec: Nested[str | Path],\n",
    "        /,\n",
    "        *,\n",
    "        reference: Optional[str | Mapping[str, str]] = None,\n",
    "    ) -> None:\n",
    "        r\"\"\"Validate the file hash.\"\"\"\n",
    "        self.LOGGER.debug(\"Starting to validate dataset\")\n",
    "\n",
    "        if isinstance(filespec, Mapping):\n",
    "            for value in filespec.values():\n",
    "                self.validate(value, reference=reference)\n",
    "            return\n",
    "        if isinstance(filespec, Sequence) and not isinstance(filespec, (str, Path)):\n",
    "            for value in filespec:\n",
    "                self.validate(value, reference=reference)\n",
    "            return\n",
    "\n",
    "        assert isinstance(filespec, (str, Path)), f\"{filespec=} wrong type!\"\n",
    "        file = Path(filespec)\n",
    "\n",
    "        if not file.exists():\n",
    "            raise FileNotFoundError(f\"File '{file.name}' does not exist!\")\n",
    "\n",
    "        filehash = sha256(file.read_bytes()).hexdigest()\n",
    "\n",
    "        if reference is None:\n",
    "            warnings.warn(\n",
    "                f\"File '{file.name}' cannot be validated as no hash is stored in\"\n",
    "                f\" {self.__class__}.The filehash is '{filehash}'.\"\n",
    "            )\n",
    "\n",
    "        elif isinstance(reference, str):\n",
    "            if filehash != reference:\n",
    "                warnings.warn(\n",
    "                    f\"File '{file.name}' failed to validate!\"\n",
    "                    f\"File hash '{filehash}' does not match reference '{reference}'.\"\n",
    "                    \"ğ—œğ—´ğ—»ğ—¼ğ—¿ğ—² ğ˜ğ—µğ—¶ğ˜€ ğ˜„ğ—®ğ—¿ğ—»ğ—¶ğ—»ğ—´ ğ—¶ğ—³ ğ˜ğ—µğ—² ğ—³ğ—¶ğ—¹ğ—² ğ—³ğ—¼ğ—¿ğ—ºğ—®ğ˜ ğ—¶ğ˜€ ğ—½ğ—®ğ—¿ğ—¾ğ˜‚ğ—²ğ˜.\"\n",
    "                )\n",
    "            self.LOGGER.info(\n",
    "                f\"File '{file.name}' validated successfully '{filehash=}'.\"\n",
    "            )\n",
    "\n",
    "        elif isinstance(reference, Mapping):\n",
    "            if not (file.name in reference) ^ (file.stem in reference):\n",
    "                warnings.warn(\n",
    "                    f\"File '{file.name}' cannot be validated as it is not contained in\"\n",
    "                    f\" {reference}.The filehash is '{filehash}'.ğ—œğ—´ğ—»ğ—¼ğ—¿ğ—² ğ˜ğ—µğ—¶ğ˜€ ğ˜„ğ—®ğ—¿ğ—»ğ—¶ğ—»ğ—´ ğ—¶ğ—³\"\n",
    "                    \" ğ˜ğ—µğ—² ğ—³ğ—¶ğ—¹ğ—² ğ—³ğ—¼ğ—¿ğ—ºğ—®ğ˜ ğ—¶ğ˜€ ğ—½ğ—®ğ—¿ğ—¾ğ˜‚ğ—²ğ˜.\"\n",
    "                )\n",
    "            elif file.name in reference and filehash != reference[file.name]:\n",
    "                warnings.warn(\n",
    "                    f\"File '{file.name}' failed to validate!File hash '{filehash}' does\"\n",
    "                    f\" not match reference '{reference[file.name]}'.ğ—œğ—´ğ—»ğ—¼ğ—¿ğ—² ğ˜ğ—µğ—¶ğ˜€ ğ˜„ğ—®ğ—¿ğ—»ğ—¶ğ—»ğ—´\"\n",
    "                    \" ğ—¶ğ—³ ğ˜ğ—µğ—² ğ—³ğ—¶ğ—¹ğ—² ğ—³ğ—¼ğ—¿ğ—ºğ—®ğ˜ ğ—¶ğ˜€ ğ—½ğ—®ğ—¿ğ—¾ğ˜‚ğ—²ğ˜.\"\n",
    "                )\n",
    "            elif file.stem in reference and filehash != reference[file.stem]:\n",
    "                warnings.warn(\n",
    "                    f\"File '{file.name}' failed to validate!File hash '{filehash}' does\"\n",
    "                    f\" not match reference '{reference[file.stem]}'.ğ—œğ—´ğ—»ğ—¼ğ—¿ğ—² ğ˜ğ—µğ—¶ğ˜€ ğ˜„ğ—®ğ—¿ğ—»ğ—¶ğ—»ğ—´\"\n",
    "                    \" ğ—¶ğ—³ ğ˜ğ—µğ—² ğ—³ğ—¶ğ—¹ğ—² ğ—³ğ—¼ğ—¿ğ—ºğ—®ğ˜ ğ—¶ğ˜€ ğ—½ğ—®ğ—¿ğ—¾ğ˜‚ğ—²ğ˜.\"\n",
    "                )\n",
    "            else:\n",
    "                self.LOGGER.info(\n",
    "                    f\"File '{file.name}' validated successfully '{filehash=}'.\"\n",
    "                )\n",
    "        else:\n",
    "            raise TypeError(f\"Unsupported type for {reference=}.\")\n",
    "\n",
    "        self.LOGGER.debug(\"Finished validating file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68681ae4-ad51-4760-bab7-ed27819f54ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tsdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180e9169-b2ec-468a-b021-069ebca038b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsdm.datasets.kiwi_runsKIWI_RUNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20eed8fa-5256-4fa0-aae4-7295dc08ae6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEYS = Literal[\"us_daily\", \"states\", \"stations\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d0d776-9f21-4298-a54e-7283580386b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEYS[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec232f5d-a0b2-478a-8a60-c5e5a20ecf08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20191951-beec-414a-b3c6-89dca8277ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InteractiveShell.ast_node_interactivity='last_expr_or_assign'  # always print last expr.\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b7f6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from abc import ABC\n",
    "from collections.abc import Mapping, Sequence\n",
    "from hashlib import sha256\n",
    "from pathlib import Path\n",
    "from typing import Any, Optional, TypeAlias\n",
    "\n",
    "import pandas\n",
    "from pandas import DataFrame, Index, Series\n",
    "\n",
    "from tsdm.datasets.base import BaseDataset\n",
    "from tsdm.utils.types import KeyVar, Nested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e1c40c-f097-4cbe-83a2-cf9de2fb0aa7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tsdm\n",
    "\n",
    "ds = tsdm.datasets.KIWI_RUNS(initialize=False)\n",
    "ds.download_table.__doc__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d695b42b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PandasObject: TypeAlias = Index | Series | DataFrame\n",
    "DATASET_OBJECT: TypeAlias = Series | DataFrame\n",
    "r\"\"\"Type hint for pandas objects.\"\"\"\n",
    "\n",
    "\n",
    "class PandasDataset(BaseDataset, ABC, Mapping[KeyVar, PandasObject]):\n",
    "    r\"\"\"Base class for datasets that consist of multiple pandas objects.\n",
    "\n",
    "    - Each subclass must contain a dictionary `tables`, so that keys(), values(), etc.\n",
    "    point to this dictionary\n",
    "    - Each subclass optionally may behave like a dataclass, i.e. all tables are reachable\n",
    "    as lazily loaded properties.\n",
    "    - Each table should have a hash value stored that can be compared against when loading it.\n",
    "\n",
    "    -\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    DEFAULT_FILE_FORMAT: str = \"parquet\"\n",
    "    r\"\"\"Default format for the dataset.\"\"\"\n",
    "    RAWDATA_SHA256: Optional[str | Mapping[str, str]] = None\n",
    "    r\"\"\"SHA256 hash value of the raw data file(s).\"\"\"\n",
    "    RAWDATA_SHAPE: Optional[tuple[int, ...] | Mapping[str, tuple[int, ...]]] = None\n",
    "    r\"\"\"Reference shape of the raw data file(s).\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def serialize(frame: DATASET_OBJECT, path: Path, /, **kwargs: Any) -> None:\n",
    "        r\"\"\"Serialize the dataset.\"\"\"\n",
    "        file_type = path.suffix\n",
    "        assert file_type.startswith(\".\"), \"File must have a suffix!\"\n",
    "        file_type = file_type[1:]\n",
    "\n",
    "        if isinstance(frame, Series):\n",
    "            frame = frame.to_frame()\n",
    "\n",
    "        if hasattr(frame, f\"to_{file_type}\"):\n",
    "            pandas_writer = getattr(frame, f\"to_{file_type}\")\n",
    "            pandas_writer(path, **kwargs)\n",
    "            return\n",
    "\n",
    "        raise NotImplementedError(f\"No loader for {file_type=}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def deserialize(path: Path, /, *, squeeze: bool = True) -> DATASET_OBJECT:\n",
    "        r\"\"\"Deserialize the dataset.\"\"\"\n",
    "        file_type = path.suffix\n",
    "        assert file_type.startswith(\".\"), \"File must have a suffix!\"\n",
    "        file_type = file_type[1:]\n",
    "\n",
    "        if hasattr(pandas, f\"read_{file_type}\"):\n",
    "            pandas_loader = getattr(pandas, f\"read_{file_type}\")\n",
    "            pandas_object = pandas_loader(path)\n",
    "            return pandas_object.squeeze() if squeeze else pandas_object\n",
    "\n",
    "        raise NotImplementedError(f\"No loader for {file_type=}\")\n",
    "\n",
    "    def validate(\n",
    "        self,\n",
    "        filespec: Nested[str | Path],\n",
    "        /,\n",
    "        *,\n",
    "        reference: Optional[str | Mapping[str, str]] = None,\n",
    "    ) -> None:\n",
    "        r\"\"\"Validate the file hash.\"\"\"\n",
    "        self.LOGGER.debug(\"Starting to validate dataset\")\n",
    "\n",
    "        if isinstance(filespec, Mapping):\n",
    "            for value in filespec.values():\n",
    "                self.validate(value, reference=reference)\n",
    "            return\n",
    "        if isinstance(filespec, Sequence) and not isinstance(filespec, (str, Path)):\n",
    "            for value in filespec:\n",
    "                self.validate(value, reference=reference)\n",
    "            return\n",
    "\n",
    "        assert isinstance(filespec, (str, Path)), f\"{filespec=} wrong type!\"\n",
    "        file = Path(filespec)\n",
    "\n",
    "        if not file.exists():\n",
    "            raise FileNotFoundError(f\"File '{file.name}' does not exist!\")\n",
    "\n",
    "        filehash = sha256(file.read_bytes()).hexdigest()\n",
    "\n",
    "        if reference is None:\n",
    "            warnings.warn(\n",
    "                f\"File '{file.name}' cannot be validated as no hash is stored in\"\n",
    "                f\" {self.__class__}.The filehash is '{filehash}'.\"\n",
    "            )\n",
    "\n",
    "        elif isinstance(reference, str):\n",
    "            if filehash != reference:\n",
    "                warnings.warn(\n",
    "                    f\"File '{file.name}' failed to validate!\"\n",
    "                    f\"File hash '{filehash}' does not match reference '{reference}'.\"\n",
    "                    \"𝗜𝗴𝗻𝗼𝗿𝗲 𝘁𝗵𝗶𝘀 𝘄𝗮𝗿𝗻𝗶𝗻𝗴 𝗶𝗳 𝘁𝗵𝗲 𝗳𝗶𝗹𝗲 𝗳𝗼𝗿𝗺𝗮𝘁 𝗶𝘀 𝗽𝗮𝗿𝗾𝘂𝗲𝘁.\"\n",
    "                )\n",
    "            self.LOGGER.info(\n",
    "                f\"File '{file.name}' validated successfully '{filehash=}'.\"\n",
    "            )\n",
    "\n",
    "        elif isinstance(reference, Mapping):\n",
    "            if not (file.name in reference) ^ (file.stem in reference):\n",
    "                warnings.warn(\n",
    "                    f\"File '{file.name}' cannot be validated as it is not contained in\"\n",
    "                    f\" {reference}.The filehash is '{filehash}'.𝗜𝗴𝗻𝗼𝗿𝗲 𝘁𝗵𝗶𝘀 𝘄𝗮𝗿𝗻𝗶𝗻𝗴 𝗶𝗳\"\n",
    "                    \" 𝘁𝗵𝗲 𝗳𝗶𝗹𝗲 𝗳𝗼𝗿𝗺𝗮𝘁 𝗶𝘀 𝗽𝗮𝗿𝗾𝘂𝗲𝘁.\"\n",
    "                )\n",
    "            elif file.name in reference and filehash != reference[file.name]:\n",
    "                warnings.warn(\n",
    "                    f\"File '{file.name}' failed to validate!File hash '{filehash}' does\"\n",
    "                    f\" not match reference '{reference[file.name]}'.𝗜𝗴𝗻𝗼𝗿𝗲 𝘁𝗵𝗶𝘀 𝘄𝗮𝗿𝗻𝗶𝗻𝗴\"\n",
    "                    \" 𝗶𝗳 𝘁𝗵𝗲 𝗳𝗶𝗹𝗲 𝗳𝗼𝗿𝗺𝗮𝘁 𝗶𝘀 𝗽𝗮𝗿𝗾𝘂𝗲𝘁.\"\n",
    "                )\n",
    "            elif file.stem in reference and filehash != reference[file.stem]:\n",
    "                warnings.warn(\n",
    "                    f\"File '{file.name}' failed to validate!File hash '{filehash}' does\"\n",
    "                    f\" not match reference '{reference[file.stem]}'.𝗜𝗴𝗻𝗼𝗿𝗲 𝘁𝗵𝗶𝘀 𝘄𝗮𝗿𝗻𝗶𝗻𝗴\"\n",
    "                    \" 𝗶𝗳 𝘁𝗵𝗲 𝗳𝗶𝗹𝗲 𝗳𝗼𝗿𝗺𝗮𝘁 𝗶𝘀 𝗽𝗮𝗿𝗾𝘂𝗲𝘁.\"\n",
    "                )\n",
    "            else:\n",
    "                self.LOGGER.info(\n",
    "                    f\"File '{file.name}' validated successfully '{filehash=}'.\"\n",
    "                )\n",
    "        else:\n",
    "            raise TypeError(f\"Unsupported type for {reference=}.\")\n",
    "\n",
    "        self.LOGGER.debug(\"Finished validating file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68681ae4-ad51-4760-bab7-ed27819f54ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tsdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180e9169-b2ec-468a-b021-069ebca038b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsdm.datasets.kiwi_runsKIWI_RUNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20eed8fa-5256-4fa0-aae4-7295dc08ae6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEYS = Literal[\"us_daily\", \"states\", \"stations\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d0d776-9f21-4298-a54e-7283580386b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEYS[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec232f5d-a0b2-478a-8a60-c5e5a20ecf08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef3d9ae-4b74-4b55-88d4-522b7b6793d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%config InteractiveShell.ast_node_interactivity='last_expr_or_assign'\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "import tsdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e597be6-6f0a-49f4-8636-59797821ad9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsdm.datasets.MIMIC_IV(version=2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102876c2-a80e-434d-891f-b73c0b0f8c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import subprocess\n",
    "from collections.abc import Mapping\n",
    "from io import IOBase\n",
    "from pathlib import Path\n",
    "from typing import Any, Optional\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "import requests\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "from tsdm.constants import EMPTY_MAP\n",
    "from tsdm.types.aliases import PathLike\n",
    "from tsdm.utils.hash import validate_file_hash\n",
    "\n",
    "\n",
    "def download_io(\n",
    "    file: IOBase,\n",
    "    url: str,\n",
    "    *,\n",
    "    session,\n",
    "    chunk_size: int = 1024,\n",
    ") -> None:\n",
    "    \"\"\"Download a file from a URL to an IO stream.\"\"\"\n",
    "    response = session.get(url)  # type: ignore[arg-type]\n",
    "\n",
    "    with tqdm(\n",
    "        desc=f\"Downloading {url}\",\n",
    "        total=int(response.headers.get(\"content-length\", 0)),\n",
    "        unit=\"iB\",\n",
    "        unit_scale=True,\n",
    "        unit_divisor=1024,\n",
    "    ) as progress_bar:\n",
    "        for data in response.iter_content(chunk_size=chunk_size):\n",
    "            if data:  # filter out keep-alive new chunks\n",
    "                print(type(data), data)\n",
    "                size = file.write(data)\n",
    "                progress_bar.update(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989961fb-590c-4a20-a48f-870443998d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from requests.auth import HTTPBasicAuth\n",
    "\n",
    "# Define the base URL and authentication credentials\n",
    "base_url = \"https://physionet.org/files/mimiciv/2.0/\"\n",
    "username = getuser()\n",
    "password = getpass()\n",
    "headers = {\"User-Agent\": \"Wget/1.21.2\"}\n",
    "\n",
    "response = requests.get(\n",
    "    base_url, auth=HTTPBasicAuth(username, password), headers=headers\n",
    ")\n",
    "assert response.status_code == 200, f\"Reponse is {response.status_code}\"\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54869f09-a82a-4048-a2a7-8069c9f98931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to download all files in a directory recursively and store in a single zip file\n",
    "def download_directory_to_zip(url, zip_filename, session=None):\n",
    "    if session is None:\n",
    "        session = requests.Session()\n",
    "        session.auth = (username, password)\n",
    "        session.headers.update(headers)\n",
    "\n",
    "    response = session.get(url)\n",
    "    assert response.status_code == 200, f\"Reponse is {response.status_code}\"\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    print([link.get(\"href\") for link in soup.find_all(\"a\")])\n",
    "\n",
    "    with ZipFile(zip_filename, \"w\", compression=zipfile.ZIP_DEFLATED) as archive:\n",
    "        for link in (pbar := tqdm(soup.find_all(\"a\"), desc=f\"Download from {url}\")):\n",
    "            href = link.get(\"href\")\n",
    "            pbar.set_postfix(href=href)\n",
    "            if href == \"../\":\n",
    "                continue\n",
    "            if href.endswith(\"/\"):\n",
    "                # Recursively download sub-directories\n",
    "                sub_url = url + href\n",
    "                download_directory_to_zip(sub_url, zip_filename, session=session)\n",
    "            else:\n",
    "                # Download non-directory files into the zip file\n",
    "                file_url = url + href\n",
    "                file_name = os.path.basename(href)\n",
    "                with archive.open(file_name, \"w\") as file:\n",
    "                    download_io(file, file_url, session=session)\n",
    "\n",
    "\n",
    "zip_filename = \"mimiciv_2.0.zip\"\n",
    "download_directory_to_zip(base_url, zip_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdf6a67-4840-45f8-bccc-87a21c77ae80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f664aa63-ed9a-4940-a6be-b4d8febc69f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_io(\n",
    "    url: str,\n",
    "    file: IOBase,\n",
    "    *,\n",
    "    session: Optional[Session] = None,\n",
    "    username: Optional[str] = None,\n",
    "    password: Optional[str] = None,\n",
    "    headers: Mapping[str, str] = EMPTY_MAP,\n",
    "    request_options: Mapping[str, Any] = EMPTY_MAP,\n",
    "    chunk_size: int = 1024,\n",
    ") -> None:\n",
    "    \"\"\"Download a file from a URL to an IO stream.\"\"\"\n",
    "    if session is None:\n",
    "        # construct the request\n",
    "        request_options = {\n",
    "            \"headers\": headers,\n",
    "            \"auth\": None if username is None else (username, password),\n",
    "            \"stream\": True,\n",
    "            \"timeout\": 10,\n",
    "        } | request_options\n",
    "        response = requests.get(url, **request_options)  # type: ignore[arg-type]\n",
    "    else:\n",
    "        response = session.get(url)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        raise RuntimeError(\n",
    "            f\"Failed to download {url} with status code {response.status_code}.\"\n",
    "        )\n",
    "\n",
    "    with tqdm(\n",
    "        desc=f\"Downloading {url}\",\n",
    "        total=int(response.headers.get(\"content-length\", 0)),\n",
    "        unit=\"iB\",\n",
    "        unit_scale=True,\n",
    "        unit_divisor=1024,\n",
    "        leave=False,\n",
    "    ) as progress_bar:\n",
    "        for data in response.iter_content(chunk_size=chunk_size):\n",
    "            if data:  # filter out keep-alive new chunks\n",
    "                progress_bar.update(chunk_size)\n",
    "                file.write(data)\n",
    "\n",
    "\n",
    "def stream_download(\n",
    "    url: str,\n",
    "    *,\n",
    "    session: Optional[Session] = None,\n",
    "    username: Optional[str] = None,\n",
    "    password: Optional[str] = None,\n",
    "    headers: Mapping[str, str] = EMPTY_MAP,\n",
    "    request_options: Mapping[str, Any] = EMPTY_MAP,\n",
    "    chunk_size: int = 1024,\n",
    ") -> Iterator[bytes]:\n",
    "    \"\"\"Download a file as a bytes-stream.\"\"\"\n",
    "    if session is None:\n",
    "        # construct the request\n",
    "        request_options = {\n",
    "            \"headers\": headers,\n",
    "            \"auth\": None if username is None else (username, password),\n",
    "            \"stream\": True,\n",
    "            \"timeout\": 10,\n",
    "        } | request_options\n",
    "        response = requests.get(url, **request_options)  # type: ignore[arg-type]\n",
    "    else:\n",
    "        response = session.get(url)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        raise RuntimeError(\n",
    "            f\"Failed to download {url} with status code {response.status_code}.\"\n",
    "        )\n",
    "    with tqdm(\n",
    "        desc=f\"Downloading {url}\",\n",
    "        total=int(response.headers.get(\"content-length\", 0)),\n",
    "        unit=\"iB\",\n",
    "        unit_scale=True,\n",
    "        unit_divisor=1024,\n",
    "        leave=False,\n",
    "    ) as progress_bar:\n",
    "        for data in response.iter_content(chunk_size=chunk_size):\n",
    "            if data:  # filter out keep-alive new chunks\n",
    "                progress_bar.update(chunk_size)\n",
    "                yield data\n",
    "\n",
    "\n",
    "from typing import Iterator\n",
    "from html.parser import HTMLParser\n",
    "from requests import Session\n",
    "\n",
    "\n",
    "class LinkParser(HTMLParser):\n",
    "    def __init__(self, url, session):\n",
    "        super().__init__()\n",
    "        self.url = url\n",
    "        self.session = session\n",
    "        self.links = []\n",
    "\n",
    "    def handle_starttag(self, tag, attrs):\n",
    "        if tag == \"a\":\n",
    "            for name, value in attrs:\n",
    "                if name == \"href\":\n",
    "                    self.links.append(value)\n",
    "\n",
    "\n",
    "def iter_content(url: str, /, *, session: Session) -> Iterator[str]:\n",
    "    \"\"\"Iterate over the contents of a directory.\"\"\"\n",
    "    response = session.get(url)\n",
    "    if response.status_code != 200:\n",
    "        raise RuntimeError(\n",
    "            f\"Failed to download {url} with status code {response.status_code}.\"\n",
    "        )\n",
    "\n",
    "    parser = LinkParser(url, session)\n",
    "    parser.feed(response.text)\n",
    "\n",
    "    for link in parser.links:\n",
    "        if link == \"../\":\n",
    "            continue\n",
    "        elif link.endswith(\"/\"):\n",
    "            # Recursion\n",
    "            yield from iter_content(url + link, session=session)\n",
    "        else:\n",
    "            # Download non-directory files into the zip file\n",
    "            yield url + link\n",
    "\n",
    "\n",
    "# NOTE: Session options as of requests 2.26.0\n",
    "# __attrs__ = [\n",
    "#     \"headers\",\n",
    "#     \"cookies\",\n",
    "#     \"auth\",\n",
    "#     \"proxies\",\n",
    "#     \"hooks\",\n",
    "#     \"params\",\n",
    "#     \"verify\",\n",
    "#     \"cert\",\n",
    "#     \"adapters\",\n",
    "#     \"stream\",\n",
    "#     \"trust_env\",\n",
    "#     \"max_redirects\",\n",
    "# ]\n",
    "def download_directory_to_zip(\n",
    "    url: str,\n",
    "    zip_filename: PathLike,\n",
    "    *,\n",
    "    # session options\n",
    "    username: Optional[str] = None,\n",
    "    password: Optional[str] = None,\n",
    "    headers: Mapping[str, str] = EMPTY_MAP,\n",
    "    stream: bool = True,\n",
    ") -> None:\n",
    "    \"\"\"Download a directory from a URL to a zip file.\"\"\"\n",
    "    with Session() as session:\n",
    "        session.auth = (username, password) if username is not None else None\n",
    "        session.headers = headers\n",
    "        session.stream = stream\n",
    "\n",
    "        response = session.get(url)\n",
    "        if response.status_code != 200:\n",
    "            raise RuntimeError(\n",
    "                f\"Failed to create session for {url} with status code\"\n",
    "                f\" {response.status_code}.\"\n",
    "            )\n",
    "\n",
    "        # Get the contents of the directory\n",
    "        content = sorted(iter_content(url, session=session))\n",
    "        print(content)\n",
    "        # Download the directory\n",
    "        with ZipFile(zip_filename, \"w\", compression=ZIP_DEFLATED) as archive:\n",
    "            for href in (pbar := tqdm(content)):\n",
    "                # get relative path w.r.t. the base url\n",
    "                file_name = os.path.relpath(href, url)\n",
    "                pbar.set_description(f\"Downloading {file_name}\")\n",
    "                with archive.open(file_name, \"w\") as file:\n",
    "                    download_io(href, file, session=session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad9596f-2bfc-4d6c-93eb-c25863d3fb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://physionet.org/files/mimiciv/2.0/\"\n",
    "username = getuser()\n",
    "password = getpass()\n",
    "headers = {\"User-Agent\": \"Wget/1.21.2\"}\n",
    "zip_filename = \"mimic_iv_2.0.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a881cd-888e-4af5-a7a0-b50fe28af438",
   "metadata": {},
   "outputs": [],
   "source": [
    "href = \"https://physionet.org/files/mimiciv/2.0/hosp/admissions.csv.gz\"\n",
    "os.path.basename(href)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71970cb0-abf8-4867-85c6-7d3019582830",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_directory_to_zip(\n",
    "    base_url, zip_filename, username=username, password=password, headers=headers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15029d0-3b63-487c-94ee-cfddaef09bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01527800-2b76-44d3-a475-b1e887d82d1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841fd4a6-fd7f-40ad-a43a-286169315cb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcbdef4-ac0c-403b-8cc2-64a62104120c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7208b82a-ba23-420f-82d0-5992f47edc8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e52e3f7-e816-45f4-af4e-6b5d1e3ec414",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb52d451-c952-4a27-882a-2e8b34149746",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689c64e8-9c81-4e52-a42e-da5e46ec5f36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efef5528-c033-4100-966e-548a1c21589a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbfcd2a-ddb0-4551-80e0-888b68d6858d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf828da-067d-421f-b42c-7eb75d5bf092",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "import tsdm\n",
    "from tsdm.utils.remote import download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8994b08-1282-4cc8-a327-a0628b1edad6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds = tsdm.datasets.MIMIC_III(initialize=False, version=\"1.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20e1621-e499-49d8-8ab9-6610887837ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144779dd-d237-463e-a208-e8d4eb9b711a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds.HOME_URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc83f70a-7bb6-4e48-b542-23f78ef3de77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tuple(map(int, \"1.3\".split(\".\"))) <= (1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e07e93-34ad-40fa-98ae-0bd01e588066",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb39e36-5caf-48eb-b9d8-47068c2e6c22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = Literal[\"a\", \"b\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ba648b-3ab5-4010-8ffc-9719af776757",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import get_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5febc86e-7b8f-4255-8c54-c6af4fcaee37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_args(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd058aee-12d9-47e8-86d3-943f58f0859f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "url = ds.BASE_URL.format(version=\"1.4\")\n",
    "fname = \"mimic-iii-clinical-database-1.4.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022ffd7c-ad33-46c4-b9c7-f81596653802",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "username = input(\"MIMIC-III username: \")\n",
    "password = getpass(prompt=\"MIMIC-III password: \", stream=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7af035-3861-48c2-8bd0-4e0ac336315b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d19ae4-ac29-4c6e-8b6a-6b390e5c9717",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "headers = {\n",
    "    \"User-Agent\": \"Wget/1.21.2\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d7912b-c473-4478-a96a-39e5636f6b33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "download(url, fname, headers=headers, username=username, password=password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f5f7f2-0d6e-4a64-80a9-787be98bf761",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6440129-0f39-449f-8c61-00b970031ab2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49457e31-971e-4f77-96a0-f668c6073b71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "self = MIMIC_III_DeBrouwer2019()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5accd19e-2526-486d-b18f-01a7d44fc8f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x: [1, 2] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131bddcc-cab7-4fed-8d93-746891c88767",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"0\".isidentifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47887f5-0ef1-4f64-bb87-291ec0f8c79b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(16, 6, figsize=(20, 32), constrained_layout=True, sharey=True)\n",
    "\n",
    "for col, ax in zip(self.timeseries, axes.flatten()):\n",
    "    self.timeseries[col].hist(ax=ax, density=True, log=True, bins=20)\n",
    "    ax.set_ylim(10**-6, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12deea56-4c88-43c7-b6cf-362a5fced9ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "(self.metadata[\"min\"] == 0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc87dcd5-55c9-46d7-8ae8-bd4c9c365611",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b75963e-1b6b-4105-86f4-0921415e7e2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "self.LOGGER.info(\"Loading main file.\")\n",
    "ts = pd.read_csv(self.rawdata_paths[\"complete_tensor.csv\"], index_col=0)\n",
    "\n",
    "# Check shape.\n",
    "if ts.shape != self.rawdata_shapes[\"complete_tensor.csv\"]:\n",
    "    raise ValueError(\n",
    "        f\"The {ts.shape=} is not correct.\"\n",
    "        \"Please apply the modified preprocessing using bin_k=2, as outlined in\"\n",
    "        \"the appendix. The resulting tensor should have 3082224 rows and 7 columns.\"\n",
    "    )\n",
    "\n",
    "ts = ts.astype(self.rawdata_schemas[\"complete_tensor.csv\"]).sort_values(\n",
    "    by=[\"UNIQUE_ID\", \"TIME_STAMP\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f19fe33-a405-4d6e-8a3d-b494045208eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "means = ts.groupby(\"LABEL_CODE\").mean()[\"VALUENUM\"].rename(\"MEANS\")\n",
    "stdvs = ts.groupby(\"LABEL_CODE\").std()[\"VALUENUM\"].rename(\"STDVS\")\n",
    "stats = (\n",
    "    DataFrame([means, stdvs])\n",
    "    .T.reset_index()\n",
    "    .astype(\n",
    "        {\n",
    "            \"LABEL_CODE\": \"int16\",\n",
    "            \"MEANS\": \"float32\",\n",
    "            \"STDVS\": \"float32\",\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fd4f28-e474-4392-9acd-1624b06b7a12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ts = (\n",
    "    ts[[\"UNIQUE_ID\", \"TIME_STAMP\", \"LABEL_CODE\", \"VALUENUM\"]]\n",
    "    .reset_index(drop=True)\n",
    "    .set_index([\"UNIQUE_ID\", \"TIME_STAMP\"])\n",
    "    .pivot(columns=\"LABEL_CODE\", values=\"VALUENUM\")\n",
    "    .sort_index()\n",
    "    .sort_index(axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35805c3-992f-48c3-bd47-a0f298ac80d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ts.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89826bca-b90c-44ad-878f-79931b46f7f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ts.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa070ba9-0aad-4c1e-9451-0545dffa889a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

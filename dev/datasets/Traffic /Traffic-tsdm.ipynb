{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "644fc9a2-7b35-483d-860e-d1e77185c197",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Traffic Dataset\n",
    "\n",
    "There are two files for each fold, the data file and the labels file. We have split the 440 time series between train and test folds, but you are of course free to merge them to consider a different cross validation setting.\n",
    "- The PEMS_train textfile has 263 lines. Each line describes a time-series provided as a matrix. The matrix syntax is that of Matlab, e.g. [ a b ; c d] is the matrix with row vectors [a b] and [c d] in that order. Each matrix describes the different occupancies rates (963 lines, one for each station/detector) sampled every 10 minutes during the day (144 columns).\n",
    "- The PEMS_trainlabel text describes, for each day of measurements described above, the day of the week on which the data was sampled, namely an integer between 1 (Mon.) and 7 (Sun.).\n",
    "\n",
    "- PEMS_test and PEMS_testlabels are formatted in the same way, except that there are 173 test instances.\n",
    "\n",
    "- The permutation that I used to shuffle the dataset is given in the randperm file. If you need to rearrange the data so that it follows the calendar order, you should merge train and test samples and reorder them using the inverse permutation of randperm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ad4886-bf56-4f02-83f8-e949b5a12e6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%config InteractiveShell.ast_node_interactivity='last_expr_or_assign'  # always print last expr.\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e22b6e-7e7c-436a-8b70-828745d0ead8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "\n",
    "from tsdm.datasets import Traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89c7343-aff5-4aba-93e3-526b44c7b70d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "self = Traffic(initialize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf26b13-a484-43e6-97af-9940bf30e03d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "self.timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87a7a4e-e9c8-4ea9-a839-8da3f0386849",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "\n",
    "class Foo(ABC):\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def foo(self) -> int:\n",
    "        return 0\n",
    "\n",
    "\n",
    "class Bar(Foo):\n",
    "    foo = 1  # mypy ignores this complain!\n",
    "\n",
    "\n",
    "obj = Bar()\n",
    "obj.foo = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0760d1b-bbea-44cc-82b0-3326784417f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Traffic(initialize=False).weekdays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89788cd8-3102-48b4-9e50-c33a5ccba9d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Traffic.dates.__get__(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c801061-cce1-4988-9a72-913bc48ea6b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92ae914-8db6-4bb4-9b81-a1eae6c09df3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "false_dates = pd.date_range(\"2008-01-01\", \"2009-03-30\", freq=\"d\", name=\"day\")\n",
    "false_anomalies = pd.DatetimeIndex({\n",
    "    \"Jan. 1, 2008\": \"New Year’s Day\",\n",
    "    \"Jan. 21, 2008\": \"Martin Luther King Jr. Day\",\n",
    "    \"Feb. 18, 2008\": \"Washington’s Birthday\",\n",
    "    \"Mar. 9, 2008\": \"Anomaly day\",\n",
    "    \"May 26, 2008\": \"Memorial Day\",\n",
    "    \"Jul. 4, 2008\": \"Independence Day\",\n",
    "    \"Sep. 1, 2008\": \"Labor Day\",\n",
    "    \"Oct. 13, 2008\": \"Columbus Day\",\n",
    "    \"Nov. 11, 2008\": \"Veterans Day\",\n",
    "    \"Nov. 27, 2008\": \"Thanksgiving\",\n",
    "    \"Dec. 25, 2008\": \"Christmas Day\",\n",
    "    \"Jan. 1, 2009\": \"New Year’s Day\",\n",
    "    \"Jan. 19, 2009\": \"Martin Luther King Jr. Day\",\n",
    "    \"Feb. 16, 2009\": \"Washington’s Birthday\",\n",
    "    \"Mar. 8, 2009\": \"Anomaly day\",\n",
    "})\n",
    "false_weekdays = {\n",
    "    \"1\": \"Sunday\",\n",
    "    \"2\": \"Monday\",\n",
    "    \"3\": \"Tuesday\",\n",
    "    \"4\": \"Wednesday\",\n",
    "    \"5\": \"Thursday\",\n",
    "    \"6\": \"Friday\",\n",
    "    \"7\": \"Saturday\",\n",
    "}\n",
    "use_corrected_dates = False\n",
    "dates = true_dates if use_corrected_dates else false_dates\n",
    "anomalies = true_anomalies if use_corrected_dates else false_anomalies\n",
    "weekdays = true_weekdays if use_corrected_dates else false_weekdays\n",
    "\n",
    "# remove anomalies\n",
    "mask = dates.isin(anomalies)\n",
    "assert sum(mask) == len(anomalies)\n",
    "dates = dates[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170faa35-9fb8-4edc-b868-1f451b2da6c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.timedelta_range(\"0:00:00\", \"23:59:59\", freq=\"10min\", name=\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ee72fa-313a-4bb0-a512-198fb03f57bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d388fe3d-4880-45c5-b796-a9169a720329",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "use_corrected_dates = True\n",
    "\n",
    "true_dates = pd.date_range(\"2008-01-01\", \"2009-03-26\", freq=\"d\", name=\"day\")\n",
    "true_anomalies = pd.DatetimeIndex({\n",
    "    \"2008-01-01\": \"New Year’s Day\",\n",
    "    \"2008-01-21\": \"Martin Luther King Jr. Day\",\n",
    "    \"2008-02-18\": \"Washington’s Birthday\",\n",
    "    \"2008-03-09\": \"anomaly\",\n",
    "    \"2008-05-26\": \"Memorial Day\",\n",
    "    \"2008-07-04\": \"Independence Day\",\n",
    "    \"2008-09-01\": \"Labor Day\",\n",
    "    \"2008-10-20\": \"???\",\n",
    "    \"2008-11-17\": \"???\",\n",
    "    \"2008-12-07\": \"???\",\n",
    "    \"2009-02-23\": \"???\",\n",
    "    # \"2009-03-08\": \"anomaly\",\n",
    "})\n",
    "true_weekdays = {\n",
    "    1: \"Sunday\",\n",
    "    2: \"Monday\",\n",
    "    3: \"Tuesday\",\n",
    "    4: \"Wednesday\",\n",
    "    5: \"Thursday\",\n",
    "    6: \"Friday\",\n",
    "    7: \"Saturday\",\n",
    "}\n",
    "\n",
    "false_dates = pd.date_range(\"2008-01-01\", \"2009-03-30\", freq=\"d\", name=\"day\")\n",
    "false_anomalies = pd.DatetimeIndex({\n",
    "    \"Jan. 1, 2008\": \"New Year’s Day\",\n",
    "    \"Jan. 21, 2008\": \"Martin Luther King Jr. Day\",\n",
    "    \"Feb. 18, 2008\": \"Washington’s Birthday\",\n",
    "    \"Mar. 9, 2008\": \"Anomaly day\",\n",
    "    \"May 26, 2008\": \"Memorial Day\",\n",
    "    \"Jul. 4, 2008\": \"Independence Day\",\n",
    "    \"Sep. 1, 2008\": \"Labor Day\",\n",
    "    \"Oct. 13, 2008\": \"Columbus Day\",\n",
    "    \"Nov. 11, 2008\": \"Veterans Day\",\n",
    "    \"Nov. 27, 2008\": \"Thanksgiving\",\n",
    "    \"Dec. 25, 2008\": \"Christmas Day\",\n",
    "    \"Jan. 1, 2009\": \"New Year’s Day\",\n",
    "    \"Jan. 19, 2009\": \"Martin Luther King Jr. Day\",\n",
    "    \"Feb. 16, 2009\": \"Washington’s Birthday\",\n",
    "    \"Mar. 8, 2009\": \"Anomaly day\",\n",
    "})\n",
    "false_weekdays = {\n",
    "    1: \"Monday\",\n",
    "    2: \"Tuesday\",\n",
    "    3: \"Wednesday\",\n",
    "    4: \"Thursday\",\n",
    "    5: \"Friday\",\n",
    "    6: \"Saturday\",\n",
    "    7: \"Sunday\",\n",
    "}\n",
    "\n",
    "dates = true_dates if use_corrected_dates else false_dates\n",
    "anomalies = true_anomalies if use_corrected_dates else false_anomalies\n",
    "weekdays = true_weekdays if use_corrected_dates else false_weekdays\n",
    "\n",
    "# remove anomalies\n",
    "dates = dates[~dates.isin(anomalies)]\n",
    "\n",
    "# Shuffle dates according to permutation the authors applied\n",
    "shuffled_dates = dates[self.randperm]\n",
    "\n",
    "timestamps = pd.timedelta_range(\"0:00:00\", \"23:59:59\", freq=\"10min\", name=\"time\")\n",
    "assert len(timestamps) == 144\n",
    "\n",
    "with ZipFile(self.rawdata_paths[\"PEMS-SF.zip\"]) as archive:\n",
    "    with archive.open(\"stations_list\") as file:\n",
    "        content = file.read().decode(\"utf8\")\n",
    "        content = _reformat(content, {\"[\": \"\", \"]\": \"\", \" \": \"\\n\"})\n",
    "        stations = pd.read_csv(\n",
    "            StringIO(content), names=[\"station\"], dtype=\"category\"\n",
    "        ).squeeze()\n",
    "\n",
    "    with archive.open(\"PEMS_trainlabels\") as file:\n",
    "        content = file.read().decode(\"utf8\")\n",
    "        content = _reformat(content, {\"[\": \"\", \"]\": \"\\n\", \" \": \"\\n\"})\n",
    "        trainlabels = pd.read_csv(\n",
    "            StringIO(content), names=[\"label\"], dtype=\"uint8\"\n",
    "        ).squeeze()\n",
    "        train_dates = shuffled_dates[: len(trainlabels)]\n",
    "        trainlabels.index = train_dates\n",
    "    # Check that the labels match with the actual weekdays\n",
    "    assert all(\n",
    "        trainlabels.index.day_name() == trainlabels.map(weekdays)\n",
    "    ), \"Labels do not match with dates!\"\n",
    "\n",
    "    with archive.open(\"PEMS_testlabels\") as file:\n",
    "        content = file.read().decode(\"utf8\")\n",
    "        content = _reformat(content, {\"[\": \"\", \"]\": \"\", \" \": \"\\n\"})\n",
    "        testlabels = pd.read_csv(\n",
    "            StringIO(content), names=[\"label\"], dtype=\"uint8\"\n",
    "        ).squeeze()\n",
    "        test_dates = shuffled_dates[len(trainlabels) :]\n",
    "        testlabels.index = test_dates\n",
    "\n",
    "    # Check that the labels match with the actual weekdays\n",
    "    assert all(\n",
    "        testlabels.index.day_name() == testlabels.map(weekdays)\n",
    "    ), \"Labels do not match with dates!\"\n",
    "    assert (\n",
    "        trainlabels.dtype == testlabels.dtype\n",
    "    ), \"Train and test have different labels!\"\n",
    "\n",
    "    with archive.open(\"PEMS_train\") as file:\n",
    "        _PEMS_train = []\n",
    "        for line in file:\n",
    "            content = line.decode(\"utf8\")\n",
    "            content = _reformat(content, {\"[\": \"\", \"]\": \"\", \";\": \"\\n\", \" \": \",\"})\n",
    "            df = pd.read_csv(StringIO(content), header=None).squeeze()\n",
    "            df = DataFrame(df.values, index=stations, columns=timestamps)\n",
    "            _PEMS_train.append(df.T)\n",
    "        PEMS_train = pd.concat(_PEMS_train, keys=train_dates)\n",
    "\n",
    "    with archive.open(\"PEMS_test\") as file:\n",
    "        _PEMS_test = []\n",
    "        for line in file:\n",
    "            content = line.decode(\"utf8\")\n",
    "            content = _reformat(content, {\"[\": \"\", \"]\": \"\", \";\": \"\\n\", \" \": \",\"})\n",
    "            df = pd.read_csv(StringIO(content), header=None).squeeze()\n",
    "            df = DataFrame(df.values, index=stations, columns=timestamps)\n",
    "            _PEMS_test.append(df.T)\n",
    "        PEMS_test = pd.concat(_PEMS_test, keys=test_dates)\n",
    "\n",
    "PEMS = pd.concat([PEMS_train, PEMS_test]).reset_index()\n",
    "labels = pd.concat([trainlabels, testlabels]).rename(\"labels\")\n",
    "\n",
    "mismatches = labels[self.invperm].map(weekdays) != dates.day_name()\n",
    "assert len(dates[mismatches]) == 0, \"Mismatches in label and date weekday!\"\n",
    "\n",
    "PEMS = (\n",
    "    PEMS.assign(time=PEMS[\"day\"] + PEMS[\"time\"])\n",
    "    .drop(columns=\"day\")\n",
    "    .set_index(\"time\")\n",
    "    .astype(\"float32\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b42644-1260-41a4-bbff-afa3a7f6c87b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PEMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5dd88b-6ca2-4c19-a523-f08f5ea8c4bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da8708e-9525-4414-879f-d38fb5acc561",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainlabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2635379b-1610-4f15-8d04-6dd6edffa949",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f9cafc-404f-4276-b6b2-8a92a7092bc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dates.to_series().loc[\"2009-03\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3562c41-6141-47f5-88a7-ee6498e98846",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9c4af5-3865-42ca-9219-8b7c7a531689",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _reformat(s: str, replacements: dict) -> str:\n",
    "    r\"\"\"Replace multiple substrings via dict.\n",
    "\n",
    "    https://stackoverflow.com/a/64500851/9318372\n",
    "    \"\"\"\n",
    "    *_, result = (s := s.replace(c, r) for c, r in replacements.items())  # noqa: F841\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e6cf4c-110f-44ba-a8ab-d6e00230fd36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "timestamps = pd.timedelta_range(\"0:00:00\", \"23:59:59\", freq=\"10min\", name=\"time\")\n",
    "\n",
    "with ZipFile(self.rawdata_paths[\"PEMS-SF.zip\"]) as archive:\n",
    "    with archive.open(\"PEMS_train\") as file:\n",
    "        _PEMS_train = []\n",
    "        for line in file:\n",
    "            content = line.decode(\"utf8\")\n",
    "            content = _reformat(content, {\"[\": \"\", \"]\": \"\", \";\": \"\\n\", \" \": \",\"})\n",
    "            df = pd.read_csv(StringIO(content), names=timestamps).squeeze()\n",
    "            # df = DataFrame(df.values, columns=timestamps)\n",
    "            _PEMS_train.append(df.T)\n",
    "        PEMS_train = pd.concat(_PEMS_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee2b8bd-8310-4c11-9b94-67e9f161e7b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shuffled_dates = dates[self.randperm]\n",
    "\n",
    "\n",
    "with ZipFile(self.rawdata_paths[\"PEMS-SF.zip\"]) as archive:\n",
    "    with archive.open(\"stations_list\") as file:\n",
    "        content = file.read().decode(\"utf8\")\n",
    "        content = _reformat(content, {\"[\": \"\", \"]\": \"\", \" \": \"\\n\"})\n",
    "        stations = pd.read_csv(\n",
    "            StringIO(content), names=[\"station\"], dtype=\"category\"\n",
    "        ).squeeze()\n",
    "        stations = Series(stations)  # make sure it's not TextFileReader\n",
    "\n",
    "    with archive.open(\"PEMS_trainlabels\") as file:\n",
    "        content = file.read().decode(\"utf8\")\n",
    "        content = _reformat(content, {\"[\": \"\", \"]\": \"\\n\", \" \": \"\\n\"})\n",
    "        trainlabels = pd.read_csv(\n",
    "            StringIO(content), names=[\"labels\"], dtype=\"category\"\n",
    "        ).squeeze()\n",
    "\n",
    "    with archive.open(\"PEMS_testlabels\") as file:\n",
    "        content = file.read().decode(\"utf8\")\n",
    "        content = _reformat(content, {\"[\": \"\", \"]\": \"\", \" \": \"\\n\"})\n",
    "        testlabels = pd.read_csv(\n",
    "            StringIO(content), names=[\"labels\"], dtype=\"category\"\n",
    "        ).squeeze()\n",
    "        # test_dates = shuffled_dates[len(trainlabels) :]\n",
    "        # testlabels.index = test_dates\n",
    "        # testlabels = Series(testlabels)  # make sure it's not TextFileReader\n",
    "    #     train_dates = shuffled_dates[: len(trainlabels)]\n",
    "    #     trainlabels.index = train_dates\n",
    "    #     trainlabels = Series(trainlabels)  # make sure it's not TextFileReader\n",
    "    # # Check that the labels match with the actual weekdays\n",
    "    # assert all(\n",
    "    #     trainlabels.index.day_name() == trainlabels.values.map(weekdays)\n",
    "    # ), \"Labels do not match with dates!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad37292-abca-4a5f-9331-db3e3d9b552b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels.iloc[self.invperm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220971ed-48f0-4e35-9bda-030c9794167a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cb6ac8-43fc-41dc-beb9-b832c1743436",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "self.randperm == ((self.randperm + 1).apply(lambda x: x % len(self.randperm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52b206a-0ed5-4988-bd1a-0f36f351351d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "self.randperm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdc8c52-d633-4165-b61f-eb6e351e55f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "((self.randperm + 1).apply(lambda x: x % len(self.randperm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70040028-268e-4a7b-93b6-0233dbc1fcf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = pd.concat([trainlabels, testlabels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29876ec8-3ca6-448f-807c-fa3825cd2925",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad30651f-c7d3-44e7-8cb4-4f70c13300f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainlabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2d0dbc-c8ae-4808-8589-615374281e80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shuffled_dates = dates[self.randperm]\n",
    "\n",
    "\n",
    "with ZipFile(self.rawdata_paths[\"PEMS-SF.zip\"]) as archive:\n",
    "    with archive.open(\"stations_list\") as file:\n",
    "        content = file.read().decode(\"utf8\")\n",
    "        content = _reformat(content, {\"[\": \"\", \"]\": \"\", \" \": \"\\n\"})\n",
    "        stations = pd.read_csv(\n",
    "            StringIO(content), names=[\"station\"], dtype=\"category\"\n",
    "        ).squeeze()\n",
    "        stations = Series(stations)  # make sure it's not TextFileReader\n",
    "\n",
    "    with archive.open(\"PEMS_trainlabels\") as file:\n",
    "        content = file.read().decode(\"utf8\")\n",
    "        content = _reformat(content, {\"[\": \"\", \"]\": \"\\n\", \" \": \"\\n\"})\n",
    "        trainlabels = pd.read_csv(\n",
    "            StringIO(content), names=[\"labels\"], dtype=\"category\"\n",
    "        ).squeeze()\n",
    "        train_dates = shuffled_dates[: len(trainlabels)]\n",
    "        trainlabels.index = train_dates\n",
    "        trainlabels = Series(trainlabels)  # make sure it's not TextFileReader\n",
    "    # Check that the labels match with the actual weekdays\n",
    "    assert all(\n",
    "        trainlabels.index.day_name() == trainlabels.values.map(weekdays)\n",
    "    ), \"Labels do not match with dates!\"\n",
    "\n",
    "    with archive.open(\"PEMS_testlabels\") as file:\n",
    "        content = file.read().decode(\"utf8\")\n",
    "        content = _reformat(content, {\"[\": \"\", \"]\": \"\", \" \": \"\\n\"})\n",
    "        testlabels = pd.read_csv(\n",
    "            StringIO(content), names=[\"labels\"], dtype=\"category\"\n",
    "        ).squeeze()\n",
    "        test_dates = shuffled_dates[len(trainlabels) :]\n",
    "        testlabels.index = test_dates\n",
    "        testlabels = Series(testlabels)  # make sure it's not TextFileReader\n",
    "\n",
    "    # Check that the labels match with the actual weekdays\n",
    "    assert all(\n",
    "        testlabels.index.day_name() == testlabels.values.map(weekdays)\n",
    "    ), \"Labels do not match with dates!\"\n",
    "    assert (\n",
    "        trainlabels.dtype == testlabels.dtype\n",
    "    ), \"Train and test have different labels!\"\n",
    "\n",
    "    with archive.open(\"PEMS_train\") as file:\n",
    "        _PEMS_train = []\n",
    "        for line in file:\n",
    "            content = line.decode(\"utf8\")\n",
    "            content = _reformat(content, {\"[\": \"\", \"]\": \"\", \";\": \"\\n\", \" \": \",\"})\n",
    "            df = pd.read_csv(StringIO(content), header=None).squeeze()\n",
    "            df = DataFrame(df.values, index=stations, columns=timestamps)\n",
    "            _PEMS_train.append(df.T)\n",
    "        PEMS_train = pd.concat(_PEMS_train, keys=train_dates)\n",
    "\n",
    "    with archive.open(\"PEMS_test\") as file:\n",
    "        _PEMS_test = []\n",
    "        for line in file:\n",
    "            content = line.decode(\"utf8\")\n",
    "            content = _reformat(content, {\"[\": \"\", \"]\": \"\", \";\": \"\\n\", \" \": \",\"})\n",
    "            df = pd.read_csv(StringIO(content), header=None).squeeze()\n",
    "            df = DataFrame(df.values, index=stations, columns=timestamps)\n",
    "            _PEMS_test.append(df.T)\n",
    "        PEMS_test = pd.concat(_PEMS_test, keys=test_dates)\n",
    "\n",
    "PEMS = pd.concat([PEMS_train, PEMS_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c309eef5-611c-4ab1-942f-630d5c67ac34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa6dc7a-87ed-4bc9-ad6c-06db485cb85f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56c255f-d571-4757-85d3-8104d4b622f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adea4705-8d2b-4ad3-a151-0d6c71295224",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PEMS_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da00a8a-cb8f-44dc-834d-63412da65f49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe0d235-b144-4bc3-ac04-d4dc02773e1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

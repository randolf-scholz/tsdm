{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIMIC 4 data - dataset construction inputevents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from pathlib import Path\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import pandas as pd\n",
    "import pyarrow\n",
    "import pyarrow.csv\n",
    "import pyarrow.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata_file = Path.cwd() / \"mimic-iv-1.0.zip\"\n",
    "dataset_path = Path.cwd() / \"processed\"\n",
    "rawdata_path = Path.cwd() / \"raw\"\n",
    "\n",
    "files = {\n",
    "    \"outputevents\": \"mimic-iv-1.0/icu/outputevents.csv.gz\",\n",
    "}\n",
    "\n",
    "CATEGORY = pyarrow.dictionary(\"int32\", \"string\")\n",
    "ID_TYPE = \"int32\"  # pyarrow.dictionary(\"int32\", \"int32\", ordered=True)\n",
    "\n",
    "column_types = {\n",
    "    \"outputevents\": {\n",
    "        \"subject_id\": ID_TYPE,\n",
    "        \"hadm_id\": ID_TYPE,\n",
    "        \"stay_id\": ID_TYPE,\n",
    "        \"charttime\": \"timestamp[s]\",\n",
    "        \"storetime\": \"timestamp[s]\",\n",
    "        \"itemid\": ID_TYPE,\n",
    "        \"value\": \"float32\",\n",
    "        \"valueuom\": CATEGORY,\n",
    "    }\n",
    "}\n",
    "\n",
    "null_values = [\n",
    "    \"-\",\n",
    "    \"-1.#IND\",\n",
    "    \"-1.#QNAN\",\n",
    "    \"-NaN\",\n",
    "    \"-nan\",\n",
    "    \"?\",\n",
    "    \"\",\n",
    "    \"#N/A N/A\",\n",
    "    \"#N/A\",\n",
    "    \"#NA\",\n",
    "    \"#na\",\n",
    "    \"<N/A>\",\n",
    "    \"<n/a>\",\n",
    "    \"<NA>\",\n",
    "    \"<na>\",\n",
    "    \"1.#IND\",\n",
    "    \"1.#QNAN\",\n",
    "    \"INFORMATION NOT AVAILABLE\",\n",
    "    \"N/A\",\n",
    "    \"n/a\",\n",
    "    \"NA\",\n",
    "    \"na\",\n",
    "    \"NAN\",\n",
    "    \"NaN\",\n",
    "    \"nan\",\n",
    "    \"NONE\",\n",
    "    \"None\",\n",
    "    \"none\",\n",
    "    \"NULL\",\n",
    "    \"NULL\",\n",
    "    \"Null\",\n",
    "    \"null\",\n",
    "    \"UNABLE TO OBTAIN\",\n",
    "    \"UNKNOWN\",\n",
    "    \"unknown\",\n",
    "]\n",
    "\n",
    "types_map = {\n",
    "    \"string\": pd.StringDtype(),\n",
    "    \"bool\": pd.BooleanDtype(),\n",
    "    \"int8\": pd.Int8Dtype(),\n",
    "    \"int16\": pd.Int16Dtype(),\n",
    "    \"int32\": pd.Int32Dtype(),\n",
    "    \"int64\": pd.Int64Dtype(),\n",
    "    \"uint8\": pd.UInt8Dtype(),\n",
    "    \"uint16\": pd.UInt16Dtype(),\n",
    "    \"uint32\": pd.UInt32Dtype(),\n",
    "    \"uint64\": pd.UInt64Dtype(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"outputevents\"\n",
    "with (\n",
    "    ZipFile(rawdata_file) as archive,\n",
    "    archive.open(files[key]) as compressed_file,\n",
    "    gzip.open(compressed_file) as file,\n",
    "):\n",
    "    outputevents = pyarrow.csv.read_csv(\n",
    "        file,\n",
    "        convert_options=pyarrow.csv.ConvertOptions(\n",
    "            column_types=column_types[key],\n",
    "            strings_can_be_null=True,\n",
    "            null_values=null_values,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "outputevents.shape, outputevents.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store and reload as pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pyarrow.parquet.write_table(outputevents, rawdata_path / f\"{key}.parquet\")\n",
    "outputevents = outputevents.to_pandas(self_destruct=True, types_mapper=types_map.get)\n",
    "outputevents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the input items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"inputitems\"\n",
    "with pd.option_context(\"string_storage\", \"pyarrow\"):\n",
    "    inputitems = pd.read_parquet(\n",
    "        rawdata_path / f\"{key}.parquet\", use_nullable_dtypes=True\n",
    "    )\n",
    "inputitems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only keep selected patients/admissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "admissions = pd.read_parquet(dataset_path / \"admissions_processed.parquet\")\n",
    "\n",
    "for key in [\"hadm_id\", \"subject_id\"]:\n",
    "    mask = outputevents[key].isin(admissions[key])\n",
    "    outputevents = outputevents[mask]\n",
    "    print(f\"Removing {(~mask).sum()} {key}\")\n",
    "    print(f\"Number of patients remaining: {outputevents['subject_id'].nunique()}\")\n",
    "    print(f\"Number of admissions remaining: {outputevents['hadm_id'].nunique()}\")\n",
    "    print(f\"Number of events remaining: {outputevents.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge on items &  keep only common ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outputevents = pd.merge(outputevents, inputitems, on=\"itemid\")\n",
    "NTOP = 15\n",
    "item_freq = outputevents.groupby(\"label\")[\"subject_id\"].nunique()\n",
    "item_freq = item_freq.sort_values(ascending=False)\n",
    "common_items = item_freq.index[:NTOP]\n",
    "\n",
    "for key in common_items:\n",
    "    assert key in outputevents[\"label\"].values, f\"{key:20} missing in data!\"\n",
    "\n",
    "outputevents = outputevents[outputevents[\"label\"].isin(common_items)]\n",
    "print(f\"Number of events remaining: {outputevents.shape}\")\n",
    "print(f\"Number of patients remaining: {outputevents['subject_id'].nunique()}\")\n",
    "list(common_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification that all input labels have the same amounts units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert outputevents[\"valueuom\"].nunique() == 1\n",
    "outputevents.groupby(\"label\")[\"valueuom\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serialize Pre-processed DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Clean categories\n",
    "\n",
    "\n",
    "def clean_categories(df):\n",
    "    for col in df:\n",
    "        if df[col].dtype == \"category\":\n",
    "            df[col] = df[col].cat.remove_unused_categories()\n",
    "    return df\n",
    "\n",
    "\n",
    "outputevents = clean_categories(outputevents)\n",
    "outputevents.to_parquet(dataset_path / \"outputevents_processed.parquet\")\n",
    "outputevents.shape, outputevents.dtypes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

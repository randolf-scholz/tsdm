{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# MIMIC 4 data - dataset construction inputevents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "from pathlib import Path\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow\n",
    "import pyarrow.csv\n",
    "import pyarrow.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# Load tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Table Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rawdata_file = Path.cwd() / \"mimic-iv-1.0.zip\"\n",
    "dataset_path = Path.cwd() / \"processed\"\n",
    "rawdata_path = Path.cwd() / \"raw\"\n",
    "\n",
    "\n",
    "files = {\n",
    "    \"inputevents\": \"mimic-iv-1.0/icu/inputevents.csv.gz\",\n",
    "    \"inputitems\": \"mimic-iv-1.0/icu/d_items.csv.gz\",\n",
    "}\n",
    "\n",
    "CATEGORY = pyarrow.dictionary(\"int32\", \"string\")\n",
    "ID_TYPE = \"int32\"  # pyarrow.dictionary(\"int32\", \"int32\", ordered=True)\n",
    "\n",
    "column_types = {\n",
    "    \"inputevents\": {\n",
    "        \"amount\": \"float32\",\n",
    "        \"amountuom\": CATEGORY,\n",
    "        \"cancelreason\": \"int32\",\n",
    "        \"continueinnextdept\": \"bool\",\n",
    "        \"endtime\": \"timestamp[s]\",\n",
    "        \"hadm_id\": ID_TYPE,\n",
    "        \"isopenbag\": \"bool\",\n",
    "        \"itemid\": ID_TYPE,\n",
    "        \"linkorderid\": ID_TYPE,\n",
    "        \"ordercategorydescription\": CATEGORY,\n",
    "        \"ordercategoryname\": CATEGORY,\n",
    "        \"ordercomponenttypedescription\": CATEGORY,\n",
    "        \"orderid\": ID_TYPE,\n",
    "        \"originalamount\": \"float32\",\n",
    "        \"originalrate\": \"float32\",\n",
    "        \"patientweight\": \"float32\",\n",
    "        \"rate\": \"float32\",\n",
    "        \"rateuom\": CATEGORY,\n",
    "        \"secondaryordercategoryname\": CATEGORY,\n",
    "        \"starttime\": \"timestamp[s]\",\n",
    "        \"statusdescription\": CATEGORY,\n",
    "        \"stay_id\": ID_TYPE,\n",
    "        \"storetime\": \"timestamp[s]\",\n",
    "        \"subject_id\": ID_TYPE,\n",
    "        \"totalamount\": \"float32\",\n",
    "        \"totalamountuom\": CATEGORY,\n",
    "    },\n",
    "    \"inputitems\": {\n",
    "        \"abbreviation\": CATEGORY,\n",
    "        \"category\": CATEGORY,\n",
    "        \"highnormalvalue\": \"float32\",\n",
    "        \"itemid\": ID_TYPE,\n",
    "        \"label\": CATEGORY,\n",
    "        \"linksto\": CATEGORY,\n",
    "        \"lownormalvalue\": \"float32\",\n",
    "        \"param_type\": CATEGORY,\n",
    "        \"unitname\": CATEGORY,\n",
    "    },\n",
    "}\n",
    "\n",
    "null_values = [\n",
    "    \"-\",\n",
    "    \"-1.#IND\",\n",
    "    \"-1.#QNAN\",\n",
    "    \"-NaN\",\n",
    "    \"-nan\",\n",
    "    \"?\",\n",
    "    \"\",\n",
    "    \"#N/A N/A\",\n",
    "    \"#N/A\",\n",
    "    \"#NA\",\n",
    "    \"#na\",\n",
    "    \"<N/A>\",\n",
    "    \"<n/a>\",\n",
    "    \"<NA>\",\n",
    "    \"<na>\",\n",
    "    \"1.#IND\",\n",
    "    \"1.#QNAN\",\n",
    "    \"INFORMATION NOT AVAILABLE\",\n",
    "    \"N/A\",\n",
    "    \"n/a\",\n",
    "    \"NA\",\n",
    "    \"na\",\n",
    "    \"NAN\",\n",
    "    \"NaN\",\n",
    "    \"nan\",\n",
    "    \"NONE\",\n",
    "    \"None\",\n",
    "    \"none\",\n",
    "    \"NULL\",\n",
    "    \"NULL\",\n",
    "    \"Null\",\n",
    "    \"null\",\n",
    "    \"UNABLE TO OBTAIN\",\n",
    "    \"UNKNOWN\",\n",
    "    \"unknown\",\n",
    "]\n",
    "\n",
    "types_map = {\n",
    "    \"string\": pd.StringDtype(),\n",
    "    \"bool\": pd.BooleanDtype(),\n",
    "    \"int8\": pd.Int8Dtype(),\n",
    "    \"int16\": pd.Int16Dtype(),\n",
    "    \"int32\": pd.Int32Dtype(),\n",
    "    \"int64\": pd.Int64Dtype(),\n",
    "    \"uint8\": pd.UInt8Dtype(),\n",
    "    \"uint16\": pd.UInt16Dtype(),\n",
    "    \"uint32\": pd.UInt32Dtype(),\n",
    "    \"uint64\": pd.UInt64Dtype(),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load `Inputevents`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# shape: (10M, 26) ‚áù 0.3B values.\n",
    "key = \"inputevents\"\n",
    "with (\n",
    "    ZipFile(rawdata_file) as archive,\n",
    "    archive.open(files[key]) as compressed_file,\n",
    "    gzip.open(compressed_file) as file,\n",
    "):\n",
    "    inputevents = pyarrow.csv.read_csv(\n",
    "        file,\n",
    "        convert_options=pyarrow.csv.ConvertOptions(\n",
    "            column_types=column_types[key],\n",
    "            strings_can_be_null=True,\n",
    "            null_values=null_values,\n",
    "        ),\n",
    "    )\n",
    "inputevents.shape, inputevents.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Store and reload as pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pyarrow.parquet.write_table(inputevents, rawdata_path / f\"{key}.parquet\")\n",
    "inputevents = inputevents.to_pandas(self_destruct=True, types_mapper=types_map.get)\n",
    "pd.DataFrame({\"type\": inputevents.dtypes, \"uniques\": inputevents.nunique()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load `inputitems`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "key = \"inputitems\"\n",
    "with (\n",
    "    ZipFile(rawdata_file) as archive,\n",
    "    archive.open(files[key]) as compressed_file,\n",
    "    gzip.open(compressed_file) as file,\n",
    "):\n",
    "    inputitems = pyarrow.csv.read_csv(\n",
    "        file,\n",
    "        convert_options=pyarrow.csv.ConvertOptions(\n",
    "            column_types=column_types[key],\n",
    "            strings_can_be_null=True,\n",
    "            null_values=null_values,\n",
    "        ),\n",
    "    )\n",
    "inputitems.shape, inputitems.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Store and reload as pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pyarrow.parquet.write_table(inputitems, rawdata_path / f\"{key}.parquet\")\n",
    "inputitems = inputitems.to_pandas(self_destruct=True, types_mapper=types_map.get)\n",
    "inputitems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Select relevant Subset of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Only keep selected Patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "admissions = pd.read_parquet(dataset_path / \"admissions_processed.parquet\")\n",
    "\n",
    "for key in [\"hadm_id\", \"subject_id\"]:\n",
    "    mask = inputevents[key].isin(admissions[key])\n",
    "    inputevents = inputevents[mask]\n",
    "    print(f\"Removing {(~mask).sum()} {key}\")\n",
    "    print(f\"Number of patients remaining: {inputevents['subject_id'].nunique()}\")\n",
    "    print(f\"Number of admissions remaining: {inputevents['hadm_id'].nunique()}\")\n",
    "    print(f\"Number of events remaining: {inputevents.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## Only keep columns of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_columns = [\n",
    "    \"amount\",\n",
    "    \"amountuom\",\n",
    "    \"endtime\",\n",
    "    \"hadm_id\",\n",
    "    \"itemid\",\n",
    "    \"ordercategorydescription\",\n",
    "    \"patientweight\",\n",
    "    \"rate\",\n",
    "    \"rateuom\",\n",
    "    \"starttime\",\n",
    "    \"subject_id\",\n",
    "]\n",
    "\n",
    "inputevents = inputevents[selected_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Only keep common items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputevents = pd.merge(inputevents, inputitems, on=\"itemid\")\n",
    "print(f\"Number of events remaining: {inputevents.shape}\")\n",
    "print(f\"Number of patients remaining: {inputevents['subject_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "item_freq = inputevents.groupby(\"label\")[\"subject_id\"].nunique()\n",
    "N_TOP = 50\n",
    "common_items = item_freq.sort_values(ascending=False).index[:N_TOP]\n",
    "inputevents = inputevents[inputevents[\"label\"].isin(common_items)]\n",
    "print(f\"Number of events remaining: {inputevents.shape}\")\n",
    "print(f\"Number of patients remaining: {inputevents['subject_id'].nunique()}\")\n",
    "inputevents.groupby(\"label\")[\"amountuom\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Clean up bad data entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Split Continuous medication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "key = \"Pantoprazole (Protonix)\"\n",
    "unit = \"Continuous Med\"\n",
    "mask = (inputevents[\"label\"] == key) & (inputevents[\"ordercategorydescription\"] == unit)\n",
    "print(\n",
    "    f\"Modifying {mask.sum():5d} entries - bad data in {key} (divide in two)\\n\\tdrug\"\n",
    "    \" shot or continuous treatment and create a new item id for the continuous version\"\n",
    ")\n",
    "inputevents[\"label\"] = inputevents[\"label\"].cat.add_categories(\n",
    "    \"Pantoprazole (Protonix) Continuous\"\n",
    ")\n",
    "inputevents.loc[mask, \"label\"] = \"Pantoprazole (Protonix) Continuous\"\n",
    "inputevents.loc[mask, \"itemid\"] = 2217441"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Only keep drugs with correct dosage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "check_amountuom = {  # MIMIC-III and MIMIC-IV\n",
    "    \"Cefazolin\": \"dose\",\n",
    "    \"Cefepime\": \"dose\",\n",
    "    \"Ceftriaxone\": \"dose\",\n",
    "    \"Ciprofloxacin\": \"dose\",\n",
    "    \"Famotidine (Pepcid)\": \"dose\",\n",
    "    \"Fentanyl (Concentrate)\": \"mg\",\n",
    "    \"Heparin Sodium (Prophylaxis)\": \"dose\",\n",
    "    \"Hydromorphone (Dilaudid)\": \"mg\",\n",
    "    \"Magnesium Sulfate\": \"grams\",\n",
    "    \"Metoprolol\": \"mg\",\n",
    "    \"Metronidazole\": \"dose\",\n",
    "    \"Pantoprazole (Protonix)\": \"dose\",\n",
    "    \"Piperacillin/Tazobactam (Zosyn)\": \"dose\",\n",
    "    \"Propofol\": \"mg\",\n",
    "    \"Ranitidine (Prophylaxis)\": \"dose\",\n",
    "    \"Vancomycin\": \"dose\",\n",
    "} | {  # MIMIC-IV specific\n",
    "    \"Acetaminophen-IV\": \"mg\",\n",
    "    \"D5 1/2NS\": \"ml\",\n",
    "    \"LR\": \"ml\",\n",
    "    \"NaCl 0.9%\": \"ml\",\n",
    "    \"OR Crystalloid Intake\": \"ml\",\n",
    "    \"PO Intake\": \"ml\",\n",
    "    \"Pre-Admission/Non-ICU Intake\": \"ml\",\n",
    "}\n",
    "\n",
    "MASK = pd.Series(False, index=inputevents.index)\n",
    "\n",
    "for drug, unit in check_amountuom.items():\n",
    "    assert drug in inputevents[\"label\"].cat.categories, f\"{drug} not in categories!\"\n",
    "    mask = (inputevents[\"label\"] == drug) & (inputevents[\"amountuom\"] != unit)\n",
    "    print(f\"Removing {mask.sum():5d} entries - bad data in {drug} (drop {unit})\")\n",
    "    MASK |= mask\n",
    "\n",
    "inputevents = inputevents[~MASK].copy()\n",
    "print(f\"Number of events remaining: {inputevents.shape}\")\n",
    "print(f\"Number of patients remaining: {inputevents['subject_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Convert to standard units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "key = \"Dexmedetomidine (Precedex)\"\n",
    "mask = (inputevents[\"label\"] == key) & (inputevents[\"amountuom\"] == \"mcg\")\n",
    "print(f\"Modifying {mask.sum():5d} entries - bad data in {key} (cast all to mg)\")\n",
    "inputevents.loc[mask, \"amount\"] /= 1000\n",
    "inputevents.loc[mask, \"amountuom\"] = \"mg\"\n",
    "\n",
    "\n",
    "key = \"Fentanyl (Concentrate)\"\n",
    "mask = (inputevents[\"label\"] == key) & (inputevents[\"amountuom\"] == \"mg\")\n",
    "print(f\"Modifying {mask.sum():5d} entries - bad data in {key} (remove the non mg)\")\n",
    "inputevents.loc[mask, \"amount\"] *= 1000\n",
    "inputevents.loc[mask, \"amountuom\"] = \"mcg\"\n",
    "\n",
    "\n",
    "key = \"Fentanyl\"\n",
    "mask = (inputevents[\"label\"] == key) & (inputevents[\"amountuom\"] == \"mg\")\n",
    "print(f\"Modifying {mask.sum():5d} entries - bad data in {key} (put the mg to mcg)\")\n",
    "inputevents.loc[mask, \"amount\"] *= 1000\n",
    "inputevents.loc[mask, \"amountuom\"] = \"mcg\"\n",
    "inputevents.groupby(\"label\")[\"amountuom\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Validate prescription rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "check_rateuom = {\n",
    "    \"Acetaminophen-IV\": \"mg/min\",\n",
    "    \"Dextrose 5%\": \"mL/hour\",\n",
    "    \"Fentanyl (Concentrate)\": \"mcg/hour\",\n",
    "    \"Magnesium Sulfate (Bolus)\": \"mL/hour\",\n",
    "    \"NaCl 0.9%\": \"mL/hour\",\n",
    "    \"Packed Red Blood Cells\": \"mL/hour\",\n",
    "    \"Phenylephrine\": \"mcg/kg/min\",\n",
    "    \"Piggyback\": \"mL/hour\",\n",
    "    \"Sterile Water\": \"mL/hour\",\n",
    "}\n",
    "\n",
    "MASK = pd.Series(False, index=inputevents.index)\n",
    "\n",
    "for drug, unit in check_rateuom.items():\n",
    "    assert drug in inputevents[\"label\"].cat.categories, f\"{drug} not in categories!\"\n",
    "    mask = (inputevents[\"label\"] == drug) & (inputevents[\"rateuom\"] != unit)\n",
    "    print(f\"Removing {mask.sum():5d} entries - bad data in {drug} (drop {unit})\")\n",
    "    MASK |= mask\n",
    "\n",
    "inputevents = inputevents[~MASK].copy()\n",
    "print(f\"Number of events remaining: {inputevents.shape}\")\n",
    "print(f\"Number of patients remaining: {inputevents['subject_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "### Check if a single unit per drug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for drug, frame in inputevents.groupby(\"label\"):\n",
    "    usage_by_unit = frame[\"rateuom\"].value_counts()\n",
    "    assert (usage_by_unit != 0).sum() in (0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Validate computed amounts agree with reported amounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DURATION = inputevents.endtime - inputevents.starttime\n",
    "total_hours = DURATION / np.timedelta64(1, \"h\")\n",
    "units = inputevents[\"rateuom\"].dropna().unique()\n",
    "\n",
    "for unit in units:\n",
    "    mask = inputevents[\"rate\"].notnull() & (inputevents[\"rateuom\"] == unit)\n",
    "    df = inputevents[mask]\n",
    "    time = total_hours[mask] * 60 ** (\"min\" in unit)\n",
    "\n",
    "    amount_units = df[\"amountuom\"].unique()\n",
    "    assert len(amount_units) == 1\n",
    "\n",
    "    if \"kg\" in unit:\n",
    "        amount = df[\"rate\"] * time * df[\"patientweight\"]\n",
    "        discrepancy = amount / 1000 - df[\"amount\"]\n",
    "    else:\n",
    "        amount = df[\"rate\"] * time\n",
    "        discrepancy = amount - df[\"amount\"]\n",
    "\n",
    "    print(f\"{unit=:12} {amount_units[0]=:8} {discrepancy.max()=:.6f}\")\n",
    "    assert all(discrepancy < 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Create data splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "FREQ = pd.Timedelta(\"30min\")\n",
    "has_rate = inputevents[\"rate\"].notna()\n",
    "is_late = DURATION > FREQ\n",
    "\n",
    "splits = {}\n",
    "\n",
    "# The first dataframe contains the entries with no rate but with extended duration inputs (over 0.5 hour)\n",
    "splits[0] = inputevents[~has_rate & is_late].copy()\n",
    "\n",
    "# The second dataframe contains the entries with no rate and low duration entries (<0.5hour)\n",
    "splits[1] = inputevents[~has_rate & ~is_late].copy()\n",
    "\n",
    "# The third dataframe contains the entries with a rate and extended duration inputs (over 0.5 hour)\n",
    "splits[2] = inputevents[has_rate & is_late].copy()\n",
    "\n",
    "# The forth dataframe contains the entries with a rate and low duration entries (< 0.5 hour)\n",
    "splits[3] = inputevents[has_rate & ~is_late].copy()\n",
    "\n",
    "# Check if split is complete\n",
    "assert sum(map(len, splits.values())) == len(inputevents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "### Add repeats to split 0 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "REPEATS = DURATION / FREQ\n",
    "IS_INT = np.ceil(REPEATS).astype(int) == REPEATS\n",
    "REPEATS = np.ceil(REPEATS).astype(int) + IS_INT\n",
    "REPEATS = REPEATS.astype(\"Int32\")\n",
    "\n",
    "for k in (0, 2):\n",
    "    df = splits[k].copy()\n",
    "    df[\"Repeat\"] = REPEATS[df.index]\n",
    "    df = df.reindex(df.index.repeat(df[\"Repeat\"]))\n",
    "    step = df[\"starttime\"].groupby(level=0).cumcount()\n",
    "    df[\"charttime\"] = df[\"starttime\"] + step * FREQ\n",
    "    df[\"amount\"] = (df[\"amount\"] / df[\"Repeat\"]).astype(\"float32\")\n",
    "    min_diff = (df[\"endtime\"] - df[\"charttime\"]).groupby(level=0).min()\n",
    "    assert all(min_diff < FREQ), \"Did add enough steps!\"\n",
    "    splits[k] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "### For the early splits, we do not add repeats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "splits[1][\"charttime\"] = splits[1][\"starttime\"]\n",
    "splits[3][\"charttime\"] = splits[3][\"starttime\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "### Merge splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputevents = pd.concat(splits, names=[\"split\"])\n",
    "inputevents = inputevents.reset_index(level=1, drop=True)\n",
    "inputevents = inputevents.sort_values(by=[\"subject_id\", \"charttime\", \"label\"])\n",
    "inputevents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Serialize Pre-processed DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Clean categories\n",
    "\n",
    "\n",
    "def clean_categories(df):\n",
    "    for col in df:\n",
    "        if df[col].dtype == \"category\":\n",
    "            df[col] = df[col].cat.remove_unused_categories()\n",
    "    return df\n",
    "\n",
    "\n",
    "inputevents = clean_categories(inputevents)\n",
    "inputevents.reset_index().to_parquet(dataset_path / \"inputevents_processed.parquet\")\n",
    "inputevents.shape, inputevents.dtypes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

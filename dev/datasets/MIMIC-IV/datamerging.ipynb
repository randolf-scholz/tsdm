{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging all data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load processed tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rawdata_file = Path.cwd() / \"mimic-iv-1.0.zip\"\n",
    "dataset_path = Path.cwd() / \"processed\"\n",
    "rawdata_path = Path.cwd() / \"raw\"\n",
    "\n",
    "\n",
    "with pd.option_context(\"string_storage\", \"pyarrow\"):\n",
    "    admissions = pd.read_parquet(dataset_path / \"admissions_processed.parquet\")\n",
    "\n",
    "    labevents = pd.read_parquet(\n",
    "        dataset_path / \"labevents_processed.parquet\",\n",
    "        columns=[\"subject_id\", \"hadm_id\", \"charttime\", \"valuenum\", \"label\"],\n",
    "    )\n",
    "    inputevents = pd.read_parquet(\n",
    "        dataset_path / \"inputevents_processed.parquet\",\n",
    "        columns=[\"subject_id\", \"hadm_id\", \"charttime\", \"amount\", \"label\"],\n",
    "    )\n",
    "    outputevents = pd.read_parquet(\n",
    "        dataset_path / \"outputevents_processed.parquet\",\n",
    "        columns=[\"subject_id\", \"hadm_id\", \"charttime\", \"value\", \"label\"],\n",
    "    )\n",
    "    prescriptions = pd.read_parquet(\n",
    "        dataset_path / \"prescriptions_processed.parquet\",\n",
    "        columns=[\"subject_id\", \"hadm_id\", \"charttime\", \"dose_val_rx\", \"drug\"],\n",
    "    )\n",
    "\n",
    "admissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for table in (labevents, inputevents, outputevents, prescriptions):\n",
    "    display(table.shape)\n",
    "    display(pd.DataFrame({\"type\": table.dtypes, \"uniques\": table.nunique()}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change the name of amount. Valuenum for every table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputevents = inputevents.rename(columns={\"amount\": \"valuenum\"})\n",
    "outputevents = outputevents.rename(columns={\"value\": \"valuenum\"})\n",
    "prescriptions = prescriptions.rename(columns={\"dose_val_rx\": \"valuenum\"})\n",
    "prescriptions = prescriptions.rename(columns={\"drug\": \"label\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tables = {\n",
    "    \"inputevent\": inputevents,\n",
    "    \"labevent\": labevents,\n",
    "    \"outputevent\": outputevents,\n",
    "    \"prescription\": prescriptions,\n",
    "}\n",
    "\n",
    "merged_df = pd.concat(tables, names=[\"type\"]).reset_index(drop=True)\n",
    "assert all(merged_df.notna())\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate that all labels have different names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert merged_df[\"label\"].nunique() == (\n",
    "    inputevents[\"label\"].nunique()\n",
    "    + labevents[\"label\"].nunique()\n",
    "    + outputevents[\"label\"].nunique()\n",
    "    + prescriptions[\"label\"].nunique()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate that all subject_id / hadm_id pairs are unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert all(merged_df.groupby(\"subject_id\")[\"hadm_id\"].nunique() == 1)\n",
    "assert all(merged_df.groupby(\"hadm_id\")[\"subject_id\"].nunique() == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Metadata tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metadata = admissions.copy().sort_values(by=[\"subject_id\"])\n",
    "\n",
    "for key in [\"hadm_id\", \"subject_id\"]:\n",
    "    mask = metadata[key].isin(merged_df[key])\n",
    "    metadata = metadata[mask]\n",
    "    print(f\"Removing {(~mask).sum()} {key}\")\n",
    "    print(f\"Number of patients remaining: {metadata['subject_id'].nunique()}\")\n",
    "    print(f\"Number of admissions remaining: {metadata['hadm_id'].nunique()}\")\n",
    "    print(f\"Number of events remaining: {metadata.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only keep data with duration in bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mintime = metadata.set_index(\"subject_id\")[[\"admittime\", \"edregtime\"]].min(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "delta = (\n",
    "    merged_df.groupby(\"subject_id\")[\"charttime\"].max()\n",
    "    - merged_df.groupby(\"subject_id\")[\"charttime\"].min()\n",
    ")\n",
    "mask = delta < metadata.set_index(\"subject_id\")[\"elapsed_time\"]\n",
    "mask.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only keep data chose `charttime` > `admittime`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mask = (\n",
    "    merged_df.groupby(\"subject_id\")[\"charttime\"].min()\n",
    "    >= metadata.set_index(\"subject_id\")[\"admittime\"]\n",
    ")\n",
    "mask.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (\n",
    "    merged_df.groupby(\"subject_id\")[\"charttime\"].min()\n",
    "    >= metadata.set_index(\"subject_id\")[\"edregtime\"]\n",
    ")\n",
    "mask.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mask = merged_df.groupby(\"subject_id\")[\"charttime\"].min() >= mintime\n",
    "mask.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only keep data chose `charttime` < `dischtime`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mask &= (\n",
    "    merged_df.groupby(\"subject_id\")[\"charttime\"].max()\n",
    "    <= metadata.set_index(\"subject_id\")[\"dischtime\"]\n",
    ")\n",
    "mask.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only keep data chose `charttime` ends within the (2d, 29d) bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lb = mintime + pd.Timedelta(\"2d\")\n",
    "ub = mintime + pd.Timedelta(\"29d\")\n",
    "et = merged_df.groupby(\"subject_id\")[\"charttime\"].max()\n",
    "mask &= (lb <= et) & (et <= ub)\n",
    "mask.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: combined masks âŸ¹ only ~ 70 % of data remains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add timestamps and Label Codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reftime = merged_df.groupby(\"subject_id\")[\"charttime\"].min()\n",
    "reftime = reftime.rename(\"reftime\")\n",
    "metadata = metadata.join(reftime, on=\"subject_id\")\n",
    "merged_df = pd.merge(reftime, merged_df, left_index=True, right_on=\"subject_id\")\n",
    "merged_df[\"time_stamp\"] = merged_df[\"charttime\"] - merged_df[\"reftime\"]\n",
    "merged_df = merged_df.drop(columns=[\"reftime\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create label codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_df[\"label\"] = merged_df[\"label\"].astype(\"string\").astype(\"category\")\n",
    "merged_df[\"label_code\"] = merged_df[\"label\"].cat.codes\n",
    "merged_df = merged_df.sort_values([\"hadm_id\", \"valuenum\", \"time_stamp\", \"label_code\"])\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## select only values within first 48 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mask = merged_df[\"time_stamp\"] < pd.Timedelta(48, \"h\")\n",
    "merged_df = merged_df[mask].copy()\n",
    "print(f\"Number of patients considered: {merged_df['hadm_id'].nunique()}\")\n",
    "assert all(merged_df[\"time_stamp\"] < pd.Timedelta(48, \"h\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert time_stamp to minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_df[\"time_stamp\"] = merged_df[\"time_stamp\"].dt.total_seconds().div(60).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Finalize and Serialize Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select columns used in final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LABELS = merged_df[\"label\"].dtype\n",
    "LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selection = [\"subject_id\", \"time_stamp\", \"label\", \"valuenum\"]\n",
    "timeseries = merged_df[selection].copy()\n",
    "timeseries = timeseries.sort_values(by=selection)\n",
    "timeseries = timeseries.set_index([\"subject_id\", \"time_stamp\"])\n",
    "timeseries.to_parquet(dataset_path / \"timeseries_triplet.parquet\")\n",
    "print(timeseries.shape, timeseries.dtypes)\n",
    "timeseries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tsdm.encoders import TripletDecoder\n",
    "\n",
    "timeseries.label = timeseries.label.astype(LABELS)\n",
    "encoder = TripletDecoder(value_name=\"valuenum\", var_name=\"label\")\n",
    "encoder.fit(timeseries)\n",
    "encoded = encoder.encode(timeseries)\n",
    "assert len(encoded.index.unique()) == len(encoded)\n",
    "encoded.columns = encoded.columns.astype(\"string\")\n",
    "encoded.to_parquet(dataset_path / \"timeseries.parquet\")\n",
    "encoded.columns = encoded.columns.astype(LABELS)\n",
    "encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Metadata Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selection = [\n",
    "    \"subject_id\",\n",
    "    \"reftime\",\n",
    "    \"admission_type\",\n",
    "    \"admission_location\",\n",
    "    \"discharge_location\",\n",
    "    \"insurance\",\n",
    "    \"language\",\n",
    "    \"marital_status\",\n",
    "    \"ethnicity\",\n",
    "    \"hospital_expire_flag\",\n",
    "    \"gender\",\n",
    "    \"anchor_age\",\n",
    "    \"anchor_year\",\n",
    "    \"anchor_year_group\",\n",
    "]\n",
    "metadata = metadata[selection]\n",
    "metadata = metadata.set_index(\"subject_id\")\n",
    "metadata = metadata.sort_index()\n",
    "metadata.to_parquet(dataset_path / \"metadata.parquet\")\n",
    "print(metadata.shape, metadata.dtypes)\n",
    "metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create label table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = pd.Series(LABELS.categories, name=\"label\", dtype=LABELS)\n",
    "labels = labels.to_frame()\n",
    "label_origin = pd.Series(\n",
    "    {\n",
    "        key: name\n",
    "        for name, table in tables.items()\n",
    "        for key in table[\"label\"].cat.categories\n",
    "    },\n",
    "    name=\"origin\",\n",
    "    dtype=\"category\",\n",
    ")\n",
    "label_origin.index.name = \"label\"\n",
    "label_origin.index = label_origin.index.astype(LABELS)\n",
    "labels = pd.merge(labels, label_origin, right_index=True, left_on=\"label\")\n",
    "labels[\"code\"] = labels[\"label\"].cat.codes\n",
    "missing = encoded.isna().mean().rename(\"missing\").astype(\"float32\")\n",
    "means = encoded.mean().rename(\"mean\").astype(\"float32\")\n",
    "stdvs = encoded.std().rename(\"stdv\").astype(\"float32\")\n",
    "labels = labels.join(missing, on=\"label\")\n",
    "labels = labels.join(means, on=\"label\")\n",
    "labels = labels.join(stdvs, on=\"label\")\n",
    "labels.to_parquet(dataset_path / \"labels.parquet\")\n",
    "print(labels.dtypes)\n",
    "labels"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,auto:nomarker"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

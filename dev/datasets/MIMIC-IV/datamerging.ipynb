{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging all data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-12T11:52:58.860708Z",
     "iopub.status.busy": "2022-09-12T11:52:58.860470Z",
     "iopub.status.idle": "2022-09-12T11:52:59.438815Z",
     "shell.execute_reply": "2022-09-12T11:52:59.438168Z",
     "shell.execute_reply.started": "2022-09-12T11:52:58.860648Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import gzip\n",
    "from datetime import timedelta\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow\n",
    "import pyarrow.csv\n",
    "import pyarrow.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all the previously processed data from the source files in the MIMIC4 dataset. <br/>Unify column naming across data sources and merge to one dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-12T11:52:59.848087Z",
     "iopub.status.busy": "2022-09-12T11:52:59.847164Z",
     "iopub.status.idle": "2022-09-12T11:52:59.851311Z",
     "shell.execute_reply": "2022-09-12T11:52:59.850613Z",
     "shell.execute_reply.started": "2022-09-12T11:52:59.847999Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 50)\n",
    "pd.set_option(\"display.max_columns\", 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-12T14:34:20.266625Z",
     "iopub.status.busy": "2022-09-12T14:34:20.266313Z",
     "iopub.status.idle": "2022-09-12T14:34:20.925548Z",
     "shell.execute_reply": "2022-09-12T14:34:20.924615Z",
     "shell.execute_reply.started": "2022-09-12T14:34:20.266591Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with pd.option_context(\"string_storage\", \"pyarrow\"):\n",
    "    labevents = pd.read_parquet(\n",
    "        \"labevents_processed.parquet\",\n",
    "        columns=[\"subject_id\", \"hadm_id\", \"charttime\", \"valuenum\", \"label\"],\n",
    "    )\n",
    "    inputevents = pd.read_parquet(\n",
    "        \"inputevents_processed.parquet\",\n",
    "        columns=[\"subject_id\", \"hadm_id\", \"charttime\", \"amount\", \"label\"],\n",
    "    )\n",
    "    outputevents = pd.read_parquet(\n",
    "        \"outputevents_processed.parquet\",\n",
    "        columns=[\"subject_id\", \"hadm_id\", \"charttime\", \"value\", \"label\"],\n",
    "    )\n",
    "    prescriptions = pd.read_parquet(\n",
    "        \"prescriptions_processed.parquet\",\n",
    "        columns=[\"subject_id\", \"hadm_id\", \"charttime\", \"dose_val_rx\", \"drug\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-12T14:34:20.927209Z",
     "iopub.status.busy": "2022-09-12T14:34:20.926675Z",
     "iopub.status.idle": "2022-09-12T14:34:24.041082Z",
     "shell.execute_reply": "2022-09-12T14:34:24.040309Z",
     "shell.execute_reply.started": "2022-09-12T14:34:20.927187Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for frame in (labevents, inputevents, outputevents, prescriptions):\n",
    "    display(pd.DataFrame({\"type\": frame.dtypes, \"uniques\": frame.nunique()}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labevents = pd.read_csv(\"/path/processed/lab_processed.csv\")[\n",
    "    [\"subject_id\", \"hadm_id\", \"charttime\", \"valuenum\", \"label\"]\n",
    "]\n",
    "inputevents = pd.read_csv(\"/path/processed/inputs_processed.csv\")[\n",
    "    [\"subject_id\", \"hadm_id\", \"charttime\", \"amount\", \"label\"]\n",
    "]\n",
    "outputevents = pd.read_csv(\"/path/processed/outputs_processed.csv\")[\n",
    "    [\"subject_id\", \"hadm_id\", \"charttime\", \"value\", \"label\"]\n",
    "]\n",
    "prescriptions = pd.read_csv(\"/path/processed/prescriptions_processed.csv\")[\n",
    "    [\"subject_id\", \"hadm_id\", \"charttime\", \"dose_val_rx\", \"drug\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the name of amount. Valuenum for every table\n",
    "inputevents[\"valuenum\"] = inputevents[\"amount\"]\n",
    "inputevents.head()\n",
    "inputevents = inputevents.drop(columns=[\"amount\"]).copy()\n",
    "\n",
    "outputevents[\"valuenum\"] = outputevents[\"value\"]\n",
    "outputevents = outputevents.drop(columns=[\"value\"]).copy()\n",
    "\n",
    "prescriptions[\"valuenum\"] = prescriptions[\"dose_val_rx\"]\n",
    "prescriptions = prescriptions.drop(columns=[\"dose_val_rx\"]).copy()\n",
    "prescriptions[\"label\"] = prescriptions[\"drug\"]\n",
    "prescriptions = prescriptions.drop(columns=[\"drug\"]).copy()\n",
    "prescriptions = prescriptions.drop((prescriptions[\"valuenum\"] == \"3-10\").index)\n",
    "\n",
    "# Tag to distinguish between lab and inputs events\n",
    "inputevents[\"Origin\"] = \"Inputs\"\n",
    "labevents[\"Origin\"] = \"Lab\"\n",
    "outputevents[\"Origin\"] = \"Outputs\"\n",
    "prescriptions[\"Origin\"] = \"Prescriptions\"\n",
    "\n",
    "# merge both dfs.\n",
    "merged_df1 = (inputevents.append(labevents)).reset_index()\n",
    "merged_df2 = (merged_df1.append(outputevents)).reset_index()\n",
    "merged_df2.drop(columns=\"level_0\", inplace=True)\n",
    "merged_df = (merged_df2.append(prescriptions)).reset_index()\n",
    "\n",
    "# Check that all labels have different names.\n",
    "assert merged_df[\"label\"].nunique() == (\n",
    "    inputevents[\"label\"].nunique()\n",
    "    + labevents[\"label\"].nunique()\n",
    "    + outputevents[\"label\"].nunique()\n",
    "    + prescriptions[\"label\"].nunique()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the timestamp as the time delta between the first chart time for each admission\n",
    "merged_df[\"charttime\"] = pd.to_datetime(\n",
    "    merged_df[\"charttime\"], format=\"%Y-%m-%d %H:%M:%S\"\n",
    ")\n",
    "ref_time = merged_df.groupby(\"hadm_id\")[\"charttime\"].min()\n",
    "merged_df_1 = pd.merge(\n",
    "    ref_time.to_frame(name=\"ref_time\"), merged_df, left_index=True, right_on=\"hadm_id\"\n",
    ")\n",
    "merged_df_1[\"time_stamp\"] = merged_df_1[\"charttime\"] - merged_df_1[\"ref_time\"]\n",
    "assert len(merged_df_1.loc[merged_df_1[\"time_stamp\"] < timedelta(hours=0)].index) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a label code (int) for the labels.\n",
    "label_dict = dict(\n",
    "    zip(\n",
    "        list(merged_df_1[\"label\"].unique()),\n",
    "        range(len(list(merged_df_1[\"label\"].unique()))),\n",
    "    )\n",
    ")\n",
    "merged_df_1[\"label_code\"] = merged_df_1[\"label\"].map(label_dict)\n",
    "\n",
    "merged_df_short = merged_df_1[\n",
    "    [\"hadm_id\", \"valuenum\", \"time_stamp\", \"label_code\", \"Origin\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict_df = pd.Series(merged_df_1[\"label\"].unique()).reset_index()\n",
    "label_dict_df.columns = [\"index\", \"label\"]\n",
    "label_dict_df[\"label_code\"] = label_dict_df[\"label\"].map(label_dict)\n",
    "label_dict_df.drop(columns=[\"index\"], inplace=True)\n",
    "label_dict_df.to_csv(\"/path/processed/label_dict.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_short[\"valuenum\"] = merged_df_short[\"valuenum\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only values within first 48 hours\n",
    "merged_df_short = merged_df_short.loc[\n",
    "    (merged_df_short[\"time_stamp\"] < timedelta(hours=48))\n",
    "]\n",
    "merged_df_short[\"time_stamp\"] = (\n",
    "    merged_df_short[\"time_stamp\"].dt.total_seconds().div(60).astype(int)\n",
    ")\n",
    "print(\"Number of patients considered: \" + str(merged_df_short[\"hadm_id\"].nunique()))\n",
    "assert len(merged_df_short.loc[merged_df_short[\"time_stamp\"] > 2880].index) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns that are not needed for final dataset\n",
    "merged_df_short.drop([\"Origin\"], axis=1, inplace=True)\n",
    "complete_df = merged_df_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create value- and mask- columns and fill with data\n",
    "labels = complete_df[\"label_code\"].unique()\n",
    "value_columns = []\n",
    "mask_columns = []\n",
    "for num in labels:\n",
    "    name = \"Value_label_\" + str(num)\n",
    "    name2 = \"Mask_label_\" + str(num)\n",
    "    value_columns.append(name)\n",
    "    mask_columns.append(name2)\n",
    "    complete_df[name] = 0\n",
    "    complete_df[name2] = 0\n",
    "    complete_df[name] = complete_df[name].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df.dropna(inplace=True)\n",
    "for index, row in complete_df.iterrows():\n",
    "    name = \"Value_label_\" + str(row[\"label_code\"].astype(int))\n",
    "    name2 = \"Mask_label_\" + str(row[\"label_code\"].astype(int))\n",
    "    complete_df.at[index, name] = row[\"valuenum\"]\n",
    "    complete_df.at[index, name2] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all unneccesary columns and do sanity check\n",
    "complete_df.drop([\"valuenum\", \"label_code\"], axis=1, inplace=True)\n",
    "complete_df = complete_df.groupby([\"hadm_id\", \"time_stamp\"], as_index=False).max()\n",
    "for x in mask_columns:\n",
    "    assert len(complete_df.loc[complete_df[x] > 1]) == 0\n",
    "complete_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df.to_csv(\"/path/processed/full_dataset.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

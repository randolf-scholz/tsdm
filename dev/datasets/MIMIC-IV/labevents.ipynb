{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIMIC 4 data - dataset construction labevents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "from pathlib import Path\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import pandas as pd\n",
    "import pyarrow\n",
    "import pyarrow.csv\n",
    "import pyarrow.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load `labevents` and `labitems` tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rawdata_file = Path.cwd() / \"mimic-iv-1.0.zip\"\n",
    "dataset_path = Path.cwd() / \"processed\"\n",
    "rawdata_path = Path.cwd() / \"raw\"\n",
    "\n",
    "files = {\n",
    "    \"labevents\": \"mimic-iv-1.0/hosp/labevents.csv.gz\",\n",
    "    \"labitems\": \"mimic-iv-1.0/hosp/d_labitems.csv.gz\",\n",
    "}\n",
    "\n",
    "CATEGORY = pyarrow.dictionary(\"int32\", \"string\")\n",
    "ID_TYPE = \"int32\"  # pyarrow.dictionary(\"int32\", \"int32\", ordered=True)\n",
    "\n",
    "column_types = {\n",
    "    \"labevents\": {\n",
    "        \"labevent_id\": ID_TYPE,\n",
    "        \"subject_id\": ID_TYPE,\n",
    "        \"hadm_id\": ID_TYPE,\n",
    "        \"specimen_id\": ID_TYPE,\n",
    "        \"itemid\": ID_TYPE,\n",
    "        \"charttime\": \"timestamp[s]\",\n",
    "        \"storetime\": \"timestamp[s]\",\n",
    "        \"value\": CATEGORY,\n",
    "        \"valuenum\": \"float32\",\n",
    "        \"valueuom\": CATEGORY,\n",
    "        \"ref_range_lower\": \"float32\",\n",
    "        \"ref_range_upper\": \"float32\",\n",
    "        \"flag\": CATEGORY,\n",
    "        \"priority\": CATEGORY,\n",
    "        \"comments\": \"string\",\n",
    "    },\n",
    "    \"labitems\": {\n",
    "        \"itemid\": ID_TYPE,\n",
    "        \"label\": CATEGORY,\n",
    "        \"fluid\": CATEGORY,\n",
    "        \"category\": CATEGORY,\n",
    "        \"loinc_code\": CATEGORY,\n",
    "    },\n",
    "}\n",
    "\n",
    "null_values = [\n",
    "    \"-\",\n",
    "    \"-1.#IND\",\n",
    "    \"-1.#QNAN\",\n",
    "    \"-NaN\",\n",
    "    \"-nan\",\n",
    "    \"?\",\n",
    "    \"\",\n",
    "    \"#N/A N/A\",\n",
    "    \"#N/A\",\n",
    "    \"#NA\",\n",
    "    \"#na\",\n",
    "    \"<N/A>\",\n",
    "    \"<n/a>\",\n",
    "    \"<NA>\",\n",
    "    \"<na>\",\n",
    "    \"1.#IND\",\n",
    "    \"1.#QNAN\",\n",
    "    \"INFORMATION NOT AVAILABLE\",\n",
    "    \"N/A\",\n",
    "    \"n/a\",\n",
    "    \"NA\",\n",
    "    \"na\",\n",
    "    \"NAN\",\n",
    "    \"NaN\",\n",
    "    \"nan\",\n",
    "    \"NONE\",\n",
    "    \"None\",\n",
    "    \"none\",\n",
    "    \"NULL\",\n",
    "    \"NULL\",\n",
    "    \"Null\",\n",
    "    \"null\",\n",
    "    \"UNABLE TO OBTAIN\",\n",
    "    \"UNKNOWN\",\n",
    "    \"unknown\",\n",
    "]\n",
    "\n",
    "types_map = {\n",
    "    \"string\": pd.StringDtype(),\n",
    "    \"bool\": pd.BooleanDtype(),\n",
    "    \"int8\": pd.Int8Dtype(),\n",
    "    \"int16\": pd.Int16Dtype(),\n",
    "    \"int32\": pd.Int32Dtype(),\n",
    "    \"int64\": pd.Int64Dtype(),\n",
    "    \"uint8\": pd.UInt8Dtype(),\n",
    "    \"uint16\": pd.UInt16Dtype(),\n",
    "    \"uint32\": pd.UInt32Dtype(),\n",
    "    \"uint64\": pd.UInt64Dtype(),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load `labevents` table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# shape: (120M, 15) ⇝ 1.8B values.\n",
    "key = \"labevents\"\n",
    "with (\n",
    "    ZipFile(rawdata_file) as archive,\n",
    "    archive.open(files[key]) as compressed_file,\n",
    "    gzip.open(compressed_file) as file,\n",
    "):\n",
    "    labevents = pyarrow.csv.read_csv(\n",
    "        file,\n",
    "        convert_options=pyarrow.csv.ConvertOptions(\n",
    "            column_types=column_types[key],\n",
    "            strings_can_be_null=True,\n",
    "            null_values=null_values,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "labevents.shape, labevents.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store and reload as pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pyarrow.parquet.write_table(labevents, rawdata_path / f\"{key}.parquet\")\n",
    "\n",
    "labevents = labevents.to_pandas(self_destruct=True, types_mapper=types_map.get)\n",
    "print(labevents.dtypes)\n",
    "labevents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load `labitems` table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# shape: (120M, 15) ⇝ 1.8B values.\n",
    "key = \"labitems\"\n",
    "with (\n",
    "    ZipFile(rawdata_file) as archive,\n",
    "    archive.open(files[key]) as compressed_file,\n",
    "    gzip.open(compressed_file) as file,\n",
    "):\n",
    "    labitems = pyarrow.csv.read_csv(\n",
    "        file,\n",
    "        convert_options=pyarrow.csv.ConvertOptions(\n",
    "            column_types=column_types[key],\n",
    "            strings_can_be_null=True,\n",
    "            null_values=null_values,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "labitems.shape, labitems.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store and reload as pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pyarrow.parquet.write_table(labitems, rawdata_path / f\"{key}.parquet\")\n",
    "\n",
    "labitems = labitems.to_pandas(self_destruct=True, types_mapper=types_map.get)\n",
    "labitems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Only keep labevents associated with the selected patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "admissions = pd.read_parquet(dataset_path / \"admissions_processed.parquet\")\n",
    "\n",
    "for key in [\"hadm_id\", \"subject_id\"]:\n",
    "    mask = labevents[key].isin(admissions[key])\n",
    "    labevents = labevents[mask]\n",
    "    print(f\"Removing {(~mask).sum()} {key}\")\n",
    "    print(f\"Number of patients remaining: {labevents['subject_id'].nunique()}\")\n",
    "    print(f\"Number of admissions remaining: {labevents['hadm_id'].nunique()}\")\n",
    "    print(f\"Number of events remaining: {labevents.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only keep labevents with float measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labevents = labevents[labevents[\"valuenum\"].notna()]\n",
    "print(f\"Number of events remaining: {labevents.shape}\")\n",
    "print(f\"Number of patients remaining: {labevents.subject_id.nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Merge on `ItemID`, only select tests that were given to many people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labevents = pd.merge(labevents, labitems, on=\"itemid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_variables = [\n",
    "    \"Albumin\",\n",
    "    \"Alanine Aminotransferase (ALT)\",\n",
    "    \"Alkaline Phosphatase\",\n",
    "    \"Anion Gap\",\n",
    "    \"Asparate Aminotransferase (AST)\",\n",
    "    \"Base Excess\",\n",
    "    \"Basophils\",\n",
    "    \"Bicarbonate\",\n",
    "    \"Bilirubin, Total\",\n",
    "    \"Calcium, Total\",\n",
    "    \"Calculated Total CO2\",\n",
    "    \"Chloride\",\n",
    "    \"Creatinine\",\n",
    "    \"Eosinophils\",\n",
    "    \"Glucose\",\n",
    "    \"Hematocrit\",\n",
    "    \"Hemoglobin\",\n",
    "    \"Lactate\",\n",
    "    \"Lymphocytes\",\n",
    "    \"MCH\",\n",
    "    \"MCV\",\n",
    "    \"Magnesium\",\n",
    "    \"Monocytes\",\n",
    "    \"Neutrophils\",\n",
    "    \"PT\",\n",
    "    \"PTT\",\n",
    "    \"Phosphate\",\n",
    "    \"Platelet Count\",\n",
    "    \"Potassium\",\n",
    "    \"RDW\",\n",
    "    \"Red Blood Cells\",\n",
    "    \"Sodium\",\n",
    "    \"Specific Gravity\",\n",
    "    \"Urea Nitrogen\",\n",
    "    \"White Blood Cells\",\n",
    "    \"pCO2\",\n",
    "    \"pH\",\n",
    "    \"pO2\",\n",
    "]\n",
    "\n",
    "labevents = labevents[labevents[\"label\"].isin(selected_variables)]\n",
    "print(f\"Number of patients remaining: {labevents.subject_id.nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_freq = labevents.groupby(\"label\")[\"subject_id\"].nunique()\n",
    "# common_tests = test_freq.sort_values(ascending=False).index[:150]\n",
    "# labevents = labevents[labevents[\"label\"].isin(common_tests)]\n",
    "# print(f\"Number of patients remaining: {labevents.subject_id.nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serialize Pre-processed DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Clean categories\n",
    "\n",
    "\n",
    "def clean_categories(df):\n",
    "    for col in df:\n",
    "        if df[col].dtype == \"category\":\n",
    "            df[col] = df[col].cat.remove_unused_categories()\n",
    "    return df\n",
    "\n",
    "\n",
    "labevents = clean_categories(labevents)\n",
    "labevents.to_parquet(dataset_path / \"labevents_processed.parquet\")\n",
    "labevents.shape, labevents.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labevents.subject_id"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the MIMIC 3 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MIMIC3 can be downloaded from [here](https://mimic.physionet.org/gettingstarted/access/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the same preprocessing as the authors of the GRU-ODE-Bayer paper and provide the final data preparation notebook that is missing in the original repository. First, execute the notebooks *admissions*, *outputs*, *labevents* and *prescriptions* provided [here](https://github.com/edebrouwer/gru_ode_bayes/tree/master/data_preproc/MIMIC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context(\"string_storage\", \"pyarrow\"):\n",
    "    labevents = pd.read_parquet(\"labevents_processed.parquet\", columns=)\n",
    "    inputevents = pd.read_parquet(\"inputevents_processed.parquet\", columns=)\n",
    "    outputevents = pd.read_parquet(\"outputevents_processed.parquet\", columns=)\n",
    "    prescriptions = pd.read_parquet(\"prescriptions_processed.parquet\", columns=)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"path\"\n",
    "outfile_path = \"path\"\n",
    "lab_df = pd.read_csv(file_path + \"LAB_processed.csv\")[\n",
    "    [\"SUBJECT_ID\", \"HADM_ID\", \"CHARTTIME\", \"VALUENUM\", \"LABEL\"]\n",
    "]\n",
    "inputs_df = pd.read_csv(file_path + \"INPUTS_processed.csv\")[\n",
    "    [\"SUBJECT_ID\", \"HADM_ID\", \"CHARTTIME\", \"AMOUNT\", \"LABEL\"]\n",
    "]\n",
    "outputs_df = pd.read_csv(file_path + \"OUTPUTS_processed.csv\")[\n",
    "    [\"SUBJECT_ID\", \"HADM_ID\", \"CHARTTIME\", \"VALUE\", \"LABEL\"]\n",
    "]\n",
    "presc_df = pd.read_csv(file_path + \"PRESCRIPTIONS_processed.csv\")[\n",
    "    [\"SUBJECT_ID\", \"HADM_ID\", \"CHARTTIME\", \"DOSE_VAL_RX\", \"DRUG\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_df[\"VALUENUM\"] = inputs_df[\"AMOUNT\"]\n",
    "inputs_df.head()\n",
    "inputs_df = inputs_df.drop(columns=[\"AMOUNT\"]).copy()\n",
    "\n",
    "outputs_df[\"VALUENUM\"] = outputs_df[\"VALUE\"]\n",
    "outputs_df = outputs_df.drop(columns=[\"VALUE\"]).copy()\n",
    "\n",
    "presc_df[\"VALUENUM\"] = presc_df[\"DOSE_VAL_RX\"]\n",
    "presc_df = presc_df.drop(columns=[\"DOSE_VAL_RX\"]).copy()\n",
    "presc_df[\"LABEL\"] = presc_df[\"DRUG\"]\n",
    "presc_df = presc_df.drop(columns=[\"DRUG\"]).copy()\n",
    "\n",
    "inputs_df[\"Origin\"] = \"Inputs\"\n",
    "lab_df[\"Origin\"] = \"Lab\"\n",
    "outputs_df[\"Origin\"] = \"Outputs\"\n",
    "presc_df[\"Origin\"] = \"Prescriptions\"\n",
    "\n",
    "merged_df1 = (inputs_df.append(lab_df)).reset_index()\n",
    "merged_df2 = (merged_df1.append(outputs_df)).reset_index()\n",
    "merged_df2.drop(columns=\"level_0\", inplace=True)\n",
    "merged_df = (merged_df2.append(presc_df)).reset_index()\n",
    "\n",
    "assert merged_df[\"LABEL\"].nunique() == (\n",
    "    inputs_df[\"LABEL\"].nunique()\n",
    "    + lab_df[\"LABEL\"].nunique()\n",
    "    + outputs_df[\"LABEL\"].nunique()\n",
    "    + presc_df[\"LABEL\"].nunique()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[\"CHARTTIME\"] = pd.to_datetime(\n",
    "    merged_df[\"CHARTTIME\"], format=\"%Y-%m-%d %H:%M:%S\"\n",
    ")\n",
    "ref_time = merged_df.groupby(\"HADM_ID\")[\"CHARTTIME\"].min()\n",
    "\n",
    "merged_df_1 = pd.merge(\n",
    "    ref_time.to_frame(name=\"REF_TIME\"), merged_df, left_index=True, right_on=\"HADM_ID\"\n",
    ")\n",
    "merged_df_1[\"TIME_STAMP\"] = merged_df_1[\"CHARTTIME\"] - merged_df_1[\"REF_TIME\"]\n",
    "assert len(merged_df_1.loc[merged_df_1[\"TIME_STAMP\"] < timedelta(hours=0)].index) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = dict(\n",
    "    zip(\n",
    "        list(merged_df_1[\"LABEL\"].unique()),\n",
    "        range(len(list(merged_df_1[\"LABEL\"].unique()))),\n",
    "    )\n",
    ")\n",
    "merged_df_1[\"LABEL_CODE\"] = merged_df_1[\"LABEL\"].map(label_dict)\n",
    "\n",
    "merged_df_short = merged_df_1[\n",
    "    [\"HADM_ID\", \"VALUENUM\", \"TIME_STAMP\", \"LABEL_CODE\", \"Origin\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict_df = pd.Series(merged_df_1[\"LABEL\"].unique()).reset_index()\n",
    "label_dict_df.columns = [\"index\", \"LABEL\"]\n",
    "label_dict_df[\"LABEL_CODE\"] = label_dict_df[\"LABEL\"].map(label_dict)\n",
    "label_dict_df.drop(columns=[\"index\"], inplace=True)\n",
    "label_dict_df.to_csv(outfile_path + \"label_dict.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_short[\"valuenum\"] = merged_df_short[\"valuenum\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_short = merged_df_short.loc[(merged_df_short[\"TIME_STAMP\"] < 2880)]\n",
    "print(\"Number of patients considered :\" + str(merged_df_short[\"HADM_ID\"].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_short.drop([\"Origin\"], axis=1, inplace=True)\n",
    "merged_df_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_short = complete_df\n",
    "labels = complete_df[\"LABEL_CODE\"].unique()\n",
    "value_columns = []\n",
    "mask_columns = []\n",
    "for num in labels:\n",
    "    name = \"Value_label_\" + str(num)\n",
    "    name2 = \"Mask_label_\" + str(num)\n",
    "    value_columns.append(name)\n",
    "    mask_columns.append(name2)\n",
    "    complete_df[name] = 0\n",
    "    complete_df[name2] = 0\n",
    "    complete_df[name] = complete_df[name].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df.dropna(inplace=True)\n",
    "for index, row in complete_df.iterrows():\n",
    "    name = \"Value_label_\" + str(row[\"LABEL_CODE\"].astype(int))\n",
    "    name2 = \"Mask_label_\" + str(row[\"LABEL_CODE\"].astype(int))\n",
    "    complete_df.at[index, name] = row[\"VALUENUM\"]\n",
    "    complete_df.at[index, name2] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df.drop([\"VALUENUM\", \"LABEL_CODE\"], axis=1, inplace=True)\n",
    "complete_df = complete_df.groupby([\"HADM_ID\", \"TIME_STAMP\"], as_index=False).max()\n",
    "for x in mask_columns:\n",
    "    assert len(complete_df.loc[complete_df[x] > 1]) == 0\n",
    "complete_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df = complete_df.groupby([\"hadm_id\", \"time_stamp\"], as_index=False).max()\n",
    "complete_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ids = np.arange(complete_df[\"hadm_id\"].nunique())\n",
    "np.random.shuffle(unique_ids)\n",
    "d = dict(zip(complete_df[\"hadm_id\"].unique(), unique_ids))\n",
    "\n",
    "Unique_id_dict = pd.Series(complete_df[\"hadm_id\"].unique()).reset_index().copy()\n",
    "Unique_id_dict.columns = [\"index\", \"hadm_id\"]\n",
    "Unique_id_dict[\"unique_id\"] = Unique_id_dict[\"hadm_id\"].map(d)\n",
    "Unique_id_dict.to_csv(\"unique_id_dict.csv\")\n",
    "\n",
    "unique_id_df = pd.read_csv(\"unique_id_dict.csv\")\n",
    "d = dict(zip(unique_id_df[\"hadm_id\"].values, unique_id_df[\"unique_id\"].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "admissions = pd.read_csv(\"admissions_processed.csv\")\n",
    "death_tags_s = (\n",
    "    admissions.groupby(\"hadm_id\")[\"deathtag\"]\n",
    "    .unique()\n",
    "    .astype(int)\n",
    "    .to_frame()\n",
    "    .reset_index()\n",
    ")\n",
    "death_tags_df = death_tags_s.loc[\n",
    "    death_tags_s[\"hadm_id\"].isin(complete_df[\"hadm_id\"])\n",
    "].copy()\n",
    "death_tags_df[\"unique_id\"] = death_tags_df[\"hadm_id\"].map(d)\n",
    "death_tags_df.sort_values(by=\"unique_id\", inplace=True)\n",
    "death_tags_df.rename(columns={\"deathtag\": \"Value\"}, inplace=True)\n",
    "death_tags_df.set_index(\"unique_id\", inplace=True)\n",
    "death_tags_df.drop(\"hadm_id\", axis=1, inplace=True)\n",
    "death_tags_df.to_csv(\"complete_death_tags.csv\")\n",
    "\n",
    "complete_df[\"unique_id\"] = complete_df[\"hadm_id\"].map(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df.rename(columns={\"unique_id\": \"ID\", \"time_stamp\": \"Time\"}, inplace=True)\n",
    "complete_df.drop([\"hadm_id\"], axis=1, inplace=True)\n",
    "complete_df.set_index([\"ID\"], inplace=True)\n",
    "complete_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df.to_csv(\"full_dataset.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

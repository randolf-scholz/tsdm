{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing KIWI dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Validation\n",
    "\n",
    "Format\n",
    "\n",
    "```python\n",
    "data: tuple[\n",
    "    dict[\n",
    "        'description': set[str],\n",
    "        'variables': list[dict[str, str]],\n",
    "        'time_format': str,\n",
    "        'series': dict[int, \n",
    "            dict['generating_parameters': \n",
    "                 dict[\n",
    "                     'qsmax': float,\n",
    "                     'qm': float,\n",
    "                     'qamax': float,\n",
    "                     'Yem': float,\n",
    "                     'Yxsof': float,\n",
    "                     'Yxa': float,\n",
    "                     'Yos': float,\n",
    "                     'Yoa': float,\n",
    "                     'Yas': float,\n",
    "                     'Kia': float,\n",
    "                     'Ks': float,\n",
    "                     'Ko': float,\n",
    "                     'Kap': float,\n",
    "                     'Kis': float,\n",
    "                     'Ksa': float,\n",
    "                     'Pamax': float,\n",
    "                     'F0': float,\n",
    "                     'mu_set': float,\n",
    "                     'C_feed': float,\n",
    "                     'Kp': float,\n",
    "                ]\n",
    "            ],\n",
    "        ],\n",
    "    ], \n",
    "    dict[int, DataFrame[columns=['X', 'S', 'A', 'DOTm', 'V', 'pulse', 'kLa']]]\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InteractiveShell.ast_node_interactivity='last_expr_or_assign'  # always print last expr.\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format\n",
    "\n",
    "\n",
    "```python\n",
    "dict[int, # run_id\n",
    "    dict[int, # experiment_id\n",
    "         dict[\n",
    "             'metadata',: DataFrame,                # static\n",
    "             'setpoints': DataFrame,                # static\n",
    "             'measurements_reactor',: DataFrame,    # TimeTensor\n",
    "             'measurements_array',: DataFrame,      # TimeTensor\n",
    "             'measurements_aggregated': DataFrame,  # TimeTensor\n",
    "         ]\n",
    "    ]\n",
    "]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas\n",
    "import pandas as pd\n",
    "from cross_validate_kiwi_runs import ReplicateBasedSplitter, create_replicate_dict\n",
    "from pandas import DataFrame\n",
    "\n",
    "with open(\"kiwi_experiments_and_run_355.pk\", \"rb\") as file:\n",
    "    data = pickle.load(file)\n",
    "\n",
    "col_run_to_exp = create_replicate_dict(data)\n",
    "splitter = ReplicateBasedSplitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA = [\n",
    "    (data[run][exp] | {\"run_id\": run, \"experiment_id\": exp})\n",
    "    for run in data\n",
    "    for exp in data[run]\n",
    "]\n",
    "DF = DataFrame(DATA).set_index([\"run_id\", \"experiment_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw-Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tables = {}\n",
    "\n",
    "for key in (\n",
    "    \"metadata\",\n",
    "    \"setpoints\",\n",
    "    \"measurements_reactor\",\n",
    "    \"measurements_array\",\n",
    "    \"measurements_aggregated\",\n",
    "):\n",
    "    if key == \"metadata\":\n",
    "        tables[key] = pd.concat(iter(DF[key])).reset_index(drop=True)\n",
    "    else:\n",
    "        tables[key] = (\n",
    "            pd.concat(iter(DF[key]), keys=DF[key].index)\n",
    "            .reset_index(level=2, drop=True)\n",
    "            .reset_index()\n",
    "        )\n",
    "\n",
    "tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.number?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_no_information(series) -> bool:\n",
    "    return len(series.dropna().unique()) <= 1\n",
    "\n",
    "\n",
    "def contains_nan_slice(series, slices, two_enough: bool = False) -> bool:\n",
    "    num_missing = 0\n",
    "    for idx in slices:\n",
    "        if pd.isna(series[idx]).all():\n",
    "            num_missing += 1\n",
    "\n",
    "    if (num_missing > 0 and not two_enough) or (\n",
    "        num_missing >= len(slices) - 1 and two_enough\n",
    "    ):\n",
    "        print(f\"{series.name}: data missing in {num_missing}/{len(slices)} slices!\")\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def float_is_int(series) -> bool:\n",
    "    mask = pd.notna(series)\n",
    "    return series[mask].apply(float.is_integer).all()\n",
    "\n",
    "def is_bool(vals) -> bool:\n",
    "    dtype = \n",
    "    if np.issubdtype(vals.dtype, np.bool_):\n",
    "        return True\n",
    "    elif np.issubdtype(vals.dtype, np.integer) and len(vals)==2:\n",
    "        if np.all(vals==0 ^ vals==1) or np.all(vals==-1 ^ vals==1):\n",
    "            return Ture\n",
    "    elif np.issubdtype(vals.dtype, np.floating) and len(vals)==2:\n",
    "        if np.all(vals==0 ^ vals==1) or np.all(vals==-1 ^ vals==1):\n",
    "            return True\n",
    "    elif np.issubdtype(vals.dtype, pandas.StringDtype and len(vals)==2):\n",
    "        val1, val2 = set(vals)\n",
    "        val1 = str(val1).lower()\n",
    "        val2 = str(val2).lower()\n",
    "        if {val1, val2} in ({\"0\", \"1\"}, {\"-1\", \"+1\"}, {\"-1\", \"1\"}, {\"t\", \"f\"}, {\"true\", \"false\"}, {\"y\", \"n\"}, {\"yes\", \"no\"}):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def \n",
    "\n",
    "def get_true_column_dtypes(table) -> dict[str, str]:\n",
    "    dtypes = {}\n",
    "    for col in table:\n",
    "        series = table[col]\n",
    "        mask = pd.notna(series)\n",
    "        vals = series[mask].unique()\n",
    "\n",
    "def get_integer_cols(df) -> set[str]:\n",
    "    cols = set()\n",
    "    for col in table[selected_columns]:\n",
    "        if np.issubdtype(table[col].dtype, np.integer):\n",
    "            print(f\"Integer column                       : {col}\")\n",
    "            cols.add(col)\n",
    "        elif np.issubdtype(table[col].dtype, np.floating) and float_is_int(table[col]):\n",
    "            print(f\"Integer column pretending to be float: {col}\")\n",
    "            cols.add(col)\n",
    "    return cols\n",
    "\n",
    "def get_useless_cols(df, strict: bool=False) -> set[str]:\n",
    "    useless_cols = set()\n",
    "    for col in table:\n",
    "        s = table[col]\n",
    "        if col in (\"run_id\", \"experiment_id\"):\n",
    "            continue\n",
    "        if contains_no_information(s):\n",
    "            print(f\"No information in      {col}\")\n",
    "            useless_cols.add(col)\n",
    "        elif contains_nan_slice(s, run_masks, two_enough=(not strict)):\n",
    "            print(f\"Missing for some run   {col}\")\n",
    "            useless_cols.add(col)\n",
    "    return useless_cols\n",
    "\n",
    "def get_μ_set(s: str):\n",
    "    if pd.isna(s):\n",
    "        return s\n",
    "    s = s.strip().lstrip(\"µ_set: \").strip()\n",
    "    percent, s = s.split(\", \")\n",
    "    value = s.strip().rstrip(\"mM IPTG\").strip()\n",
    "    return percent, value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### MetaData Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = metadata = tables[\"metadata\"]\n",
    "runs = table[\"run_id\"].dropna().unique()\n",
    "run_masks = [table[\"run_id\"] == run for run in runs]\n",
    "\n",
    "useless_cols = set()\n",
    "\n",
    "for col in table:\n",
    "    s = table[col]\n",
    "    if col in (\"run_id\", \"experiment_id\"):\n",
    "        continue\n",
    "    if contains_no_information(s):\n",
    "        print(f\"No information in      {col}\")\n",
    "        useless_cols.add(col)\n",
    "    elif contains_nan_slice(s, run_masks):\n",
    "        print(f\"Missing for some run   {col}\")\n",
    "        useless_cols.add(col)\n",
    "\n",
    "# drop the following specific columns\n",
    "useless_cols |= {\n",
    "    \"folder_id_y\",\n",
    "    \"ph_Base_conc\",\n",
    "    \"ph_Ki\",\n",
    "    \"ph_Kp\",\n",
    "    \"ph_Tolerance\",\n",
    "    \"pms_id\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metadata_columns = {\n",
    "    \"bioreactor_id\",\n",
    "    \"container_number\",\n",
    "    \"experiment_id\",\n",
    "    \"run_id\",\n",
    "    \"profile_id\",\n",
    "    \"color\",\n",
    "    \"profile_name\",\n",
    "    \"organism_id\",\n",
    "    \"OD_Dilution\",\n",
    "    \"run_name\",\n",
    "    \"start_time\",\n",
    "    \"end_time\",\n",
    "}\n",
    "\n",
    "remaining_cols = set(metadata.columns) - useless_cols\n",
    "assert (\n",
    "    metadata_columns >= set(metadata.columns) - useless_cols\n",
    "), f\"Superfluous {metadata_columns - remaining_cols}\"\n",
    "assert (\n",
    "    metadata_columns <= set(metadata.columns) - useless_cols\n",
    "), f\"You forgot to check {metadata_columns - remaining_cols}\"\n",
    "\n",
    "\n",
    "metadata_dtypes = {\n",
    "    \"experiment_id\": \"UInt32\",\n",
    "    \"bioreactor_id\": \"UInt32\",\n",
    "    \"container_number\": \"UInt32\",\n",
    "    \"profile_id\": \"UInt32\",\n",
    "    \"color\": \"string\",\n",
    "    \"profile_name\": \"string\",\n",
    "    \"organism_id\": \"UInt32\",\n",
    "    \"run_id\": \"UInt32\",\n",
    "    \"OD_Dilution\": \"float32\",\n",
    "    \"run_name\": \"string\",\n",
    "    \"start_time\": \"datetime64[ns]\",\n",
    "    \"end_time\": \"datetime64[ns]\",\n",
    "}\n",
    "\n",
    "assert metadata_columns >= set(\n",
    "    metadata_dtypes\n",
    "), f\"Superfluous encoing  {set(metadata_dtypes) - metadata_columns}\"\n",
    "assert metadata_columns <= set(\n",
    "    metadata_dtypes\n",
    "), f\"You forgot to encode {metadata_columns - set(metadata_dtypes)}\"\n",
    "\n",
    "metadata_categoricals = {\n",
    "    \"profile_name\": \"category\",\n",
    "    \"run_name\": \"category\",\n",
    "    \"color\": \"category\",\n",
    "    \"OD_Dilution\": \"Float32\",\n",
    "}\n",
    "\n",
    "assert metadata_columns >= set(\n",
    "    metadata_categoricals\n",
    "), f\"Superfluous encoing {set(metadata_categoricals) - metadata_columns}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = metadata.astype(metadata_dtypes)\n",
    "metadata = metadata.astype(metadata_categoricals)\n",
    "metadata = metadata[metadata_columns]\n",
    "metadata = metadata.set_index([\"run_id\", \"experiment_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setpoint Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = setpoints = tables[\"setpoints\"]\n",
    "runs = table[\"run_id\"].dropna().unique()\n",
    "run_masks = [table[\"run_id\"] == run for run in runs]\n",
    "\n",
    "useless_cols = set()\n",
    "\n",
    "for col in table:\n",
    "    s = table[col]\n",
    "    if col in (\"run_id\", \"experiment_id\"):\n",
    "        continue\n",
    "    if contains_no_information(s):\n",
    "        print(f\"No information in      {col}\")\n",
    "        useless_cols.add(col)\n",
    "    elif contains_nan_slice(s, run_masks, two_enough=True):\n",
    "        print(f\"Missing for some run   {col}\")\n",
    "        useless_cols.add(col)\n",
    "\n",
    "# drop the following specific columns\n",
    "useless_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setpoint_columns = set(setpoints.columns)\n",
    "remaining_cols = setpoint_columns - useless_cols\n",
    "\n",
    "selected_columns = {\n",
    "    \"experiment_id\",\n",
    "    \"run_id\",\n",
    "    \"cultivation_age\",\n",
    "    \"setpoint_id\",\n",
    "    \"unit\",\n",
    "    \"Puls_Glucose\",\n",
    "    \"StirringSpeed\",\n",
    "    \"Feed_glc_cum_setpoints\",\n",
    "    \"Flow_Air\",\n",
    "    \"InducerConcentration\",\n",
    "}\n",
    "\n",
    "assert (\n",
    "    selected_columns >= setpoint_columns - useless_cols\n",
    "), f\"You forgot to check {remaining_cols - selected_columns}\"\n",
    "assert (\n",
    "    selected_columns <= setpoint_columns - useless_cols\n",
    "), f\"Superfluous {selected_columns - remaining_cols}\"\n",
    "\n",
    "setpoints_dtypes = {\n",
    "    \"experiment_id\": \"UInt32\",\n",
    "    \"run_id\": \"UInt32\",\n",
    "    \"cultivation_age\": \"UInt32\",\n",
    "    \"setpoint_id\": \"UInt32\",\n",
    "    \"unit\": \"string\",\n",
    "    \"Puls_AceticAcid\": \"Float32\",\n",
    "    \"Puls_Glucose\": \"Float32\",\n",
    "    \"Puls_Medium\": \"Float32\",\n",
    "    \"StirringSpeed\": \"UInt16\",\n",
    "    \"pH\": \"Float32\",\n",
    "    \"Feed_glc_cum_setpoints\": \"UInt16\",\n",
    "    \"Flow_Air\": \"UInt8\",\n",
    "    \"InducerConcentration\": \"Float32\",\n",
    "    \"Flow_Nitrogen\": \"Float32\",\n",
    "    \"Flow_O2\": \"Float32\",\n",
    "    \"Feed_dextrine_cum_setpoints\": \"Float32\",\n",
    "}\n",
    "\n",
    "assert (\n",
    "    set(setpoints_dtypes) <= setpoint_columns\n",
    "), f\"Superfluous encoing  {set(setpoints_dtypes) - setpoint_columns}\"\n",
    "assert (\n",
    "    set(setpoints_dtypes) >= selected_columns\n",
    "), f\"You forgot to encode {selected_columns - set(setpoints_dtypes)}\"\n",
    "\n",
    "setpoints_categoricals = {\n",
    "    \"unit\": \"category\",\n",
    "}\n",
    "\n",
    "assert set(setpoints_categoricals) <= set(\n",
    "    setpoints_dtypes\n",
    "), f\"Superfluous encoing {set(setpoints_categoricals) - set(setpoints_dtypes)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setpoints[\"unit\"] = setpoints[\"unit\"].replace(to_replace=\"-\", value=pd.NA)\n",
    "setpoints = setpoints.astype(setpoints_dtypes)\n",
    "setpoints = setpoints.astype(setpoints_categoricals)\n",
    "setpoints = setpoints[selected_columns]\n",
    "setpoints = setpoints.set_index([\"run_id\", \"experiment_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Measurements Reactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = measurements_reactor = tables[\"measurements_reactor\"]\n",
    "runs = table[\"run_id\"].dropna().unique()\n",
    "run_masks = [table[\"run_id\"] == run for run in runs]\n",
    "\n",
    "useless_cols = get_useless_cols(table)\n",
    "integer_cols = get_integer_cols(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_columns = set(table.columns)\n",
    "remaining_cols = table_columns - useless_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = {\n",
    "    \"Acetate\",\n",
    "    \"Base\",\n",
    "    \"Cumulated_feed_volume_glucose\",\n",
    "    \"Cumulated_feed_volume_medium\",\n",
    "    \"DOT\",\n",
    "    \"Fluo_GFP\",\n",
    "    \"Glucose\",\n",
    "    \"InducerConcentration\",\n",
    "    \"OD600\",\n",
    "    \"Probe_Volume\",\n",
    "    \"Volume\",\n",
    "    \"experiment_id\",\n",
    "    \"measurement_id\",\n",
    "    \"measurement_time\",\n",
    "    \"pH\",\n",
    "    \"run_id\",\n",
    "    \"unit\",\n",
    "}\n",
    "\n",
    "assert (\n",
    "    selected_columns >= table_columns - useless_cols\n",
    "), f\"You forgot to check {remaining_cols - selected_columns}\"\n",
    "assert (\n",
    "    selected_columns <= table_columns - useless_cols\n",
    "), f\"Superfluous {selected_columns - remaining_cols}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "table[selected_columns].dtypes.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "table[\"Base\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.dtyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reactor_dtypes = {\n",
    "    \"Acetate\"                       : \"Float32\",\n",
    "    \"Base\"                          : \"Int32\",\n",
    "    \"Cumulated_feed_volume_glucose\" : \"\",\n",
    "    \"Cumulated_feed_volume_medium\"  : \"\",\n",
    "    \"DOT\"                           : \"\",\n",
    "    \"Fluo_GFP\"                      : \"\",\n",
    "    \"Glucose\"                       : \"\",\n",
    "    \"InducerConcentration\"          : \"\",\n",
    "    \"OD600\"                         : \"\",\n",
    "    \"Probe_Volume\"                  : \"\",\n",
    "    \"Volume\"                        : \"\",\n",
    "    \"experiment_id\"                 : \"\",\n",
    "    \"measurement_id\"                : \"\",\n",
    "    \"measurement_time\"              : \"\",\n",
    "    \"pH\"                            : \"\",\n",
    "    \"run_id\"                        : \"\",\n",
    "    \"unit\"                          : \"\",\n",
    "}\n",
    "\n",
    "assert (\n",
    "    set(setpoints_dtypes) <= setpoint_columns\n",
    "), f\"Superfluous encoing  {set(setpoints_dtypes) - setpoint_columns}\"\n",
    "assert (\n",
    "    set(setpoints_dtypes) >= selected_columns\n",
    "), f\"You forgot to encode {selected_columns - set(setpoints_dtypes)}\"\n",
    "\n",
    "setpoints_categoricals = {\n",
    "    \"unit\": \"category\",\n",
    "}\n",
    "\n",
    "assert set(setpoints_categoricals) <= set(\n",
    "    setpoints_dtypes\n",
    "), f\"Superfluous encoing {set(setpoints_categoricals) - set(setpoints_dtypes)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = metadata.astype(metadata_dtypes)\n",
    "metadata = metadata.astype(metadata_categoricals)\n",
    "metadata = metadata[metadata_columns]\n",
    "metadata = metadata.set_index([\"run_id\", \"experiment_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measurements_Array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measurements Aggregated"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

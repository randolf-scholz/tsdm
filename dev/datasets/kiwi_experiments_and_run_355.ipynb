{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InteractiveShell.ast_node_interactivity='last_expr_or_assign'  # always print last expr.\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format\n",
    "\n",
    "\n",
    "```python\n",
    "dict[int, # run_id\n",
    "    dict[int, # experiment_id\n",
    "         dict[\n",
    "             'metadata',: DataFrame,                # static\n",
    "             'setpoints': DataFrame,                # static\n",
    "             'measurements_reactor',: DataFrame,    # TimeTensor\n",
    "             'measurements_array',: DataFrame,      # TimeTensor\n",
    "             'measurements_aggregated': DataFrame,  # TimeTensor\n",
    "         ]\n",
    "    ]\n",
    "]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from cross_validate_kiwi_runs import create_replicate_dict, ReplicateBasedSplitter\n",
    "\n",
    "with open(\"kiwi_experiments_and_run_355.pk\", \"rb\") as file:\n",
    "    data = pickle.load(file)\n",
    "\n",
    "col_run_to_exp = create_replicate_dict(data)\n",
    "splitter = ReplicateBasedSplitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA = [(data[run][exp] | {\"run_id\": run, \"experiment_id\": exp}) for run in data for exp in data[run]]\n",
    "DF = DataFrame(DATA).set_index([\"run_id\", \"experiment_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tables = {}\n",
    "\n",
    "for key in ('metadata', 'setpoints', 'measurements_reactor', 'measurements_array', 'measurements_aggregated'):\n",
    "    if key == \"metadata\":\n",
    "        tables[key] = pd.concat(iter(DF[key])).reset_index(drop=True)\n",
    "    else:\n",
    "        tables[key] = pd.concat(iter(DF[key]), keys=DF[key].index).reset_index(level=2, drop=True).reset_index()\n",
    "\n",
    "tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MetaData Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_no_information(series) -> bool:\n",
    "    return len(series.dropna().unique()) <= 1\n",
    "\n",
    "def contains_nan_slice(series, slices, two_enough: bool=False) -> bool:\n",
    "    num_missing = 0\n",
    "    for idx in slices:\n",
    "        if pd.isna(series[idx]).all():\n",
    "            num_missing += 1\n",
    "            \n",
    "    if (num_missing > 0 and not two_enough) or (num_missing >= len(slices)-1 and two_enough):\n",
    "        print(f\"{num_missing}/{len(slices)} missing\")\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def get_μ_set(s: str):\n",
    "    if pd.isna(s):\n",
    "        return s\n",
    "    s = s.strip().lstrip(\"µ_set: \").strip()\n",
    "    percent, s = s.split(\", \")\n",
    "    value = s.strip().rstrip(\"mM IPTG\").strip()\n",
    "    return percent, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = metadata = tables[\"metadata\"]\n",
    "runs = table[\"run_id\"].dropna().unique()\n",
    "run_masks = [table[\"run_id\"]==run for run in runs]\n",
    "\n",
    "useless_cols = set()\n",
    "\n",
    "for col in table:\n",
    "    s = table[col]\n",
    "    if col in (\"run_id\", \"experiment_id\"):\n",
    "        continue\n",
    "    if contains_no_information(s):\n",
    "        print(f\"No information in      {col}\")\n",
    "        useless_cols.add(col)\n",
    "    elif contains_nan_slice(s, run_masks):\n",
    "        print(f\"Missing for some run   {col}\")\n",
    "        useless_cols.add(col)\n",
    "\n",
    "# drop the following specific columns\n",
    "useless_cols |= {'folder_id_y', 'ph_Base_conc', 'ph_Ki', 'ph_Kp', 'ph_Tolerance', 'pms_id'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metadata_columns = {\n",
    "    \"bioreactor_id\",\n",
    "    \"container_number\",\n",
    "    \"experiment_id\",\n",
    "    \"run_id\",\n",
    "    \"profile_id\",\n",
    "    \"color\",\n",
    "    \"profile_name\",\n",
    "    \"organism_id\",\n",
    "    \"OD_Dilution\",\n",
    "    \"run_name\",\n",
    "    \"start_time\",\n",
    "    \"end_time\",\n",
    "}\n",
    "\n",
    "remaining_cols = set(metadata.columns) - useless_cols\n",
    "assert metadata_columns >= set(metadata.columns) - useless_cols, f\"Superfluous {metadata_columns - remaining_cols}\"\n",
    "assert metadata_columns <= set(metadata.columns) - useless_cols, f\"You forgot to check {metadata_columns - remaining_cols}\"\n",
    "\n",
    "\n",
    "metadata_dtypes = {\n",
    "    \"experiment_id\": \"UInt32\",\n",
    "    \"bioreactor_id\": \"UInt32\", \n",
    "    \"container_number\": \"UInt32\",\n",
    "    \"profile_id\": \"UInt32\",\n",
    "    \"color\": \"string\", \n",
    "    \"profile_name\": \"string\",\n",
    "    \"organism_id\": \"UInt32\",\n",
    "    \"run_id\": \"UInt32\",\n",
    "    \"OD_Dilution\": \"float32\",\n",
    "    \"run_name\": \"string\",\n",
    "    \"start_time\": \"datetime64[ns]\",\n",
    "    \"end_time\": \"datetime64[ns]\", \n",
    "}\n",
    "\n",
    "assert metadata_columns >= set(metadata_dtypes), f\"Superfluous encoing  {set(metadata_dtypes) - metadata_columns}\"\n",
    "assert metadata_columns <= set(metadata_dtypes), f\"You forgot to encode {metadata_columns - set(metadata_dtypes)}\"\n",
    "\n",
    "metadata_categoricals = {\n",
    "    \"profile_name\": \"category\",\n",
    "    \"run_name\": \"category\",\n",
    "    \"color\": \"category\",\n",
    "    \"OD_Dilution\": \"Float32\",\n",
    "}\n",
    "\n",
    "assert metadata_columns >= set(metadata_categoricals), f\"Superfluous encoing {set(metadata_categoricals) - metadata_columns}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = metadata.astype(metadata_dtypes)\n",
    "metadata = metadata.astype(metadata_categoricals)\n",
    "metadata = metadata[metadata_columns]\n",
    "metadata = metadata.set_index([\"run_id\", \"experiment_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setpoint Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = setpoints = tables[\"setpoints\"]\n",
    "runs = table[\"run_id\"].dropna().unique()\n",
    "run_masks = [table[\"run_id\"]==run for run in runs]\n",
    "\n",
    "useless_cols = set()\n",
    "\n",
    "for col in table:\n",
    "    s = table[col]\n",
    "    if col in (\"run_id\", \"experiment_id\"):\n",
    "        continue\n",
    "    if contains_no_information(s):\n",
    "        print(f\"No information in      {col}\")\n",
    "        useless_cols.add(col)\n",
    "    elif contains_nan_slice(s, run_masks, two_enough=True):\n",
    "        print(f\"Missing for some run   {col}\")\n",
    "        useless_cols.add(col)\n",
    "\n",
    "# drop the following specific columns\n",
    "useless_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "setpoint_columns = set(setpoints.columns)\n",
    "remaining_cols = setpoint_columns - useless_cols\n",
    "\n",
    "selected_columns = {\n",
    "    \"experiment_id\",\n",
    "    \"run_id\",\n",
    "    'cultivation_age',\n",
    "    'setpoint_id',\n",
    "    'unit',\n",
    "    'Puls_Glucose',\n",
    "    'StirringSpeed',\n",
    "    'Feed_glc_cum_setpoints',\n",
    "    'Flow_Air',\n",
    "    'InducerConcentration',\n",
    "}\n",
    "\n",
    "assert selected_columns >= setpoint_columns - useless_cols, f\"You forgot to check {remaining_cols - selected_columns}\"\n",
    "assert selected_columns <= setpoint_columns - useless_cols, f\"Superfluous {selected_columns - remaining_cols}\"\n",
    "\n",
    "setpoints_dtypes = {\n",
    "    \"experiment_id\"                  : \"UInt32\",\n",
    "    \"run_id\"                         : \"UInt32\",\n",
    "    \"cultivation_age\"                : \"UInt32\",\n",
    "    \"setpoint_id\"                    : \"UInt32\",\n",
    "    \"unit\"                           : \"string\",\n",
    "    \"Puls_AceticAcid\"                : \"Float32\",\n",
    "    \"Puls_Glucose\"                   : \"Float32\",\n",
    "    \"Puls_Medium\"                    : \"Float32\",\n",
    "    \"StirringSpeed\"                  : \"UInt16\",\n",
    "    \"pH\"                             : \"Float32\",\n",
    "    \"Feed_glc_cum_setpoints\"         : \"UInt16\",\n",
    "    \"Flow_Air\"                       : \"UInt8\",\n",
    "    \"InducerConcentration\"           : \"Float32\",\n",
    "    \"Flow_Nitrogen\"                  : \"Float32\",\n",
    "    \"Flow_O2\"                        : \"Float32\",\n",
    "    \"Feed_dextrine_cum_setpoints\"    : \"Float32\",\n",
    "}\n",
    "\n",
    "assert set(setpoints_dtypes) <= setpoint_columns, f\"Superfluous encoing  {set(setpoints_dtypes) - setpoint_columns}\"\n",
    "assert set(setpoints_dtypes) >= selected_columns, f\"You forgot to encode {selected_columns - set(setpoints_dtypes)}\"\n",
    "\n",
    "setpoints_categoricals = {\n",
    "    \"unit\"  : \"category\",\n",
    "}\n",
    "\n",
    "assert set(setpoints_categoricals) <= set(setpoints_dtypes), f\"Superfluous encoing {set(setpoints_categoricals) - set(setpoints_dtypes)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "setpoints[\"unit\"] = setpoints[\"unit\"].replace(to_replace=\"-\", value=pd.NA)\n",
    "setpoints = setpoints.astype(setpoints_dtypes)\n",
    "setpoints = setpoints.astype(setpoints_categoricals)\n",
    "setpoints = setpoints[selected_columns]\n",
    "setpoints = setpoints.set_index([\"run_id\", \"experiment_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "setpoints[\"unit\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "[col for col in setpoints if len(setpoints[col].unique())>2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(setpoints[\"Feed_glc_cum_setpoints\"], setpoints[\"Feed_glc_cum_setpoints\"].astype(\"Int32\").astype(\"float\"), equal_nan=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "setpoints[\"pH\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata[\"pH_correction_factor\"].astype(pd.Float32Dtype())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.astype(dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata[\"organism_id\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata['folder_id_x'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF['setpoints'].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(DF['setpoints'].to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF[['setpoints']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame(list(DF[['setpoints']].iteritems()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF['setpoints']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "DF[['setpoints']].to_dict(\"split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "data[355][11722]['measurements_reactor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "meta = [data[run][exp][\"metadata\"] for run in data for exp in data[run]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_keys, test_keys in splitter.split(col_run_to_exp):\n",
    "      \n",
    "    data_train = [data[k[0]][k[1]] | {\"run_id\":k[0], \"experiment_id\": k[1]} for k in train_keys]\n",
    "    data_test = {k:data[k[0]][k[1]] for k in test_keys}  \n",
    "    \n",
    "    \n",
    "#     data_train = {k:data[k[0]][k[1]] for k in train_keys}\n",
    "#     data_test = {k:data[k[0]][k[1]] for k in test_keys}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```python\n",
    "data_train: dict[(int, int), \n",
    "    dict[\n",
    "        'metadata': DataFrame,                  # MetaData\n",
    "        'setpoints': DataFrame,                 # MetaData\n",
    "        'measurements_reactor': DataFrame,      # TimeTensor \n",
    "        'measurements_array': DataFrame,        # TimeTensor\n",
    "        'measurements_aggregated' : DataFrame,  # TimeTensor\n",
    "    ]\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = DataFrame(data_train).set_index([\"run_id\", \"experiment_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(list(DF[\"metadata\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "single_run = data_train[(484, 16331)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame.from_dict(data_train,orient='index', index=[\"run_id\", \"experiment_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df = DataFrame(columns=single_run.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df[123] = single_run\n",
    "big_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame.from_dict(single_run, index=[(484, 16331)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(splitter.split(col_run_to_exp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train[(484,16331)]['measurements_aggregated']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Data Validation\n",
    "\n",
    "Format\n",
    "\n",
    "```python\n",
    "data: tuple[\n",
    "    dict[\n",
    "        'description': set[str],\n",
    "        'variables': list[dict[str, str]],\n",
    "        'time_format': str,\n",
    "        'series': dict[int, \n",
    "            dict['generating_parameters': \n",
    "                 dict[\n",
    "                     'qsmax': float,\n",
    "                     'qm': float,\n",
    "                     'qamax': float,\n",
    "                     'Yem': float,\n",
    "                     'Yxsof': float,\n",
    "                     'Yxa': float,\n",
    "                     'Yos': float,\n",
    "                     'Yoa': float,\n",
    "                     'Yas': float,\n",
    "                     'Kia': float,\n",
    "                     'Ks': float,\n",
    "                     'Ko': float,\n",
    "                     'Kap': float,\n",
    "                     'Kis': float,\n",
    "                     'Ksa': float,\n",
    "                     'Pamax': float,\n",
    "                     'F0': float,\n",
    "                     'mu_set': float,\n",
    "                     'C_feed': float,\n",
    "                     'Kp': float,\n",
    "                ]\n",
    "            ],\n",
    "        ],\n",
    "    ], \n",
    "    dict[int, DataFrame[columns=['X', 'S', 'A', 'DOTm', 'V', 'pulse', 'kLa']]]\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]['series'][4882]['generating_parameters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]['variables']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

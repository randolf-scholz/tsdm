{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing KIWI dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Validation\n",
    "\n",
    "Format\n",
    "\n",
    "```python\n",
    "data: tuple[\n",
    "    dict[\n",
    "        'description': set[str],\n",
    "        'variables': list[dict[str, str]],\n",
    "        'time_format': str,\n",
    "        'series': dict[int, \n",
    "            dict['generating_parameters': \n",
    "                 dict[\n",
    "                     'qsmax': float,\n",
    "                     'qm': float,\n",
    "                     'qamax': float,\n",
    "                     'Yem': float,\n",
    "                     'Yxsof': float,\n",
    "                     'Yxa': float,\n",
    "                     'Yos': float,\n",
    "                     'Yoa': float,\n",
    "                     'Yas': float,\n",
    "                     'Kia': float,\n",
    "                     'Ks': float,\n",
    "                     'Ko': float,\n",
    "                     'Kap': float,\n",
    "                     'Kis': float,\n",
    "                     'Ksa': float,\n",
    "                     'Pamax': float,\n",
    "                     'F0': float,\n",
    "                     'mu_set': float,\n",
    "                     'C_feed': float,\n",
    "                     'Kp': float,\n",
    "                ]\n",
    "            ],\n",
    "        ],\n",
    "    ], \n",
    "    dict[int, DataFrame[columns=['X', 'S', 'A', 'DOTm', 'V', 'pulse', 'kLa']]]\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InteractiveShell.ast_node_interactivity='last_expr_or_assign'  # always print last expr.\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series, Interval, Period, Timestamp, Timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Data Encoding\n",
    "\n",
    "Problem: Columns are encoded in wrong data-types (e.g. categoricals as int or string, floats as string, ints as floats etc.)\n",
    "\n",
    "Solution: Sequentially figure out data types\n",
    "\n",
    "Data Type Hirarchy:\n",
    "1. String-Like (`np.flexible`)\n",
    "    - strings\n",
    "    - bytes\n",
    "2. TimeLike types\n",
    "    - Timestamp (np.datetime64)\n",
    "    - Timedelta (np.timedelta64)\n",
    "3. Numerical (`np.number`)\n",
    "   - floating (`np.floating`)\n",
    "       - float\n",
    "       - complex\n",
    "   - integer (`np.integer`)\n",
    "       - signed\n",
    "       - unsigned\n",
    "4. Boolean (np.bool_)\n",
    "5. Pandas special types\n",
    "    - CategoricalDtype\n",
    "    - DatetimeTZDtype\n",
    "    - PeriodDtype\n",
    "    - IntervalDtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End goal: whenever it is appropriate to do so, perform the following conversions:\n",
    "\n",
    "1. Get appropriate Nullable Pandas type\n",
    "2. Downcast int → uint\n",
    "3. Downcast int64 → int32 → int16 → int8\n",
    "3. Downcast float64 → float32\n",
    "4. Downcast complex128 → complex64\n",
    "5. Convert to categorical datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subdtypes(dtype):\n",
    "    subs = dtype.__subclasses__()\n",
    "    if not subs:\n",
    "        return dtype\n",
    "    return [dtype, [subdtypes(dt) for dt in subs]]\n",
    "\n",
    "\n",
    "subdtypes(np.generic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(pandas.Series([1.3]).dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format\n",
    "\n",
    "\n",
    "```python\n",
    "dict[int, # run_id\n",
    "    dict[int, # experiment_id\n",
    "         dict[\n",
    "             'metadata',: DataFrame,                # static\n",
    "             'setpoints': DataFrame,                # static\n",
    "             'measurements_reactor',: DataFrame,    # TimeTensor\n",
    "             'measurements_array',: DataFrame,      # TimeTensor\n",
    "             'measurements_aggregated': DataFrame,  # TimeTensor\n",
    "         ]\n",
    "    ]\n",
    "]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"kiwi_experiments_and_run_355.pk\", \"rb\") as file:\n",
    "    data = pickle.load(file)\n",
    "\n",
    "col_run_to_exp = create_replicate_dict(data)\n",
    "splitter = ReplicateBasedSplitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA = [\n",
    "    (data[run][exp] | {\"run_id\": run, \"experiment_id\": exp})\n",
    "    for run in data\n",
    "    for exp in data[run]\n",
    "]\n",
    "DF = DataFrame(DATA).set_index([\"run_id\", \"experiment_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw-Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cross_validate_kiwi_runs import ReplicateBasedSplitter, create_replicate_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tables = {}\n",
    "\n",
    "for key in (\n",
    "    \"metadata\",\n",
    "    \"setpoints\",\n",
    "    \"measurements_reactor\",\n",
    "    \"measurements_array\",\n",
    "    \"measurements_aggregated\",\n",
    "):\n",
    "    if key == \"metadata\":\n",
    "        tables[key] = pd.concat(iter(DF[key])).reset_index(drop=True)\n",
    "    else:\n",
    "        tables[key] = (\n",
    "            pd.concat(iter(DF[key]), keys=DF[key].index)\n",
    "            .reset_index(level=2, drop=True)\n",
    "            .reset_index()\n",
    "        )\n",
    "\n",
    "tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "?np.number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata[\"OD_Dilution\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOOLS = [\n",
    "    {\"f\": False, \"t\": True},\n",
    "    {\"false\": False, \"true\": True},\n",
    "    {\"n\": False, \"y\": True},\n",
    "    {\"no\": False, \"yes\": True},\n",
    "    {\"-\": False, \"+\": True},\n",
    "    {0: False, 1: True},\n",
    "    {-1: False, +1: True},\n",
    "    {0.0: False, 1.0: True},\n",
    "    {-1.0: False, +1.0: True},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = np.random.randn(2, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.dot(y) / (np.linalg.norm(x) * np.linalg.norm(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "Series(np.random.rand(10 ** 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "Series(np.random.rand(10 ** 7)).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "Series([+1, -1, +1, -1]).astype(\"boolean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "any({0, 1} <= pair.keys() for pair in BOOLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.api.types.is_string_dtype(metadata[\"OD_Dilution\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "Series([1, -1, 1]).astype(\"Int8\").unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_no_information(series) -> bool:\n",
    "    return len(series.dropna().unique()) <= 1\n",
    "\n",
    "\n",
    "def contains_nan_slice(series, slices, two_enough: bool = False) -> bool:\n",
    "    num_missing = 0\n",
    "    for idx in slices:\n",
    "        if pd.isna(series[idx]).all():\n",
    "            num_missing += 1\n",
    "\n",
    "    if (num_missing > 0 and not two_enough) or (\n",
    "        num_missing >= len(slices) - 1 and two_enough\n",
    "    ):\n",
    "        print(f\"{series.name}: data missing in {num_missing}/{len(slices)} slices!\")\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def float_is_int(series) -> bool:\n",
    "    mask = pd.notna(series)\n",
    "    return series[mask].apply(float.is_integer).all()\n",
    "\n",
    "\n",
    "def is_bool(vals) -> bool:\n",
    "    if len(vals) > 2:\n",
    "        return False\n",
    "\n",
    "    if np.issubdtype(vals.dtype, np.bool_):\n",
    "        print(f\"Boolean column                       : {col}\")\n",
    "        return True\n",
    "    elif np.issubdtype(vals.dtype, np.integer):\n",
    "        # print(vals==0 ^ vals==1)\n",
    "        if ((vals == 0) ^ (vals == 1)).all() or ((vals == -1) ^ (vals == 1)).all():\n",
    "            print(f\"Boolean column pretending to be integer: {col}\")\n",
    "            return Ture\n",
    "    elif np.issubdtype(vals.dtype, np.floating):\n",
    "        if ((vals == 0) ^ (vals == 1)).all() or ((vals == -1) ^ (vals == 1)).all():\n",
    "            print(f\"Boolean column pretending to be float: {col}\")\n",
    "            return True\n",
    "    elif np.issubdtype(vals.dtype, pandas.StringDtype):\n",
    "        val1, val2 = set(vals)\n",
    "        val1 = str(val1).lower()\n",
    "        val2 = str(val2).lower()\n",
    "        if {val1, val2} in (\n",
    "            {\"0\", \"1\"},\n",
    "            {\"-1\", \"+1\"},\n",
    "            {\"-1\", \"1\"},\n",
    "            {\"t\", \"f\"},\n",
    "            {\"true\", \"false\"},\n",
    "            {\"y\", \"n\"},\n",
    "            {\"yes\", \"no\"},\n",
    "        ):\n",
    "            print(f\"Boolean column pretending to be string: {col}\")\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def get_true_column_dtypes(table) -> dict[str, str]:\n",
    "    dtypes = {}\n",
    "    for col in table:\n",
    "        series = table[col]\n",
    "        mask = pd.notna(series)\n",
    "        vals = series[mask].unique()\n",
    "\n",
    "\n",
    "def get_boolean_cols(df) -> set[str]:\n",
    "    cols = set()\n",
    "    for col in table:\n",
    "        series = table[col]\n",
    "        mask = pd.notna(series)\n",
    "        vals = series[mask].unique()\n",
    "        if is_bool(vals):\n",
    "            cols.add(col)\n",
    "    return cols\n",
    "\n",
    "\n",
    "def get_integer_cols(df) -> set[str]:\n",
    "    cols = set()\n",
    "    for col in table:\n",
    "        if np.issubdtype(table[col].dtype, np.integer):\n",
    "            print(f\"Integer column                       : {col}\")\n",
    "            cols.add(col)\n",
    "        elif np.issubdtype(table[col].dtype, np.floating) and float_is_int(table[col]):\n",
    "            print(f\"Integer column pretending to be float: {col}\")\n",
    "            cols.add(col)\n",
    "    return cols\n",
    "\n",
    "\n",
    "def get_useless_cols(df, strict: bool = False) -> set[str]:\n",
    "    useless_cols = set()\n",
    "    for col in table:\n",
    "        s = table[col]\n",
    "        if col in (\"run_id\", \"experiment_id\"):\n",
    "            continue\n",
    "        if contains_no_information(s):\n",
    "            print(f\"No information in      {col}\")\n",
    "            useless_cols.add(col)\n",
    "        elif contains_nan_slice(s, run_masks, two_enough=(not strict)):\n",
    "            print(f\"Missing for some run   {col}\")\n",
    "            useless_cols.add(col)\n",
    "    return useless_cols\n",
    "\n",
    "\n",
    "def get_μ_set(s: str):\n",
    "    if pd.isna(s):\n",
    "        return s\n",
    "    s = s.strip().lstrip(\"µ_set: \").strip()\n",
    "    percent, s = s.split(\", \")\n",
    "    value = s.strip().rstrip(\"mM IPTG\").strip()\n",
    "    return percent, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.datetime64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.Series([pandas.Interval(0, 1)]).dtype == pandas.IntervalDtype()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.issubdtype(pandas.Series([pandas.Interval(0, 1)]).dtype, pandas.IntervalDtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.api.types.is_datetime64_dtype(Series([\"2021\"]).dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.api.types.is_datetime64_dtype(Series([Timestamp(\"2021\")]).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.api.types.is_unsigned_integer_dtype(pandas.Series([1, 2, 3, 4, 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(Series([1, 2, 3]).astype(\"Int64\").dtype, pandas.Int64Dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "PANDAS_DTYPES = {\n",
    "    pandas.BooleanDtype: \"boolean\",\n",
    "    pandas.CategoricalDtype: \"category\",\n",
    "    pandas.DatetimeTZDtype: \"datetime64\",  # datetime64[ns, <tz>]\n",
    "    pandas.Float32Dtype: \"Float32\",\n",
    "    pandas.Float64Dtype: \"Float64\",\n",
    "    pandas.Int16Dtype: \"Int16\",\n",
    "    pandas.Int32Dtype: \"Int32\",\n",
    "    pandas.Int64Dtype: \"Int64\",\n",
    "    pandas.Int8Dtype: \"Int8\",\n",
    "    pandas.IntervalDtype: \"interval\",  # e.g. to denote ranges of variables\n",
    "    pandas.PeriodDtype: \"period\",  # period[<freq>]\n",
    "    pandas.SparseDtype: \"Sparse\",\n",
    "    pandas.StringDtype: \"string\",\n",
    "    pandas.UInt16Dtype: \"UInt16\",\n",
    "    pandas.UInt32Dtype: \"UInt32\",\n",
    "    pandas.UInt64Dtype: \"UInt64\",\n",
    "    pandas.UInt8Dtype: \"UInt8\",\n",
    "}\n",
    "r\"\"\"Dictionary of all :mod:`pandas` data types.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "Series([(1, 2), (3, 4)]).astype(\"interval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pandas.to_numeric(metadata[\"experiment_id\"], downcast=\"unsigned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.to_numeric(s.append(Series([70000])), downcast=\"unsigned\") - 70000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata[\"OD_Dilution\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "Series([True, False, pd.NA]).astype(\"boolean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pandas.Series([None, \"2\", \"NaN\"]).convert_dtypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = pandas.isna(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(pd.NaT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.convert_dtypes().dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "Series([\"123\", \"456\"]).astype(\"string\").unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in metadata:\n",
    "    pandas.to_numeric(metadata[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_dtype(series: Series):\n",
    "    \"\"\"Tries to infer data type    \"\"\"\n",
    "    mask = pandas.notna(series)\n",
    "    values = series[mask]\n",
    "    uniques = values.unqiue()\n",
    "    dtype = series.dtype\n",
    "    dtype_type = type(dtype)\n",
    "    if type(dtype) in PANDAS_DTYPES:\n",
    "        return dtype\n",
    "    if \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.extensions import ExtensionDtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.api.types.is_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.api.type.issubdtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_datatypes(table: DataFrame) -> dict(str, np.dtype):\n",
    "    \"\"\"This is a utility function that tries to infer the datatypes of the columns of a DataFrame.\n",
    "    \n",
    "    In particular, it tries to identify ill-specified columns:\n",
    "    \n",
    "    - columns that contains booleans  but are formatter as integers\n",
    "    - columns that contains integers  but are formatted as floating\n",
    "    - columns that contains floating  but are formatted as strings\n",
    "    \"\"\"\n",
    "    \n",
    "    dtypes = dict(table.dtypes)\n",
    "    new_dtypes = dtypes.copy()\n",
    "    \n",
    "    \n",
    "    for col, dtype in dtypes.items():\n",
    "        series = table[col]\n",
    "        # Leave pandas specific columns alone\n",
    "        if type(dtype) in PANDAS_DTYPES:\n",
    "            continue\n",
    "        if pandas.api.types.is_datetime64_ns_dtype(dtype):\n",
    "            continue\n",
    "        if pandas.api.types.is_timedelta64_ns_dtype(dtype):\n",
    "            continue\n",
    "\n",
    "        if pandas.api.types.is_object_dtype(dtype):\n",
    "            \n",
    "\n",
    "            \n",
    "        if dtype == np.datetime64\n",
    "        if np.issubdtype(dtype, numpy.datetime64):\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        if np.issubdtype(dtype, pandas.DatetimeTZDtype):\n",
    "            continue\n",
    "        if np.issubdtype(dtype, pandas.DatetimeTZDtype):\n",
    "            continue\n",
    "\n",
    "        if np.issubdtype(dtype, numpy.timedelta64):\n",
    "            continue\n",
    "        if np.issubdtype(dtype, numpy.timedelta64):\n",
    "            continue\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(\"111,5156_44\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = s.strip()  # remove leading and trailing whitespace\n",
    "\n",
    "chars = set(s)\n",
    "\n",
    "assert chars <= {\".\", \",\", \"_\", \"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"}\n",
    "\n",
    "if \n",
    "\n",
    "s.replace(\"_\", \"\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### MetaData Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([1.0, 2.0]) == {1, 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_boolean_cols(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_numeric(\"10_000\", errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = table[\"ph_Timesetpoint\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = pd.notna(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.to_numeric(s, downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.api.types.is_numeric_dtype(s[mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in metadata:\n",
    "    series = metadata[col]\n",
    "    mask = pandas.notna(series)\n",
    "    values = series[mask]\n",
    "    print(pandas.api.types.infer_dtype(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "float(\"10.000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in table[\"ph_Ki\"]:\n",
    "    pd.to_numeric(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_numeric(series):\n",
    "    mask = pd.notna(series)\n",
    "\n",
    "    try:\n",
    "        pd.to_numeric(series)\n",
    "    except:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unqiues(series, uniques = None, mask = None):\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_categorical(series, ratio=0.01, uniques=None, mask=None):\n",
    "    \"\"\"Test whether a column could be categorical\n",
    "    Test 1: if number of unique values < ratio*number of recorded values\n",
    "    Test 2: if integer and unique values = range()\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "table[\"OD_Dilution\"].astype(pd.Int64Dtype())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_empty(series):\n",
    "    return pd.isna(series).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in table:\n",
    "    series = table[col]\n",
    "    dtype = series.dtype\n",
    "    if np.issubdtype(dtype, pandas.StringDtype):\n",
    "        if is_numeric(series):\n",
    "            print(f\"Numerical column pretending to be string: {col=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "table = metadata = tables[\"metadata\"]\n",
    "runs = table[\"run_id\"].dropna().unique()\n",
    "run_masks = [table[\"run_id\"] == run for run in runs]\n",
    "\n",
    "useless_cols = set()\n",
    "\n",
    "for col in table:\n",
    "    s = table[col]\n",
    "    if col in (\"run_id\", \"experiment_id\"):\n",
    "        continue\n",
    "    if contains_no_information(s):\n",
    "        print(f\"No information in      {col}\")\n",
    "        useless_cols.add(col)\n",
    "    elif contains_nan_slice(s, run_masks):\n",
    "        print(f\"Missing for some run   {col}\")\n",
    "        useless_cols.add(col)\n",
    "\n",
    "# drop the following specific columns\n",
    "useless_cols |= {\n",
    "    \"folder_id_y\",\n",
    "    \"ph_Base_conc\",\n",
    "    \"ph_Ki\",\n",
    "    \"ph_Kp\",\n",
    "    \"ph_Tolerance\",\n",
    "    \"pms_id\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "table[\"OD_Dilution\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "float(\"100.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isna(table[\"OD_Dilution\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "table[\"OD_Dilution\"].astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metadata_columns = {\n",
    "    \"bioreactor_id\",\n",
    "    \"container_number\",\n",
    "    \"experiment_id\",\n",
    "    \"run_id\",\n",
    "    \"profile_id\",\n",
    "    \"color\",\n",
    "    \"profile_name\",\n",
    "    \"organism_id\",\n",
    "    \"OD_Dilution\",\n",
    "    \"run_name\",\n",
    "    \"start_time\",\n",
    "    \"end_time\",\n",
    "}\n",
    "\n",
    "remaining_cols = set(metadata.columns) - useless_cols\n",
    "assert (\n",
    "    metadata_columns >= set(metadata.columns) - useless_cols\n",
    "), f\"Superfluous {metadata_columns - remaining_cols}\"\n",
    "assert (\n",
    "    metadata_columns <= set(metadata.columns) - useless_cols\n",
    "), f\"You forgot to check {metadata_columns - remaining_cols}\"\n",
    "\n",
    "\n",
    "metadata_dtypes = {\n",
    "    \"experiment_id\": \"UInt32\",\n",
    "    \"bioreactor_id\": \"UInt32\",\n",
    "    \"container_number\": \"UInt32\",\n",
    "    \"profile_id\": \"UInt32\",\n",
    "    \"color\": \"string\",\n",
    "    \"profile_name\": \"string\",\n",
    "    \"organism_id\": \"UInt32\",\n",
    "    \"run_id\": \"UInt32\",\n",
    "    \"OD_Dilution\": \"float32\",\n",
    "    \"run_name\": \"string\",\n",
    "    \"start_time\": \"datetime64[ns]\",\n",
    "    \"end_time\": \"datetime64[ns]\",\n",
    "}\n",
    "\n",
    "assert metadata_columns >= set(\n",
    "    metadata_dtypes\n",
    "), f\"Superfluous encoing  {set(metadata_dtypes) - metadata_columns}\"\n",
    "assert metadata_columns <= set(\n",
    "    metadata_dtypes\n",
    "), f\"You forgot to encode {metadata_columns - set(metadata_dtypes)}\"\n",
    "\n",
    "metadata_categoricals = {\n",
    "    \"profile_name\": \"category\",\n",
    "    \"run_name\": \"category\",\n",
    "    \"color\": \"category\",\n",
    "    \"OD_Dilution\": \"Float32\",\n",
    "}\n",
    "\n",
    "assert metadata_columns >= set(\n",
    "    metadata_categoricals\n",
    "), f\"Superfluous encoing {set(metadata_categoricals) - metadata_columns}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = metadata.astype(metadata_dtypes)\n",
    "metadata = metadata.astype(metadata_categoricals)\n",
    "metadata = metadata[metadata_columns]\n",
    "metadata = metadata.set_index([\"run_id\", \"experiment_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setpoint Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = setpoints = tables[\"setpoints\"]\n",
    "runs = table[\"run_id\"].dropna().unique()\n",
    "run_masks = [table[\"run_id\"] == run for run in runs]\n",
    "\n",
    "useless_cols = set()\n",
    "\n",
    "for col in table:\n",
    "    s = table[col]\n",
    "    if col in (\"run_id\", \"experiment_id\"):\n",
    "        continue\n",
    "    if contains_no_information(s):\n",
    "        print(f\"No information in      {col}\")\n",
    "        useless_cols.add(col)\n",
    "    elif contains_nan_slice(s, run_masks, two_enough=True):\n",
    "        print(f\"Missing for some run   {col}\")\n",
    "        useless_cols.add(col)\n",
    "\n",
    "# drop the following specific columns\n",
    "useless_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "setpoint_columns = set(setpoints.columns)\n",
    "remaining_cols = setpoint_columns - useless_cols\n",
    "\n",
    "selected_columns = {\n",
    "    \"experiment_id\",\n",
    "    \"run_id\",\n",
    "    \"cultivation_age\",\n",
    "    \"setpoint_id\",\n",
    "    \"unit\",\n",
    "    \"Puls_Glucose\",\n",
    "    \"StirringSpeed\",\n",
    "    \"Feed_glc_cum_setpoints\",\n",
    "    \"Flow_Air\",\n",
    "    \"InducerConcentration\",\n",
    "}\n",
    "\n",
    "assert (\n",
    "    selected_columns >= setpoint_columns - useless_cols\n",
    "), f\"You forgot to check {remaining_cols - selected_columns}\"\n",
    "assert (\n",
    "    selected_columns <= setpoint_columns - useless_cols\n",
    "), f\"Superfluous {selected_columns - remaining_cols}\"\n",
    "\n",
    "setpoints_dtypes = {\n",
    "    \"experiment_id\": \"UInt32\",\n",
    "    \"run_id\": \"UInt32\",\n",
    "    \"cultivation_age\": \"UInt32\",\n",
    "    \"setpoint_id\": \"UInt32\",\n",
    "    \"unit\": \"string\",\n",
    "    \"Puls_AceticAcid\": \"Float32\",\n",
    "    \"Puls_Glucose\": \"Float32\",\n",
    "    \"Puls_Medium\": \"Float32\",\n",
    "    \"StirringSpeed\": \"UInt16\",\n",
    "    \"pH\": \"Float32\",\n",
    "    \"Feed_glc_cum_setpoints\": \"UInt16\",\n",
    "    \"Flow_Air\": \"UInt8\",\n",
    "    \"InducerConcentration\": \"Float32\",\n",
    "    \"Flow_Nitrogen\": \"Float32\",\n",
    "    \"Flow_O2\": \"Float32\",\n",
    "    \"Feed_dextrine_cum_setpoints\": \"Float32\",\n",
    "}\n",
    "\n",
    "assert (\n",
    "    set(setpoints_dtypes) <= setpoint_columns\n",
    "), f\"Superfluous encoing  {set(setpoints_dtypes) - setpoint_columns}\"\n",
    "assert (\n",
    "    set(setpoints_dtypes) >= selected_columns\n",
    "), f\"You forgot to encode {selected_columns - set(setpoints_dtypes)}\"\n",
    "\n",
    "setpoints_categoricals = {\n",
    "    \"unit\": \"category\",\n",
    "}\n",
    "\n",
    "assert set(setpoints_categoricals) <= set(\n",
    "    setpoints_dtypes\n",
    "), f\"Superfluous encoing {set(setpoints_categoricals) - set(setpoints_dtypes)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "setpoints[\"unit\"] = setpoints[\"unit\"].replace(to_replace=\"-\", value=pd.NA)\n",
    "setpoints = setpoints.astype(setpoints_dtypes)\n",
    "setpoints = setpoints.astype(setpoints_categoricals)\n",
    "setpoints = setpoints[selected_columns]\n",
    "setpoints = setpoints.set_index([\"run_id\", \"experiment_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Measurements Reactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = measurements_reactor = tables[\"measurements_reactor\"]\n",
    "runs = table[\"run_id\"].dropna().unique()\n",
    "run_masks = [table[\"run_id\"] == run for run in runs]\n",
    "\n",
    "useless_cols = get_useless_cols(table)\n",
    "integer_cols = get_integer_cols(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_columns = set(table.columns)\n",
    "remaining_cols = table_columns - useless_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = {\n",
    "    \"Acetate\",\n",
    "    \"Base\",\n",
    "    \"Cumulated_feed_volume_glucose\",\n",
    "    \"Cumulated_feed_volume_medium\",\n",
    "    \"DOT\",\n",
    "    \"Fluo_GFP\",\n",
    "    \"Glucose\",\n",
    "    \"InducerConcentration\",\n",
    "    \"OD600\",\n",
    "    \"Probe_Volume\",\n",
    "    \"Volume\",\n",
    "    \"experiment_id\",\n",
    "    \"measurement_id\",\n",
    "    \"measurement_time\",\n",
    "    \"pH\",\n",
    "    \"run_id\",\n",
    "    \"unit\",\n",
    "}\n",
    "\n",
    "assert (\n",
    "    selected_columns >= table_columns - useless_cols\n",
    "), f\"You forgot to check {remaining_cols - selected_columns}\"\n",
    "assert (\n",
    "    selected_columns <= table_columns - useless_cols\n",
    "), f\"Superfluous {selected_columns - remaining_cols}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table[selected_columns].dtypes.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table[\"Base\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.dtyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reactor_dtypes = {\n",
    "    \"Acetate\": \"Float32\",\n",
    "    \"Base\": \"Int32\",\n",
    "    \"Cumulated_feed_volume_glucose\": \"\",\n",
    "    \"Cumulated_feed_volume_medium\": \"\",\n",
    "    \"DOT\": \"\",\n",
    "    \"Fluo_GFP\": \"\",\n",
    "    \"Glucose\": \"\",\n",
    "    \"InducerConcentration\": \"\",\n",
    "    \"OD600\": \"\",\n",
    "    \"Probe_Volume\": \"\",\n",
    "    \"Volume\": \"\",\n",
    "    \"experiment_id\": \"\",\n",
    "    \"measurement_id\": \"\",\n",
    "    \"measurement_time\": \"\",\n",
    "    \"pH\": \"\",\n",
    "    \"run_id\": \"\",\n",
    "    \"unit\": \"\",\n",
    "}\n",
    "\n",
    "assert (\n",
    "    set(setpoints_dtypes) <= setpoint_columns\n",
    "), f\"Superfluous encoing  {set(setpoints_dtypes) - setpoint_columns}\"\n",
    "assert (\n",
    "    set(setpoints_dtypes) >= selected_columns\n",
    "), f\"You forgot to encode {selected_columns - set(setpoints_dtypes)}\"\n",
    "\n",
    "setpoints_categoricals = {\n",
    "    \"unit\": \"category\",\n",
    "}\n",
    "\n",
    "assert set(setpoints_categoricals) <= set(\n",
    "    setpoints_dtypes\n",
    "), f\"Superfluous encoing {set(setpoints_categoricals) - set(setpoints_dtypes)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = metadata.astype(metadata_dtypes)\n",
    "metadata = metadata.astype(metadata_categoricals)\n",
    "metadata = metadata[metadata_columns]\n",
    "metadata = metadata.set_index([\"run_id\", \"experiment_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measurements_Array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measurements Aggregated"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

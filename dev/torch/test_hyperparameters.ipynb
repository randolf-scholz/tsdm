{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-25T22:16:44.063846Z",
     "iopub.status.busy": "2022-09-25T22:16:44.063567Z",
     "iopub.status.idle": "2022-09-25T22:16:44.066309Z",
     "shell.execute_reply": "2022-09-25T22:16:44.065982Z",
     "shell.execute_reply.started": "2022-09-25T22:16:44.063833Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor, jit, nn\n",
    "from typing import Optional\n",
    "from tsdm.models.activations import ACTIVATIONS\n",
    "from tsdm.utils.config import Config\n",
    "from dataclasses import KW_ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-25T22:16:45.978468Z",
     "iopub.status.busy": "2022-09-25T22:16:45.977874Z",
     "iopub.status.idle": "2022-09-25T22:16:45.986054Z",
     "shell.execute_reply": "2022-09-25T22:16:45.985599Z",
     "shell.execute_reply.started": "2022-09-25T22:16:45.978447Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Dense(nn.Module):\n",
    "    class HP(Config):\n",
    "        input_size: int\n",
    "        output_size: int\n",
    "        activation: str | nn.Module | Config = \"relu\"\n",
    "\n",
    "    def __init__(\n",
    "        self, input_size: int, output_size: int, activation: str | nn.Module = \"ReLU\"\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "\n",
    "        if isinstance(activation, str):\n",
    "            activation = ACTIVATIONS[activation]()\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = self.linear(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = Dense(3, 5)\n",
    "x = torch.randn(16, 3)\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-25T22:16:54.422841Z",
     "iopub.status.busy": "2022-09-25T22:16:54.422572Z",
     "iopub.status.idle": "2022-09-25T22:16:54.428330Z",
     "shell.execute_reply": "2022-09-25T22:16:54.427965Z",
     "shell.execute_reply.started": "2022-09-25T22:16:54.422828Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Sequential):\n",
    "    class HP(Config):\n",
    "        input_size: int\n",
    "        output_size: int\n",
    "        _: KW_ONLY\n",
    "        latent_size: Optional[int] = None\n",
    "        num_hidden: int = 0\n",
    "\n",
    "    config: HP\n",
    "\n",
    "    def __init__(self, *layers: nn.Module) -> None:\n",
    "        super().__init__(*layers)\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(\n",
    "        cls,\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        config = cls.HP(*args, **kwargs)\n",
    "        config |= {\"latent_size\": 1}\n",
    "        layers: list[nn.Module] = []\n",
    "\n",
    "        # input layer\n",
    "        layer = nn.Linear(config.input_size, config.latent_size)\n",
    "        nn.init.kaiming_normal_(layer.weight, nonlinearity=\"linear\")\n",
    "        nn.init.kaiming_normal_(layer.bias[None], nonlinearity=\"linear\")\n",
    "        layers.append(layer)\n",
    "\n",
    "        # hidden layers\n",
    "        for _ in range(config.num_hidden):\n",
    "            layers.append(nn.ReLU())\n",
    "            layer = nn.Linear(config.latent_size, config.latent_size)\n",
    "            nn.init.kaiming_normal_(layer.weight, nonlinearity=\"relu\")\n",
    "            nn.init.kaiming_normal_(layer.bias[None], nonlinearity=\"relu\")\n",
    "            layers.append(layer)\n",
    "\n",
    "        # output_layer\n",
    "        layers.append(nn.ReLU())\n",
    "        layer = nn.Linear(config.latent_size, config.output_size)\n",
    "        nn.init.kaiming_normal_(layer.weight, nonlinearity=\"relu\")\n",
    "        nn.init.kaiming_normal_(layer.bias[None], nonlinearity=\"relu\")\n",
    "        layers.append(layer)\n",
    "\n",
    "        module = cls(*layers)\n",
    "        module.config = config\n",
    "        return module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-25T22:16:54.581402Z",
     "iopub.status.busy": "2022-09-25T22:16:54.581099Z",
     "iopub.status.idle": "2022-09-25T22:16:54.584991Z",
     "shell.execute_reply": "2022-09-25T22:16:54.584684Z",
     "shell.execute_reply.started": "2022-09-25T22:16:54.581388Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MLP.from_config(64, 10, latent_size=32, num_hidden=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20fbd3e3-9073-43e0-b457-3218790aefb9",
   "metadata": {},
   "source": [
    "# Idea\n",
    "\n",
    "We can transform this to a decorator???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcb22a3-0e9e-419c-8d04-eb740109519f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from abc import ABCMeta\n",
    "from collections.abc import *\n",
    "from dataclasses import KW_ONLY, dataclass, field\n",
    "from typing import Any, Dict, Final, Optional, TypeVar, Union\n",
    "\n",
    "from pydantic.dataclasses import dataclass as pydantic_dataclass\n",
    "from torch import Tensor, jit, nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5212f08f-0065-435f-b69a-73ffc43c9077",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Key = TypeVar(\"Key\", bound=Hashable)\n",
    "\n",
    "\n",
    "def flatten_dict(\n",
    "    d: dict[str, Iterable[Any]],\n",
    "    /,\n",
    "    *,\n",
    "    recursive: bool = True,\n",
    "    how: Callable[[Iterable[Key]], Key] = \".\".join,\n",
    ") -> dict[tuple[str, ...], Any]:\n",
    "    r\"\"\"Flatten a dictionary containing iterables to a list of tuples.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    d: dict\n",
    "    recursive: bool (default=True)\n",
    "        If true applies flattening strategy recursively on nested dicts, yielding\n",
    "        list[tuple[key1, key2, ...., keyN, value]]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[tuple[Any, ...]]\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    for key, item in d.items():\n",
    "        if isinstance(key, tuple):\n",
    "            raise ValueError(\"Keys are not allowed to be tuples!\")\n",
    "        if isinstance(item, dict) and recursive:\n",
    "            subdict = flatten_dict(item, recursive=True, how=how)\n",
    "            for subkey, subitem in subdict.items():\n",
    "                result[how((key, subkey))] = subitem\n",
    "        else:\n",
    "            result[key] = item\n",
    "    return result\n",
    "\n",
    "\n",
    "def unflatten_dict(\n",
    "    d: dict[Hashable, Iterable[Any]],\n",
    "    /,\n",
    "    *,\n",
    "    recursive: bool = True,\n",
    "    how: Callable[[Key], Iterable[Key]] = str.split,\n",
    ") -> list[tuple[Any, ...]]:\n",
    "    r\"\"\"Flatten a dictionary containing iterables to a list of tuples.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    d: dict\n",
    "    recursive: bool (default=True)\n",
    "        If true applies flattening strategy recursively on nested dicts, yielding\n",
    "        list[tuple[key1, key2, ...., keyN, value]]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[tuple[Any, ...]]\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    for key, item in d.items():\n",
    "        if isinstance(key, tuple):\n",
    "            if key[0] not in result:\n",
    "                result[key[0]] = {}\n",
    "\n",
    "            # subdict = {subkey[1:]: subitem for subkey, subitem in item.items()}\n",
    "            if len(key) <= 1:\n",
    "                result[key[0]] |= {key[1:]: item}\n",
    "            else:\n",
    "                result[key[0]] |= unflatten_dict({key[1:]: item})\n",
    "\n",
    "        else:\n",
    "            result[key] = item\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf1e581-3eab-473f-bec3-9a8e57ba4e4c",
   "metadata": {},
   "source": [
    "### Testing flattening function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4eb28a2-0c94-4b45-80e9-62d0c7b14781",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dict: dict[str, Any] = {\n",
    "    \"foo\": 2,\n",
    "    \"bar\": True,\n",
    "    \"baz\": 0.99,\n",
    "    \"nested\": {\n",
    "        \"foo\": 1,\n",
    "        \"bar\": True,\n",
    "        \"baz\": 0.99,\n",
    "        \"nested\": {\"foo\": 1, \"bar\": True, \"baz\": 0.99},\n",
    "    },\n",
    "}\n",
    "\n",
    "flat = flatten_dict(test_dict, how=\".\".join)\n",
    "display(flat)\n",
    "display(unflatten_dict(flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c7688e-ff22-4c35-8492-28b7caafa788",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_model_attribute(model: nn.Module, attr: str) -> None:\n",
    "    r\"\"\"Check whether attr is maintained under torhc JIT\"\"\"\n",
    "\n",
    "    original_model = model\n",
    "\n",
    "    if hasattr(original_model, attr):\n",
    "        attribute = getattr(original_model, attr)\n",
    "        print(f\"INITIAL Model.{attr}={attribute}\")\n",
    "    else:\n",
    "        print(f\"INITIAL Model does not have attribute '{attr}'.\")\n",
    "\n",
    "    serialized_model = jit.script(model)\n",
    "\n",
    "    if hasattr(serialized_model, attr):\n",
    "        attribute = getattr(serialized_model, attr)\n",
    "        print(f\"JITTED  Model.{attr}={attribute}\")\n",
    "    else:\n",
    "        print(f\"JITTED  Model does not have attribute '{attr}'.\")\n",
    "\n",
    "    jit.save(serialized_model, \"model.pt\")\n",
    "    loaded_model = jit.load(\"model.pt\")\n",
    "\n",
    "    if hasattr(loaded_model, attr):\n",
    "        attribute = getattr(loaded_model, attr)\n",
    "        print(f\"LOADED  Model.{attr}={attribute}\")\n",
    "    else:\n",
    "        print(f\"LOADED  Model does not have attribute '{attr}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a99c0cc-18e6-4858-848c-4b4c9f0ca106",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DemoModel(nn.Module):\n",
    "    FOO: Dict[str, Any] = {\n",
    "        \"a\": 2,\n",
    "        \"b\": True,\n",
    "        \"c\": 0.99,\n",
    "        \"d\": {\"a\": 1, \"b\": True, \"c\": 0.99, \"d\": {\"a\": 1}},\n",
    "    }\n",
    "\n",
    "    BAR: Dict[str, Union[str, int, bool, float]]\n",
    "    # BAZ: Dict[str, Any]\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self.BAR = flatten_dict(self.FOO)\n",
    "        super().__init__()\n",
    "        # self.BAZ = self.FOO\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        r\"\"\"Simply identity\"\"\"\n",
    "        return x\n",
    "\n",
    "\n",
    "test_model_attribute(DemoModel(), \"FOO\")\n",
    "test_model_attribute(DemoModel(), \"BAR\")\n",
    "test_model_attribute(DemoModel(), \"BAZ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a20072c-9b51-4d92-8ff0-ed7e81fa542f",
   "metadata": {},
   "source": [
    "# Can we serialize models with attached dictionary?\n",
    "\n",
    "⟹ only when flattened!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5493b04f-021d-4abd-86d5-86ec6789225c",
   "metadata": {},
   "source": [
    "# Observations\n",
    "\n",
    "- As of **`torch=1.12.1`**, `typing.Dict` works but `dict` doesn't?\n",
    "- AS of **`torch=1.12.1`**, nested dictionaries are not supported.\n",
    "- As of **`torch=1.12.1`**, tracing only works if\n",
    "    - The complete dictionary is added in the class \n",
    "    - The dictionary is not annotated.\n",
    "- It makes no difference whether the dictionary is added before or after `super().__init__` is called\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8ac6b7-002b-47d9-8c04-a3f64d0ca389",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Idea\n",
    "\n",
    "We need to do 2 things for a robust initialization\n",
    "\n",
    "1. Input validation: in particular, cast values to correct type\n",
    "    - Could use pydantic\n",
    "        - Does not seem to support `KW_ONLY` yet.\n",
    "        - Use regular `DataClasses` in the meantime?\n",
    "        - ~~Alternative `TypedDict`?~~\n",
    "            - `TypedDict` do not allow extra keys... https://github.com/python/mypy/issues/4617\n",
    "2. Sub-module compatibility: e.g. module might need to be written such that latent size agrees with output size of other module.\n",
    "    - If values are given, check for compatibility.\n",
    "    - If values are not given, use defaults.\n",
    "        - `if \"input_size\" in **kwargs:... else ...`\n",
    "    - Do we want to support mixed inputs? (e.g. `encoder=<some nn.Module>`, `activation=<module_dict>`)\n",
    "3. Module Creation.\n",
    "    - Should be the responsibility of `from_hyperparameters` / `__new__` / `__init__`.\n",
    "4. Every Module should sport a default config\n",
    "    - Other Modules should be able to use this config, e.g. `encoder=MyEncoderModel.Config`\n",
    "        - If uninitialized class is given, the initialize with its default dict.\n",
    "        - If initialized class is given, use it as is.\n",
    "        - If config / dictionary is given, use it to locate the module and initialize it.\n",
    "5. Serialization: \n",
    "    - The Dataclass / NestedDict should work arbitrary Optional data.\n",
    "6. Should positional arguments be allowed or only `*args`?\n",
    "8. Optional cool stuff:\n",
    "    - Signatures and automatic signature validation.\n",
    "        - Only makes sense post-initialization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4c7dcd-27dd-4624-a1db-6b230ed3e6db",
   "metadata": {},
   "source": [
    "## Specification\n",
    "\n",
    "- Need a class object that maps 1:1 to a nested `dict` / `json` / `toml` file.\n",
    "    - Implement conversion utilities (⇝ pydantic.)\n",
    "- Should have a fixed set of required values, but allow optional values (with some naming restrictions)\n",
    "- Certain values (`__name__`, `__qualname__`, `__module__`) should always be included.\n",
    "\n",
    "How object is created.\n",
    "\n",
    "- Option 1: Subclass a `BaseConfig` class that implements the `__name__` logic.\n",
    "    - How to pass `*args`, `**kwargs`?\n",
    "    ```python\n",
    "    class MyModel(nn.Module):\n",
    "        Config(BaseConfig):\n",
    "            a: int,\n",
    "            b: int, \n",
    "            *args: Any\n",
    "            droprate: float = 0.2\n",
    "            **kwargs: Any\n",
    "    ```\n",
    "\n",
    "- Option 2: DataClass / TypedDict\n",
    "- Option 3: Instantiate a class locally? (How to pass Type Hints?)\n",
    "- Option 4: Class Factory. (might actually be best?) Issue: doesn't work syntactically.\n",
    "    \n",
    "    ```python\n",
    "    class MyModel(nn.Module):\n",
    "        Config = create_config(\n",
    "            a: int,\n",
    "            b: int, \n",
    "            *args: Any\n",
    "            droprate: float = 0.2\n",
    "            **kwargs: Any\n",
    "        )\n",
    "    ```\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a975dfea-2400-4add-aeb4-66bac17fd770",
   "metadata": {},
   "source": [
    "## How to deal with missing values?\n",
    "\n",
    "```python\n",
    "class MyModel(nn.Module):\n",
    "    Config:\n",
    "        input_size: int\n",
    "        drop_rate: float = 0.5\n",
    "```\n",
    "\n",
    "This Model requires getting input_size as an input. \n",
    "- How do we initialize it? \n",
    "- How does the default config in dictionary form look like?\n",
    "    - Should we even be able to serialize it with missing keys?\n",
    "- What value do we put for missing?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c55393-b6c3-4918-8d73-19fce9cf355a",
   "metadata": {},
   "source": [
    "```python\n",
    "class MyModel:    \n",
    "    class Config:\n",
    "        ...\n",
    "    \n",
    "Class MyOtherModel:\n",
    "\n",
    "    class Config:\n",
    "        encoder: MyModel\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567b2915-518f-4eae-ba2c-35fca2957584",
   "metadata": {},
   "source": [
    "# Solution\n",
    "\n",
    "We should be able to initialize submodules by either:\n",
    "\n",
    "1. Passing a `Config`\n",
    "2. Passing an already initialized model.\n",
    "3. Older: passing a string. (e.g. `activation='relu'`)\n",
    "\n",
    "\n",
    "- Actually used config should be searializable (currently: cast to nested dict -> flatten.)\n",
    "\n",
    "During init, do the following:\n",
    "\n",
    "- Validate entries\n",
    "- Fill-in mandatory fields to submodules from parameters passed to parent class. **\"dependent fields\"**\n",
    "\n",
    "## Questions\n",
    "\n",
    "- Do we want positional only parameters ? \n",
    "- Since some fields are dependent, how should they be passed?\n",
    "    - E.g. We want to initialize a model, some parameters are Mandatory!\n",
    "    - We want the `__name__` and `__module__` be added automatically, if possible.\n",
    "        - Use protocols?\n",
    "    \n",
    "    \n",
    "- How to easily overwrite fields of the default configuration?\n",
    "    - Idea: Allow overwriting of fields by passing filesystem like keys:\n",
    "\n",
    "```python\n",
    "\"Filter/kernel_initialization\" : \"symmetric\".\n",
    "```\n",
    "\n",
    "\n",
    "=> We will need to write a custom Config object...\n",
    "\n",
    "    - initializing it validates fields\n",
    "    - \n",
    "\n",
    "\n",
    "### Example\n",
    "\n",
    "```python\n",
    "MODEL_CONFIG = LinODEnet.DefaultConfig(\n",
    "    input_size: ...\n",
    "    hidden_size: ...\n",
    "    Filter = SequentialFilter.DefaultConfig(kernel_init=...)\n",
    "    __default_updates__ = {\"Filter/kernel_initialization\" : \"symmetric\"}.\n",
    ")\n",
    "\n",
    "\n",
    "model = Model(**Model_CONFIG)\n",
    "\n",
    "\n",
    "{\n",
    "    \"__name__\": \"LinODEnet\",\n",
    "    \"input_size\": TASK.dataset.shape[-1],\n",
    "    \"hidden_size\": ARGS.hidden_size,\n",
    "    \"embedding_type\": \"concat\",\n",
    "    \"Filter\": filters.SequentialFilter.HP,\n",
    "    \"System\": system.LinODECell.HP | {\"kernel_initialization\": ARGS.kernel_init},\n",
    "    \"Encoder\": ResNet.HP,\n",
    "    \"Decoder\": ResNet.HP,\n",
    "    \"Embedding\": embeddings.ConcatEmbedding.HP,\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50489695-45a6-485f-bddb-826a992cd0c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import keyword\n",
    "import types\n",
    "\n",
    "\n",
    "def make_dataclass(\n",
    "    cls_name,\n",
    "    fields,\n",
    "    *,\n",
    "    bases=(),\n",
    "    namespace=None,\n",
    "    init=True,\n",
    "    repr=True,\n",
    "    eq=True,\n",
    "    order=False,\n",
    "    unsafe_hash=False,\n",
    "    frozen=False,\n",
    "    match_args=True,\n",
    "    kw_only=False,\n",
    "    slots=False,\n",
    "    **kwds,\n",
    "):\n",
    "    \"\"\"Return a new dynamically created dataclass.\n",
    "    The dataclass name will be 'cls_name'.  'fields' is an iterable\n",
    "    of either (name), (name, type) or (name, type, Field) objects. If type is\n",
    "    omitted, use the string 'typing.Any'.  Field objects are created by\n",
    "    the equivalent of calling 'field(name, type [, Field-info])'.\n",
    "      C = make_dataclass('C', ['x', ('y', int), ('z', int, field(init=False))], bases=(Base,))\n",
    "    is equivalent to:\n",
    "      @dataclass\n",
    "      class C(Base):\n",
    "          x: 'typing.Any'\n",
    "          y: int\n",
    "          z: int = field(init=False)\n",
    "    For the bases and namespace parameters, see the builtin type() function.\n",
    "    The parameters init, repr, eq, order, unsafe_hash, and frozen are passed to\n",
    "    dataclass().\n",
    "    \"\"\"\n",
    "\n",
    "    if namespace is None:\n",
    "        namespace = {}\n",
    "\n",
    "    # While we're looking through the field names, validate that they\n",
    "    # are identifiers, are not keywords, and not duplicates.\n",
    "    seen = set()\n",
    "    annotations = {}\n",
    "    defaults = {}\n",
    "    for item in fields:\n",
    "        if isinstance(item, str):\n",
    "            name = item\n",
    "            tp = \"typing.Any\"\n",
    "        elif len(item) == 2:\n",
    "            (\n",
    "                name,\n",
    "                tp,\n",
    "            ) = item\n",
    "        elif len(item) == 3:\n",
    "            name, tp, spec = item\n",
    "            defaults[name] = spec\n",
    "        else:\n",
    "            raise TypeError(f\"Invalid field: {item!r}\")\n",
    "\n",
    "        if not isinstance(name, str) or not name.isidentifier():\n",
    "            raise TypeError(f\"Field names must be valid identifiers: {name!r}\")\n",
    "        if keyword.iskeyword(name):\n",
    "            raise TypeError(f\"Field names must not be keywords: {name!r}\")\n",
    "        if name in seen:\n",
    "            raise TypeError(f\"Field name duplicated: {name!r}\")\n",
    "\n",
    "        seen.add(name)\n",
    "        annotations[name] = tp\n",
    "\n",
    "    # Update 'ns' with the user-supplied namespace plus our calculated values.\n",
    "    def exec_body_callback(ns):\n",
    "        ns.update(namespace)\n",
    "        ns.update(defaults)\n",
    "        ns[\"__annotations__\"] = annotations\n",
    "\n",
    "    # We use `types.new_class()` instead of simply `type()` to allow dynamic creation\n",
    "    # of generic dataclasses.\n",
    "    cls = types.new_class(cls_name, bases, kwds, exec_body_callback)\n",
    "\n",
    "    # Apply the normal decorator.\n",
    "    return dataclass(\n",
    "        cls,\n",
    "        init=init,\n",
    "        repr=repr,\n",
    "        eq=eq,\n",
    "        order=order,\n",
    "        unsafe_hash=unsafe_hash,\n",
    "        frozen=frozen,\n",
    "        match_args=match_args,\n",
    "        kw_only=kw_only,\n",
    "        slots=slots,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427e8fad-d71c-4a6b-992b-20ce1da9a101",
   "metadata": {},
   "source": [
    "# The trick!\n",
    "\n",
    "We create a class `Config`, but, this object behaves unlike other python objects!\n",
    "\n",
    "1. Config are dependent classes that should only exist attached to a parent class.\n",
    "2. Configs are immutable Mapping-Like objects, changing keys returns a different object!\n",
    "3. Configs are similar to dataclasses. However, a key difference is that they can be initialized with a `MISSING` object.\n",
    "4. Configs can map **1:1** to nested dictionaries of elementary types\n",
    "5. Configs can map **1:1** to `json` files.\n",
    "6. Configs offer functionality to update nested entries easily `{\"obj/subobj/subsubobj\" : \"value\"}`\n",
    "7. Configs can be mapped to flattened / unflattened representation.\n",
    "8. Configs only allow keys that are not `__dunder__`.\n",
    "9. Keys ~~`__name__` and `__module__` are automatically added at class definition time.~~\n",
    "    - Reserve ALLCAPS fields.\n",
    "10. Configs offer a `validate` option that checks the types.\n",
    "\n",
    "Usage:\n",
    "\n",
    "\n",
    "```python\n",
    "Foo:\n",
    "    Config(BaseConfig):\n",
    "        input_size: int\n",
    "        output_size: int\n",
    "        ...\n",
    "        \n",
    "```\n",
    "\n",
    "Then `Foo.Config` is a type.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bde51db-b3c6-42d6-9382-d38ccba95e9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import ClassVar\n",
    "\n",
    "\n",
    "class BaseConfigMetaclass(ABCMeta):\n",
    "    \"\"\"This Metaclass does a few things:\n",
    "\n",
    "    1. Makes sure BaseClass and all subclasses are DataClasses.\n",
    "    \"\"\"\n",
    "\n",
    "    _PROTECTED_KEYS = {\n",
    "        \"__module__\",\n",
    "        \"__qualname__\",\n",
    "        \"__annotations__\",\n",
    "        \"__doc__\",\n",
    "    }\n",
    "\n",
    "    # fmt: off\n",
    "    _FORBIDDEN_KEYS = {\n",
    "\n",
    "        \"clear\",       #  Removes all the elements from the dictionary\n",
    "        \"copy\",        #  Returns a copy of the dictionary\n",
    "        \"fromkeys\",    #  Returns a dictionary with the specified keys and value\n",
    "        \"get\",         #  Returns the value of the specified key\n",
    "        \"items\",       #  Returns a list containing a tuple for each key value pair\n",
    "        \"keys\",        #  Returns a list containing the dictionary's keys\n",
    "        \"pop\",         #  Removes the element with the specified key\n",
    "        \"popitem\",     #  Removes the last inserted key-value pair\n",
    "        \"setdefault\",  #  Returns the value of the specified key. If the key does not exist: insert the key, with the specified value\n",
    "        \"update\",      #  Updates the dictionary with the specified key-value pairs\n",
    "        \"values\",      #  Returns a list of all the values in the dictionary\n",
    "    }\n",
    "    # fmt: on\n",
    "\n",
    "    def __new__(cls, name, bases, attrs, **kwds):\n",
    "        print(\">>>>>>>>>> NEW CALLED <<<<<<<<<<<<<<<\")\n",
    "        \n",
    "        if \"__annotations__\" not in attrs:\n",
    "            attrs[\"__annotations__\"] = {}\n",
    "        \n",
    "        display(f\"{cls=}\")\n",
    "        display(f\"{dir(cls)=}\")\n",
    "        # display(f\"{args=}\")\n",
    "        display(f\"{cls.__qualname__=}\")\n",
    "        display(f\"{name=}\")\n",
    "        display(f\"{bases=}\")\n",
    "        display(f\"{set(attrs)=}\")\n",
    "        display(f\"{attrs['__annotations__']=}\")\n",
    "\n",
    "        if '__slots__' in attrs:\n",
    "            display(f\"{attrs['__slots__']=}\")\n",
    "        if '__qualname__' in attrs:\n",
    "            display(f\"{attrs['__qualname__']=}\")\n",
    "        display(f\"{kwds=}\")\n",
    "        \n",
    "        print(\">>>>>>>>>>  CREATED NEW TYPE <<<<<<<<<<<<<<<\")\n",
    "        newtype = super().__new__(cls, name, bases, attrs, **kwds)\n",
    "        display(f\"{newtype=}\")\n",
    "        display(f\"{dir(newtype)=}\")\n",
    "        display(f\"{newtype.__qualname__=}\")\n",
    "        parents = newtype.__qualname__.rsplit(\".\", maxsplit=1)\n",
    "        parent = None if len(parents) == 1 else parents[0]\n",
    "\n",
    "        patched_fields = {\n",
    "            \"_\" : (\"_\", KW_ONLY),\n",
    "            \"NAME\" :(\n",
    "                \"NAME\",\n",
    "                str,\n",
    "                field(default=attrs['__qualname__']))\n",
    "            \"MODULE\": (\n",
    "                \"MODULE\",\n",
    "                str,\n",
    "                field(default=attrs['__module__']),\n",
    "            ),\n",
    "\n",
    "        }\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        fields = [\n",
    "            (key, hint, attrs[key]) if key in attrs else (key, hint)\n",
    "            for key, hint in attrs[\"__annotations__\"].items()\n",
    "        ]\n",
    "\n",
    "        for key in patched_fields:\n",
    "            if key not in attrs[\"__annotations__\"]:\n",
    "                fields.append(patched_fields[key])\n",
    "\n",
    "        display(f\"{fields=}\")\n",
    "        display(f\"{patched_fields=}\")\n",
    "\n",
    "        patched_attrs = {\n",
    "            key: value for key, value in attrs.items() if key not in patched_fields\n",
    "        }\n",
    "        \n",
    "                \n",
    "        KEYS = set(attrs['__annotations__']) - cls._PROTECTED_KEYS\n",
    "\n",
    "        if KEYS & cls._FORBIDDEN_KEYS:\n",
    "            raise ValueError(\n",
    "                f\"Keys '{FORBIDDEN_KEYS}' are not allowed! Found: '{KEYS & cls._FORBIDDEN_KEYS}'\"\n",
    "            )\n",
    "\n",
    "        DUNDER_KEYS = {\n",
    "            key for key in KEYS if is_dunder(key) and key not in patched_fields\n",
    "        }\n",
    "        if DUNDER_KEYS:\n",
    "            raise ValueError(f\"Dunder fields are not allowed, found {DUNDER_KEYS}\")\n",
    "\n",
    "#         config_type = make_dataclass(\n",
    "#             name, fields, bases=bases, namespace=attrs, eq=False, frozen=True\n",
    "#         )\n",
    "\n",
    "        for key in patched_fields:\n",
    "            if key not in attrs[\"__annotations__\"]:\n",
    "                # fields.append(patched_fields[key])\n",
    "                newtype.__annotations__[key] = patched_fields[key][1]\n",
    "                setattr(newtype, key, patched_fields[key][-1])\n",
    "\n",
    "                \n",
    "        display(f\"{newtype.__annotations__=}\")\n",
    "        config_type = dataclass(newtype, eq=False, frozen=True)\n",
    "        \n",
    "        \n",
    "        display(f\"{config_type=}\")\n",
    "        \n",
    "        return config_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e56d05-bd98-40e0-875e-5f1a1718ef9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def is_allcaps(s: str) -> bool:\n",
    "    return s.isidentifier() and s.isupper() and s.isalpha()\n",
    "\n",
    "\n",
    "def is_dunder(s: str) -> bool:\n",
    "    return s.isidentifier() and s.startswith(\"__\") and s.endswith(\"__\")\n",
    "\n",
    "\n",
    "class BaseConfigMetaclass(ABCMeta):\n",
    "    \"\"\"This Metaclass does a few things:\n",
    "\n",
    "    1. Makes sure BaseClass and all subclasses are DataClasses.\n",
    "    \"\"\"\n",
    "\n",
    "    # fmt: off\n",
    "    _FORBIDDEN_FIELDS = {\n",
    "        \"clear\",       #  Removes all the elements from the dictionary\n",
    "        \"copy\",        #  Returns a copy of the dictionary\n",
    "        \"fromkeys\",    #  Returns a dictionary with the specified keys and value\n",
    "        \"get\",         #  Returns the value of the specified key\n",
    "        \"items\",       #  Returns a list containing a tuple for each key value pair\n",
    "        \"keys\",        #  Returns a list containing the dictionary's keys\n",
    "        \"pop\",         #  Removes the element with the specified key\n",
    "        \"popitem\",     #  Removes the last inserted key-value pair\n",
    "        \"setdefault\",  #  Returns the value of the specified key. If the key does not exist: insert the key, with the specified value\n",
    "        \"update\",      #  Updates the dictionary with the specified key-value pairs\n",
    "        \"values\",      #  Returns a list of all the values in the dictionary\n",
    "    }\n",
    "    # fmt: on\n",
    "\n",
    "    def __new__(cls, name, bases, attrs, **kwds):\n",
    "        if \"__annotations__\" not in attrs:\n",
    "            attrs[\"__annotations__\"] = {}\n",
    "\n",
    "        newtype = super().__new__(cls, name, bases, attrs, **kwds)\n",
    "        FIELDS = set(attrs[\"__annotations__\"])\n",
    "\n",
    "        # check forbidden fields\n",
    "        FORBIDDEN_FIELDS = cls._FORBIDDEN_FIELDS & FIELDS\n",
    "        if FORBIDDEN_FIELDS:\n",
    "            raise ValueError(\n",
    "                f\"Fields '{cls._FORBIDDEN_FIELDS}' are not allowed! \"\n",
    "                f\"Found '{FORBIDDEN_FIELDS}'\"\n",
    "            )\n",
    "\n",
    "        # check for dunder fields\n",
    "        DUNDER_FIELDS = {key for key in FIELDS if is_dunder(key)}\n",
    "        if DUNDER_FIELDS:\n",
    "            raise ValueError(f\"Dunder fields are not allowed!Found '{DUNDER_KEYS}'.\")\n",
    "\n",
    "        # check all caps fields\n",
    "        ALLCAPS_FIELDS = {key for key in FIELDS if is_allcaps(key)}\n",
    "        if ALLCAPS_FIELDS:\n",
    "            raise ValueError(f\"ALLCAPS fields are reserved!Found '{ALLCAPS_FIELDS}'.\")\n",
    "\n",
    "        NAME = newtype.__qualname__.rsplit(\".\", maxsplit=1)[0]\n",
    "        patched_fields = [\n",
    "            (\"_\", KW_ONLY),\n",
    "            (\"NAME\", str, field(default=NAME)),\n",
    "            (\"MODULE\", str, field(default=attrs[\"__module__\"])),\n",
    "        ]\n",
    "\n",
    "        for key, hint, *value in patched_fields:\n",
    "            newtype.__annotations__[key] = hint\n",
    "            if value:\n",
    "                setattr(newtype, key, value[0])\n",
    "\n",
    "        return dataclass(newtype, eq=False, frozen=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4378e7b4-f5a7-4e7c-aa33-adad71b075ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BaseConfig(Mapping, metaclass=BaseConfigMetaclass):\n",
    "    \"\"\"Base Config\"\"\"\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.__dict__)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        return self.__dict__[key]\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.__dict__)\n",
    "\n",
    "    # def __eq__(self, other):\n",
    "    #     print(f\"HERE!!!\")\n",
    "    #     if not isinstance(other, Mapping):\n",
    "    #         return NotImplemented\n",
    "    #     return dict(self.items()) == dict(other.items())\n",
    "\n",
    "    def __hash__(self) -> int:\n",
    "        r\"\"\"Return permutation-invariant hash on `items()`.\"\"\"\n",
    "        return hash(frozenset(self.items()))\n",
    "\n",
    "    def __or__(self, other):\n",
    "        res = {}\n",
    "        res.update(self)\n",
    "        res.update(other)\n",
    "        return self.__class__(**res)\n",
    "\n",
    "\n",
    "BaseConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219ad4a6-9695-4ee2-b71e-be78ac3513a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MyConfig(BaseConfig):\n",
    "    \"\"\".\"\"\"\n",
    "\n",
    "    # __name__: str = \"demo\"\n",
    "    c: str = \"test\"\n",
    "    # keys: str = \"a\"\n",
    "\n",
    "\n",
    "class SubConfig(MyConfig):\n",
    "    d: str = \"a\"\n",
    "\n",
    "\n",
    "class Foo:\n",
    "    class MyConfig(BaseConfig):\n",
    "        # __name__: str = \"demo\"\n",
    "        _: KW_ONLY\n",
    "        c: str = \"test\"\n",
    "\n",
    "    class SubConfig(MyConfig):\n",
    "        \"\"\".\"\"\"\n",
    "\n",
    "        # __name__: str = \"demo\"\n",
    "        d: str\n",
    "        e: str = \"demo\"\n",
    "        # c: str = \"test\"\n",
    "\n",
    "\n",
    "Foo.SubConfig(1) == dict(Foo.SubConfig(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87993552-68f9-4bbd-9017-c14d14d5165c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class MyConfig:\n",
    "    _: KW_ONLY\n",
    "    c: str = \"test\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SubConfig(MyConfig):\n",
    "    d: str\n",
    "\n",
    "\n",
    "SubConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c61251-829d-4dc7-8f94-abc629778e59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MyConfig.__annotations__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ad292e-b1b9-47c8-9ae9-13b50dae3345",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Foo.MyConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725f4914-82da-4fae-ad72-c4a31c435233",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Foo.MyConfig().__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c78ce76-a55a-4427-bf9f-23136e8765fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Foo.MyConfig().__dataclass_fields__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021e7177-6493-40c2-add4-9dc01a2170b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = {\"c\": \"test\"}\n",
    "b = Foo.MyConfig(**a)\n",
    "\n",
    "set(dir(a)) - set(dir(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cab090-9623-4dcd-a589-c683aa66e920",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections.abc import Mapping\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass(eq=False, frozen=True)\n",
    "class Foo(Mapping):\n",
    "    c: str = \"test\"\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.__dict__)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        return self.__dict__[key]\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c967055d-17fa-4f18-9408-a9c843275e7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555c262c-f892-4607-8a4f-7e3e625089e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3858650b-847a-4832-bd4a-bcfc25ef1ced",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = {\"c\": \"test\"}\n",
    "b = Foo(**a)\n",
    "\n",
    "print(b.__dict__)\n",
    "assert b.__eq__(a)  # ✔\n",
    "assert a.__eq__(b)  # DeprecationWarning: NotImplemented\n",
    "assert dict(b) == a  # ✔\n",
    "assert list(b.keys()) == list(a.keys())  # ✔\n",
    "assert list(b.values()) == list(a.values())  # ✔\n",
    "assert list(b.items()) == list(a.items())  # ✔\n",
    "assert b.keys() == a.keys()  # ✔\n",
    "assert b.values().__eq__(a.values())  # DeprecationWarning: NotImplemented\n",
    "assert a.values().__eq__(b.values())  # DeprecationWarning: NotImplemented\n",
    "assert b.values() == a.values()  # ✘  Fails!!\n",
    "assert b.items() == a.items()  # ✔\n",
    "assert dict(b.items()) == dict(a.items())  # ✔\n",
    "assert b == a  # ✔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5d6fe2-7d2f-4759-b675-5bae072feab3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Test(Mapping):\n",
    "    content: dict\n",
    "\n",
    "    def __init__(self, content):\n",
    "        self.content = content\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        return self.content[key]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.content)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910cfeff-da54-496c-8883-9cd32d2a61ad",
   "metadata": {},
   "source": [
    "# Using Pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec76add3-940c-4317-a0cf-fe4169acb369",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Foo:\n",
    "    class Bar:\n",
    "        @dataclass\n",
    "        class Config(BaseConfig):\n",
    "            input_size: int\n",
    "            output_size: int\n",
    "            latent_size: Optional[int] = None\n",
    "            num_layers: int = 2\n",
    "            activation: str = Config(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8785a95f-a163-4523-92a0-ed124ac18fea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class Foo:\n",
    "    __name__: str = \"lol\"\n",
    "    a: str = \"xd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d806b05-700d-4450-b609-4fd52629b917",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResNetBlock(nn.Module):\n",
    "    \"\"\"ResNet Block Model\"\"\"\n",
    "\n",
    "    @pydantic_dataclass\n",
    "    class Config:\n",
    "        input_size: int\n",
    "        bottleneck_size: Optional[int] = None\n",
    "        num_layers: int = 2\n",
    "        activation: str | Config = \"relu\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layerA = nn.Linear()\n",
    "        self.layerB = nn.Linear()\n",
    "        self.activation = ...\n",
    "\n",
    "\n",
    "from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10839076-a01f-4e0b-9b1b-0b9458618639",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResNet(nn.ModuleList):\n",
    "    r\"\"\"A ResNet model.\"\"\"\n",
    "\n",
    "    @pydantic_dataclass\n",
    "    class Config:\n",
    "        input_size: int\n",
    "        output_size: int\n",
    "        latent_size: Optional[int] = None\n",
    "        num_layers: int = 2\n",
    "        activation: str = \"relu\"\n",
    "\n",
    "    HP: Final[dict] = {\n",
    "        \"__name__\": __qualname__,  # type: ignore[name-defined]\n",
    "        \"__module__\": __module__,  # type: ignore[name-defined]\n",
    "        \"input_size\": None,\n",
    "        \"num_blocks\": 5,\n",
    "        # \"blocks\": ResNetBlock.HP,\n",
    "    }\n",
    "\n",
    "    def __new__(cls, *blocks, **hparams):\n",
    "        r\"\"\"Initialize from hyperparameters.\"\"\"\n",
    "        assert len(blocks) ^ len(hparams), \"Provide either blocks, or hyperparameters!\"\n",
    "\n",
    "        if hparams:\n",
    "            return cls.from_hyperparameters(**hparams)\n",
    "\n",
    "        return super().__new__(cls)\n",
    "\n",
    "    def __init__(self, *blocks: Any, **hparams: Any) -> None:\n",
    "        assert len(blocks) ^ len(hparams), \"Provide either blocks, or hyperparameters!\"\n",
    "\n",
    "        if hparams:\n",
    "            return\n",
    "        super().__init__(*blocks, **hparams)\n",
    "\n",
    "    @classmethod\n",
    "    def from_hyperparameters(\n",
    "        cls,\n",
    "        *,\n",
    "        input_size: int,\n",
    "        num_blocks: int = 5,\n",
    "        # block_cfg: dict = ResNetBlock.HP,\n",
    "    ):\n",
    "        r\"\"\"Create a ResNet model from hyperparameters.\"\"\"\n",
    "        if \"input_size\" in block_cfg:\n",
    "            block_cfg[\"input_size\"] = input_size\n",
    "\n",
    "        blocks: list[nn.Module] = []\n",
    "        for _ in range(num_blocks):\n",
    "            module: nn.Module = initialize_from_config(block_cfg)\n",
    "            blocks.append(module)\n",
    "        return cls(*blocks)\n",
    "\n",
    "    @jit.export\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        r\"\"\"Forward pass.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: Tensor\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Tensor\n",
    "        \"\"\"\n",
    "        for block in self:\n",
    "            x = x + block(x)\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

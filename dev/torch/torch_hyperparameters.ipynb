{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcb22a3-0e9e-419c-8d04-eb740109519f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import *\n",
    "from typing import Any, Dict, Final, List, Optional, Tuple\n",
    "\n",
    "import torch\n",
    "from torch import Tensor, jit, nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a20072c-9b51-4d92-8ff0-ed7e81fa542f",
   "metadata": {},
   "source": [
    "# Can we serialize models with attached dictionary?\n",
    "\n",
    "⟹ only when flattened!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbce5da-c0ba-453b-92ce-e1bcc0fd607c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_attribute(model: nn.Module, attr: str) -> None:\n",
    "    r\"\"\"Check whether attr is maintained under torhc JIT\"\"\"\n",
    "\n",
    "    original_model = model\n",
    "\n",
    "    if hasattr(original_model, attr):\n",
    "        attribute = getattr(original_model, attr)\n",
    "        print(f\"{original_model}.{attr}={attribute}\")\n",
    "    else:\n",
    "        print(f\"{original_model}.{attr} does not exist\")\n",
    "\n",
    "    serialized_model = jit.script(model)\n",
    "\n",
    "    if hasattr(serialized_model, attr):\n",
    "        attribute = getattr(serialized_model, attr)\n",
    "        print(f\"{serialized_model}.{attr}={attribute}\")\n",
    "    else:\n",
    "        print(f\"{serialized_model}.{attr} does not exist\")\n",
    "\n",
    "    jit.save(serialized_model, \"model.pt\")\n",
    "    loaded_model = jit.load(\"model.pt\")\n",
    "\n",
    "    if hasattr(loaded_model, attr):\n",
    "        attribute = getattr(loaded_model, attr)\n",
    "        print(f\"{loaded_model}.{attr}={attribute}\")\n",
    "    else:\n",
    "        print(f\"{loaded_model}.{attr} does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e060fcee-a3cf-4df7-89bc-c81dbe031c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsdm.utils import flatten_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039f227c-58c8-4260-9971-9ebce4eb28a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyConfig:\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4bc96f-ec72-40d4-9157-43cbdf7ed78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "?flatten_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6587e9c-3ed0-474a-b4b8-40a1f771e4ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d128ac-ebe7-4c24-8eda-ea66fa017d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_dict(\n",
    "    d: dict[str, Iterable[Any]], /, *, recursive: bool = True, how: Callable = \"tuple\"\n",
    ") -> dict[tuple[str, ...], Any]:\n",
    "    r\"\"\"Flatten a dictionary containing iterables to a list of tuples.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    d: dict\n",
    "    recursive: bool (default=True)\n",
    "        If true applies flattening strategy recursively on nested dicts, yielding\n",
    "        list[tuple[key1, key2, ...., keyN, value]]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[tuple[Any, ...]]\n",
    "    \"\"\"\n",
    "\n",
    "    result = {}\n",
    "    for key, item in d.items():\n",
    "        if isinstance(key, tuple):\n",
    "            raise ValueError(\"Keys are not allowed to be tuples!\")\n",
    "        if isinstance(item, dict) and recursive:\n",
    "            subdict = flatten_dict(item, recursive=True)\n",
    "            for subkey, subitem in subdict.items():\n",
    "                result[(key, subkey)] = subitem\n",
    "        else:\n",
    "            result[key] = item\n",
    "    return result\n",
    "\n",
    "\n",
    "def unflatten_dict(\n",
    "    d: dict[Hashable, Iterable[Any]], recursive: bool = True\n",
    ") -> list[tuple[Any, ...]]:\n",
    "    r\"\"\"Flatten a dictionary containing iterables to a list of tuples.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    d: dict\n",
    "    recursive: bool (default=True)\n",
    "        If true applies flattening strategy recursively on nested dicts, yielding\n",
    "        list[tuple[key1, key2, ...., keyN, value]]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[tuple[Any, ...]]\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    for key, item in d.items():\n",
    "        if isinstance(key, tuple):\n",
    "            if key[0] not in result:\n",
    "                result[key[0]] = {}\n",
    "\n",
    "            # subdict = {subkey[1:]: subitem for subkey, subitem in item.items()}\n",
    "            if len(key) <= 1:\n",
    "                result[key[0]] |= {key[1:]: item}\n",
    "            else:\n",
    "                result[key[0]] |= unflatten_dict({key[1:]: item})\n",
    "\n",
    "        else:\n",
    "            result[key] = item\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4eb28a2-0c94-4b45-80e9-62d0c7b14781",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict: dict[str, Any] = {\n",
    "    \"foo\": 2,\n",
    "    \"bar\": True,\n",
    "    \"baz\": 0.99,\n",
    "    \"nested\": {\n",
    "        \"foo\": 1,\n",
    "        \"bar\": True,\n",
    "        \"baz\": 0.99,\n",
    "        \"nested\": {\"foo\": 1, \"bar\": True, \"baz\": 0.99},\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22715207-de76-4f16-9ea7-428b14b0752f",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat = flatten_dict(DemoModel.FOO)\n",
    "flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4f2ae4-66f3-4a86-8b2e-7a7e9fdd6765",
   "metadata": {},
   "outputs": [],
   "source": [
    "unflatten_dict(flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84de493-75c0-4dec-b1e9-479b51e09e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DemoModel(nn.Module):\n",
    "    FOO: Dict[str, Any] = {\n",
    "        \"a\": 2,\n",
    "        \"b\": True,\n",
    "        \"c\": 0.99,\n",
    "        \"d\": {\"a\": 1, \"b\": True, \"c\": 0.99, \"d\": {\"a\": 1}},\n",
    "    }\n",
    "\n",
    "    BAR: Dict[str, Any]\n",
    "    # BAZ: Dict[str, Any]\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self.BAR = flatten_dict(self.FOO)\n",
    "        super().__init__()\n",
    "        # self.BAZ = self.FOO\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        r\"\"\"Simply identity\"\"\"\n",
    "        return x\n",
    "\n",
    "\n",
    "test_model_attribute(DemoModel(), \"FOO\")\n",
    "test_model_attribute(DemoModel(), \"BAR\")\n",
    "test_model_attribute(DemoModel(), \"BAZ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5493b04f-021d-4abd-86d5-86ec6789225c",
   "metadata": {},
   "source": [
    "# Observations\n",
    "\n",
    "- As of **`torch=1.12.1`**, `typing.Dict` works but `dict` doesn't?\n",
    "- AS of **`torch=1.12.1`**, nested dictionaries are not supported.\n",
    "- As of **`torch=1.12.1`**, tracing only works if\n",
    "    - The complete dictionary is added in the class \n",
    "    - The dictionary is not annotated.\n",
    "- It makes no difference whether the dictionary is added before or after `super().__init__` is called\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8ac6b7-002b-47d9-8c04-a3f64d0ca389",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Idea\n",
    "\n",
    "We need to do 2 things for a robust initialization\n",
    "\n",
    "1. Input validation: in particular, cast values to correct type\n",
    "    - Could use pydantic\n",
    "        - Does not seem to support `KW_ONLY` yet.\n",
    "        - Use regular `DataClasses` in the meantime?\n",
    "        - ~~Alternative `TypedDict`?~~\n",
    "            - `TypedDict` do not allow extra keys... https://github.com/python/mypy/issues/4617\n",
    "2. Sub-module compatibility: e.g. module might need to be written such that latent size agrees with output size of other module.\n",
    "    - If values are given, check for compatibility.\n",
    "    - If values are not given, use defaults.\n",
    "        - `if \"input_size\" in **kwargs:... else ...`\n",
    "    - Do we want to support mixed inputs? (e.g. `encoder=<some nn.Module>`, `activation=<module_dict>`)\n",
    "3. Module Creation.\n",
    "    - Should be the responsibility of `from_hyperparameters` / `__new__` / `__init__`.\n",
    "4. Every Module should sport a default config\n",
    "    - Other Modules should be able to use this config, e.g. `encoder=MyEncoderModel.Config`\n",
    "        - If uninitialized class is given, the initialize with its default dict.\n",
    "        - If initialized class is given, use it as is.\n",
    "        - If config / dictionary is given, use it to locate the module and initialize it.\n",
    "5. Serialization: \n",
    "    - The Dataclass / NestedDict should work arbitrary Optional data.\n",
    "6. Should positional arguments be allowed or only `*args`?\n",
    "8. Optional cool stuff:\n",
    "    - Signatures and automatic signature validation.\n",
    "        - Only makes sense post-initialization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4c7dcd-27dd-4624-a1db-6b230ed3e6db",
   "metadata": {},
   "source": [
    "## Specification\n",
    "\n",
    "- Need a class object that maps 1:1 to a nested `dict` / `json` / `toml` file.\n",
    "    - Implement conversion utilities (⇝ pydantic.)\n",
    "- Should have a fixed set of required values, but allow optional values (with some naming restrictions)\n",
    "- Certain values (`__name__`, `__qualname__`, `__module__`) should always be included.\n",
    "\n",
    "How object is created.\n",
    "\n",
    "- Option 1: Subclass a `BaseConfig` class that implements the `__name__` logic.\n",
    "    - How to pass `*args`, `**kwargs`?\n",
    "    ```python\n",
    "    class MyModel(nn.Module):\n",
    "        Config(BaseConfig):\n",
    "            a: int,\n",
    "            b: int, \n",
    "            *args: Any\n",
    "            droprate: float = 0.2\n",
    "            **kwargs: Any\n",
    "    ```\n",
    "\n",
    "- Option 2: DataClass / TypedDict\n",
    "- Option 3: Instantiate a class locally? (How to pass Type Hints?)\n",
    "- Option 4: Class Factory. (might actually be best?) Issue: doesn't work syntactically.\n",
    "    \n",
    "    ```python\n",
    "    class MyModel(nn.Module):\n",
    "        Config = create_config(\n",
    "            a: int,\n",
    "            b: int, \n",
    "            *args: Any\n",
    "            droprate: float = 0.2\n",
    "            **kwargs: Any\n",
    "        )\n",
    "    ```\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a975dfea-2400-4add-aeb4-66bac17fd770",
   "metadata": {},
   "source": [
    "## How to deal with missing values?\n",
    "\n",
    "```python\n",
    "class MyModel(nn.Module):\n",
    "    Config:\n",
    "        input_size: int\n",
    "        drop_rate: float = 0.5\n",
    "```\n",
    "\n",
    "This Model requires getting input_size as an input. \n",
    "- How do we initialize it? \n",
    "- How does the default config in dictionary form look like?\n",
    "    - Should we even be able to serialize it with missing keys?\n",
    "- What value do we put for missing?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c55393-b6c3-4918-8d73-19fce9cf355a",
   "metadata": {},
   "source": [
    "```python\n",
    "class MyModel:    \n",
    "    class Config:\n",
    "        ...\n",
    "    \n",
    "Class MyOtherModel:\n",
    "\n",
    "    class Config:\n",
    "        encoder: MyModel\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b98599-6af2-46f7-8e28-16b26d137ada",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91382dfe-c9e7-420b-950d-8fdfc5e87253",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28dba4f-7c8c-449b-9ebb-7bc22508bad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo(*args, **kwargs):\n",
    "    return args, kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c78203-b9b0-4b74-b4e3-86e368b7a487",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class User(BaseModel):\n",
    "    id: int\n",
    "    name = \"Jane Doe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3e9c97-a41f-4247-a981-46c31aee24d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "User([], id=2, x=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d383bd-79a7-4df0-8a6c-591d48870b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ff2986-b665-4317-baf7-171d14b99fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import dataclasses as pydantic_dataclasses\n",
    "from pydantic.dataclasses import dataclass as pydantic_dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec76add3-940c-4317-a0cf-fe4169acb369",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pydantic_dataclass\n",
    "class Config:\n",
    "    input_size: int\n",
    "    output_size: int\n",
    "    latent_size: Optional[int] = None\n",
    "    num_layers: int = 2\n",
    "    activation: str = \"relu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6c7f1e-6d5a-4207-aa42-ec12485ff9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "Config.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b60539-8839-4dec-ab4e-c771f9ab7689",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.Module | type[nn.Module] |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930f5a10-89e9-4a54-b8ce-6216dd7cba00",
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNet.Config.__qualname__ - ResNet.Config.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10839076-a01f-4e0b-9b1b-0b9458618639",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.ModuleList):\n",
    "    r\"\"\"A ResNet model.\"\"\"\n",
    "\n",
    "    @pydantic_dataclass\n",
    "    class Config:\n",
    "        input_size: int\n",
    "        output_size: int\n",
    "        latent_size: Optional[int] = None\n",
    "        num_layers: int = 2\n",
    "        activation: str = \"relu\"\n",
    "\n",
    "    HP: Final[dict] = {\n",
    "        \"__name__\": __qualname__,  # type: ignore[name-defined]\n",
    "        \"__module__\": __module__,  # type: ignore[name-defined]\n",
    "        \"input_size\": None,\n",
    "        \"num_blocks\": 5,\n",
    "        # \"blocks\": ResNetBlock.HP,\n",
    "    }\n",
    "\n",
    "    def __new__(cls, *blocks, **hparams):\n",
    "        r\"\"\"Initialize from hyperparameters.\"\"\"\n",
    "        assert len(blocks) ^ len(hparams), \"Provide either blocks, or hyperparameters!\"\n",
    "\n",
    "        if hparams:\n",
    "            return cls.from_hyperparameters(**hparams)\n",
    "\n",
    "        return super().__new__(cls)\n",
    "\n",
    "    def __init__(self, *blocks: Any, **hparams: Any) -> None:\n",
    "        assert len(blocks) ^ len(hparams), \"Provide either blocks, or hyperparameters!\"\n",
    "\n",
    "        if hparams:\n",
    "            return\n",
    "        super().__init__(*blocks, **hparams)\n",
    "\n",
    "    @classmethod\n",
    "    def from_hyperparameters(\n",
    "        cls,\n",
    "        *,\n",
    "        input_size: int,\n",
    "        num_blocks: int = 5,\n",
    "        # block_cfg: dict = ResNetBlock.HP,\n",
    "    ):\n",
    "        r\"\"\"Create a ResNet model from hyperparameters.\"\"\"\n",
    "        if \"input_size\" in block_cfg:\n",
    "            block_cfg[\"input_size\"] = input_size\n",
    "\n",
    "        blocks: list[nn.Module] = []\n",
    "        for _ in range(num_blocks):\n",
    "            module: nn.Module = initialize_from_config(block_cfg)\n",
    "            blocks.append(module)\n",
    "        return cls(*blocks)\n",
    "\n",
    "    @jit.export\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        r\"\"\"Forward pass.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: Tensor\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Tensor\n",
    "        \"\"\"\n",
    "        for block in self:\n",
    "            x = x + block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08860486-1b28-49ac-b3f9-2164314c692a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

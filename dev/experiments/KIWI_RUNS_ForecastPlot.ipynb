{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InteractiveShell.ast_node_interactivity='last_expr_or_assign'  # always print last expr.\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(\"bmh\")\n",
    "plt.rcParams[\"axes.axisbelow\"] = True\n",
    "import numpy as np\n",
    "import pandas\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Index, Series, Timedelta, Timestamp\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "np.set_printoptions()\n",
    "\n",
    "import torch\n",
    "import torchinfo\n",
    "from torch import Tensor, jit, tensor\n",
    "from torch.utils.data import DataLoader\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = (439, 15325)  # the Run_id / Experiment_id we want to plot.\n",
    "\n",
    "# files:  2021-11-12T00:52:10 2021-11-12T00:51:55 2021-11-12T00:51:48\n",
    "# \"checkpoints/2021-11-15T12:05:00/LinODEnet-0\"\n",
    "# \"checkpoints/LinODEnet/KIWI_RUNS/skew_allways/2021-11-15T16:05:41/LinODEnet-0\"\n",
    "# \"adam/2021-11-15T20:38:52/LinODEnet-0\"\n",
    "PATH = \"checkpoints/LinODEnet/KIWI_RUNS/\"\n",
    "NAME = \"adam/2021-11-15T20:38:52/LinODEnet-0\"\n",
    "MODEL_FILE = PATH + NAME  # the model checkpoint\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "DTYPE = torch.float32\n",
    "NAN = tensor(float(\"nan\"), dtype=DTYPE, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply_along_axes(a: Tensor, b: Tensor, op, axes: tuple[int, ...]) -> Tensor:\n",
    "    print(a.shape, axes)\n",
    "    rank = len(a.shape)\n",
    "    axes = tuple(ax % rank for ax in axes)\n",
    "    source = tuple(range(rank))\n",
    "    iperm = axes + tuple(ax for ax in range(rank) if ax not in axes)\n",
    "    perm = tuple(np.argsort(iperm))\n",
    "    print(source, perm, iperm)\n",
    "    a = a.moveaxis(source, perm)\n",
    "    # print(a.shape, b.shape)\n",
    "    a = op(a, b)\n",
    "    a = a.moveaxis(source, iperm)\n",
    "    # print(a.shape)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.randn(7, 8, 9)\n",
    "data[data > 0] = NAN\n",
    "axes = (-1,)\n",
    "mask = ~torch.isnan(data)\n",
    "count = mask.sum(dim=axes)\n",
    "masked = torch.where(mask, data, tensor(0.0))\n",
    "print(f\"{torch.isnan(masked).any()=}\")\n",
    "mean = masked.sum(dim=axes) / count\n",
    "residual = apply_along_axes(masked, mean, torch.sub, axes=axes)\n",
    "stdv = (residual**2).sum(dim=axes) / torch.minimum(torch.tensor(1.0), count - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsdm.tasks import KIWI_RUNS_TASK\n",
    "\n",
    "task = KIWI_RUNS_TASK()\n",
    "assert ID in task.splits[(0, \"train\")][0].index\n",
    "TRAINLOADER = task.dataloaders[(0, \"train\")]\n",
    "EVALLOADER = task.dataloaders[(0, \"test\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = task.timeseries\n",
    "ts = ts.loc[ID].astype(\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.jit.load(MODEL_FILE, torch.device(\"cpu\"))\n",
    "torchinfo.summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Look: simply plot the first item from each dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_batch(batch: tuple[Tensor, Tensor]):\n",
    "    \"\"\"Get batch and create model inputs and targets\"\"\"\n",
    "    T, X = batch\n",
    "    targets = X[..., task.observation_horizon :, task.targets.index].clone()\n",
    "    # assert targets.shape == (BATCH_SIZE, PRD_HORIZON, len(TASK.targets))\n",
    "    originals = X.clone()\n",
    "    inputs = X.clone()\n",
    "    inputs[:, task.observation_horizon :, task.targets.index] = NAN\n",
    "    inputs[:, task.observation_horizon :, task.observables.index] = NAN\n",
    "    # assert inputs.shape == (BATCH_SIZE, HORIZON, NUM_DIM)\n",
    "    return T, inputs, targets, originals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iload = iter(TRAINLOADER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iload)\n",
    "times, inputs, targets, originals = (x.to(device=\"cpu\") for x in prep_batch(batch))\n",
    "outputs = model(times, inputs)\n",
    "\n",
    "times = times[0].detach().cpu().numpy()\n",
    "inputs = inputs[0].detach().cpu().numpy()\n",
    "outputs = outputs[0].detach().cpu().numpy()\n",
    "targets = targets[0].detach().cpu().numpy()\n",
    "originals = originals[0].detach().cpu().numpy()\n",
    "\n",
    "times.shape, outputs.shape, inputs.shape, targets.shape, originals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(\n",
    "    nrows=2, ncols=2, sharex=True, figsize=(8, 4), constrained_layout=True\n",
    ")\n",
    "\n",
    "for ax, (idx, target) in zip(axes.flatten(), task.targets.items()):\n",
    "\n",
    "    data = originals[:, idx]\n",
    "    mask = ~np.isnan(data)\n",
    "\n",
    "    ax.plot(\n",
    "        times[mask],\n",
    "        data[mask],\n",
    "        ls=\"-\",\n",
    "        lw=0.5,\n",
    "        marker=\".\",\n",
    "        ms=3,\n",
    "    )\n",
    "    ax.plot(\n",
    "        times,\n",
    "        outputs[:, idx],\n",
    "        ls=\"-\",\n",
    "        lw=0.5,\n",
    "        marker=\".\",\n",
    "        ms=3,\n",
    "    )\n",
    "    print(target, sum(mask))\n",
    "    ax.legend([target, target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plot(axes, task, batch):\n",
    "    # batch = slices[0]\n",
    "    times, inputs, targets, originals = (x.to(device=\"cpu\") for x in prep_batch(batch))\n",
    "    outputs = model(times, inputs)\n",
    "\n",
    "    times = times[0].detach().cpu()\n",
    "    inputs = inputs[0].detach().cpu()\n",
    "    outputs = outputs[0].detach().cpu()\n",
    "    targets = targets[0].detach().cpu()\n",
    "    originals = originals[0].detach().cpu()\n",
    "\n",
    "    times.shape, outputs.shape, inputs.shape, targets.shape, originals.shape\n",
    "    reconstructed = preprocessor.decode((times, outputs)).astype(\"float32\")\n",
    "\n",
    "    for ax, (idx, target) in zip(axes.flatten(), task.targets.items()):\n",
    "        color = next(ax._get_lines.prop_cycler)[\"color\"]\n",
    "        data = originals[:, idx]\n",
    "        mask = ~np.isnan(data)\n",
    "        ax.plot(\n",
    "            reconstructed.index[: task.observation_horizon],\n",
    "            reconstructed.iloc[: task.observation_horizon, idx],\n",
    "            ls=\":\",\n",
    "            lw=0.5,\n",
    "            color=color,\n",
    "        )\n",
    "        ax.plot(\n",
    "            reconstructed.index[task.observation_horizon :],\n",
    "            reconstructed.iloc[task.observation_horizon :, idx],\n",
    "            ls=\"-\",\n",
    "            lw=0.5,\n",
    "            color=color,\n",
    "        )\n",
    "        print(reconstructed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dloader = TRAINLOADER\n",
    "dataset = dloader.dataset[ID]\n",
    "preprocessor = deepcopy(dloader.preprocessor)\n",
    "sampler = deepcopy(dloader.sampler[ID])\n",
    "sampler.shuffle = False\n",
    "LOADER = DataLoader(dataset, sampler=sampler)\n",
    "slices = Series(LOADER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=2, ncols=2, sharex=True, figsize=(16, 8), constrained_layout=True\n",
    ")\n",
    "\n",
    "for ax, (idx, target) in zip(axes.flatten(), task.targets.items()):\n",
    "    data = ts[target]\n",
    "    times = ts.index.values\n",
    "    mask = ~np.isnan(data)\n",
    "    ax.plot(\n",
    "        times[mask],\n",
    "        data[mask],\n",
    "        ls=\"-\",\n",
    "        lw=0.5,\n",
    "        marker=\".\",\n",
    "        ms=3,\n",
    "    )\n",
    "    ax.legend([f\"{target} - observations\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batches = slices.iloc[[0, 300, 600, 900, 1200]]\n",
    "\n",
    "for batch in batches:\n",
    "    make_plot(axes, task, batch)\n",
    "\n",
    "fig.savefig(f\"{NAME.replace(r'/', r'_')}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(TRAINLOADER))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsdm.encoders import DateTimeEncoder, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = MinMaxScaler() @ DateTimeEncoder()\n",
    "enc.fit(ts.index)\n",
    "encoded = enc.encode(ts.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DateTimeEncoder().fit(ts.index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

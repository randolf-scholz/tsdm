{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc22d517-c76d-4da2-ac57-ab077be3396f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InteractiveShell.ast_node_interactivity='last_expr_or_assign'  # always print last expr.\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "880c03d7-324c-4bc8-ae50-5392d4ff4642",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# enable JIT compilation - must be done before loading torch!\n",
    "os.environ[\"PYTORCH_JIT\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20e1c36b-b316-486d-bf09-724a98b0f477",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas\n",
    "import torch\n",
    "import torchinfo\n",
    "from linodenet.models import LinODE, LinODECell, LinODEnet\n",
    "from linodenet.projections.functional import skew_symmetric, symmetric\n",
    "from pandas import DataFrame, Index, Series, Timedelta, Timestamp\n",
    "from torch import Tensor, jit, tensor\n",
    "from torch.optim import SGD, Adam, AdamW\n",
    "from torch.utils.data import BatchSampler, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "import tsdm\n",
    "from tsdm.datasets import DATASETS\n",
    "from tsdm.encoders.functional import time2float\n",
    "from tsdm.logutils import (\n",
    "    log_kernel_information,\n",
    "    log_metrics,\n",
    "    log_model_state,\n",
    "    log_optimizer_state,\n",
    ")\n",
    "from tsdm.losses import LOSSES\n",
    "from tsdm.tasks import KIWI_RUNS_TASK\n",
    "from tsdm.util import grad_norm, multi_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75c73e6-8f71-4570-ae16-0f01889052b3",
   "metadata": {},
   "source": [
    "# Initialize Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10ccb53e-8b33-45be-902f-575f1ed5afc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\")\n",
    "DTYPE = torch.float32\n",
    "NAN = tensor(float(\"nan\"), dtype=DTYPE, device=DEVICE)\n",
    "BATCH_SIZE = 128\n",
    "PRD_HORIZON = 30\n",
    "OBS_HORIZON = 90\n",
    "HORIZON = SEQLEN = OBS_HORIZON + PRD_HORIZON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0cfe050-72d6-46c0-b062-e1dbf7ebc93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK = KIWI_RUNS_TASK(\n",
    "    forecasting_horizon=PRD_HORIZON,\n",
    "    observation_horizon=OBS_HORIZON,\n",
    "    train_batch_size=BATCH_SIZE,\n",
    "    eval_batch_size=1024,\n",
    ")\n",
    "\n",
    "DATASET = TASK.dataset\n",
    "ts = TASK.timeseries\n",
    "md = TASK.metadata\n",
    "NUM_PTS, NUM_DIM = ts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7ad313-0bca-47ae-a23d-05c1430fb739",
   "metadata": {},
   "source": [
    "## Initialize Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c89a3b59-6ef4-4b41-b53e-9b23ef5bbafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOSS = TASK.test_metric.to(device=DEVICE)\n",
    "\n",
    "TASK.loss_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfde25ec-dea8-462e-9164-45dff7fd7859",
   "metadata": {},
   "source": [
    "## Initialize DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d655187-e94f-4469-a7b9-3f4beda4d6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINLOADER = TASK.batchloader\n",
    "EVALLOADERS = Series(TASK.dataloaders, dtype=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59aa5f1e-2c85-42db-933c-fe655f6641fa",
   "metadata": {},
   "source": [
    "## Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3e09543-0692-4f23-af83-912d14a18ac7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL = LinODEnet\n",
    "model = MODEL(\n",
    "    input_size=NUM_DIM,\n",
    "    hidden_size=128,\n",
    "    embedding_type=\"concat\",\n",
    "    Encoder_cfg={\"nblocks\": 10},\n",
    "    Decoder_cfg={\"nblocks\": 10},\n",
    ")\n",
    "model.to(device=DEVICE, dtype=DTYPE)\n",
    "torchinfo.summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83e71ba-af79-4c01-a587-3785154e4036",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Initalize Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c2e1b0a-274f-411a-b414-8bc41084d12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIMIZER = AdamW\n",
    "# # defaults: lr=0.001, betas=(0.9, 0.999), eps=1e-08\n",
    "# optimizer = OPTIMIZER(model.parameters(), lr=0.01, betas=(0.9, 0.999))\n",
    "\n",
    "\n",
    "OPTIMIZER = SGD\n",
    "# defaults: lr=0.001, betas=(0.9, 0.999), eps=1e-08\n",
    "optimizer = OPTIMIZER(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3e8ab3-a104-4492-b68a-d7f67e739921",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2de2a66d-5536-40d9-a209-11ba8d133a99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch = next(iter(TRAINLOADER[0]))\n",
    "T, X = batch\n",
    "targets = X[..., OBS_HORIZON:, TASK.targets.index].clone()\n",
    "# assert targets.shape == (BATCH_SIZE, PRD_HORIZON, len(TASK.targets))\n",
    "\n",
    "inputs = X.clone()\n",
    "inputs[:, OBS_HORIZON:, TASK.targets.index] = NAN\n",
    "inputs[:, OBS_HORIZON:, TASK.observables.index] = NAN\n",
    "# assert inputs.shape == (BATCH_SIZE, HORIZON, NUM_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88ea547d-d10e-420e-8f93-5a32069d99fd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "targets = X[..., OBS_HORIZON:, TASK.targets.index].clone()\n",
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20388705-69a4-4765-bde4-d27527def516",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_batch(batch: tuple[Tensor, Tensor]):\n",
    "    \"\"\"Get batch and create model inputs and targets\"\"\"\n",
    "    T, X = batch\n",
    "    targets = X[..., OBS_HORIZON:, TASK.targets.index].clone()\n",
    "    # assert targets.shape == (BATCH_SIZE, PRD_HORIZON, len(TASK.targets))\n",
    "\n",
    "    inputs = X.clone()\n",
    "    inputs[:, OBS_HORIZON:, TASK.targets.index] = NAN\n",
    "    inputs[:, OBS_HORIZON:, TASK.observables.index] = NAN\n",
    "    # assert inputs.shape == (BATCH_SIZE, HORIZON, NUM_DIM)\n",
    "    return T, inputs, targets\n",
    "\n",
    "\n",
    "def get_all_preds(model, dataloader):\n",
    "    Y, Ŷ = [], []\n",
    "    for batch in (pbar := tqdm(dataloader, leave=False)):\n",
    "        with torch.no_grad():\n",
    "            model.zero_grad()\n",
    "            times, inputs, targets = prep_batch(batch)\n",
    "            outputs = model(times, inputs)\n",
    "            predics = outputs[:, OBS_HORIZON:, TASK.targets.index]\n",
    "            loss = LOSS(targets, predics)\n",
    "            Y.append(targets)\n",
    "            Ŷ.append(predics)\n",
    "        if pbar.n == 5:\n",
    "            break\n",
    "\n",
    "    targets, predics = torch.cat(Y, dim=0), torch.cat(Ŷ, dim=0)\n",
    "    mask = torch.isnan(targets)\n",
    "    targets[mask] = torch.tensor(0.0)\n",
    "    predics[mask] = torch.tensor(0.0)\n",
    "    # scale = 1/torch.mean(mask.to(dtype=torch.float32))\n",
    "    # targets *= scale\n",
    "    # predics *= scale\n",
    "    return targets, predics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5892b9-c3ad-4b3b-992e-e082b600227c",
   "metadata": {},
   "source": [
    "## Logging Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2919d5f-1d1f-4147-aacf-3e50d09230ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_all(i, model, writer, optimizer):\n",
    "    kernel = model.system.kernel.clone().detach().cpu()\n",
    "    log_kernel_information(i, writer, kernel, histograms=True)\n",
    "    log_optimizer_state(i, writer, optimizer, histograms=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee6298fa-fd88-4191-9864-2cc58f73f78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# warmup - set all gradients to none\n",
    "y, yhat = model(torch.randn(NUM_DIM).cuda(), torch.randn(1, NUM_DIM).cuda())\n",
    "torch.linalg.norm(y).backward()\n",
    "model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d718219-e9f8-469b-827b-468c9dca0db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_START = tsdm.util.now()\n",
    "CHECKPOINTDIR = Path(f\"checkpoints/{RUN_START}/\")\n",
    "CHECKPOINTDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "writer = SummaryWriter(f\"runs/{MODEL.__name__}/{DATASET.__name__}{RUN_START}\")\n",
    "metrics = {key: LOSSES[key] for key in (\"ND\", \"NRMSE\", \"MSE\", \"MAE\")}\n",
    "# assert any(isinstance(TASK.test_metric, metric) for metric in metrics.values())\n",
    "metrics = {key: LOSSES[key]() for key in (\"ND\", \"NRMSE\", \"MSE\", \"MAE\")} | {\n",
    "    \"WRMSE\": LOSS\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62361bf2-16b2-46b0-bc69-71bee7045422",
   "metadata": {},
   "source": [
    "### Training Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e9b5c3-8da4-4e5b-b4a5-f0dfac9ff450",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = -1\n",
    "\n",
    "for epoch in (epochs := trange(10)):\n",
    "    # log\n",
    "    with torch.no_grad():\n",
    "        # log optimizer state first !!!\n",
    "        # log_optimizer_state(epoch, writer, optimizer, histograms=True)\n",
    "        log_kernel_information(epoch, writer, model.system.kernel, histograms=True)\n",
    "\n",
    "        for name, dataloader in EVALLOADERS[0].items():\n",
    "            y, ŷ = get_all_preds(model, dataloader)\n",
    "            log_metrics(\n",
    "                epoch, writer, metrics=metrics, targets=y, predics=ŷ, prefix=name\n",
    "            )\n",
    "\n",
    "    for batch in (batches := tqdm(TRAINLOADER[0])):\n",
    "        i += 1\n",
    "        # Optimization step\n",
    "        model.zero_grad()\n",
    "        times, inputs, targets = prep_batch(batch)\n",
    "\n",
    "        forward_time = time()\n",
    "        outputs = model(times, inputs)\n",
    "        forward_time = time() - forward_time\n",
    "\n",
    "        predics = outputs[:, OBS_HORIZON:, TASK.targets.index]\n",
    "\n",
    "        # get rid of nan-values in teh targets.\n",
    "        mask = torch.isnan(targets)\n",
    "        targets[mask] = torch.tensor(0.0)\n",
    "        predics[mask] = torch.tensor(0.0)\n",
    "\n",
    "        # # compensate NaN-Value with upscaling\n",
    "        # scale = 1/torch.mean(mask.to(dtype=torch.float32))\n",
    "        # targets *= scale\n",
    "        # predics *= scale\n",
    "\n",
    "        loss = LOSS(targets, predics)\n",
    "\n",
    "        backward_time = time()\n",
    "        loss.backward()\n",
    "        backward_time = time() - backward_time\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        # batch logging\n",
    "        logging_time = time()\n",
    "        with torch.no_grad():\n",
    "            i += 1\n",
    "            log_metrics(\n",
    "                i,\n",
    "                writer,\n",
    "                metrics=metrics,\n",
    "                targets=targets,\n",
    "                predics=predics,\n",
    "                prefix=\"batch\",\n",
    "            )\n",
    "            log_optimizer_state(i, writer, optimizer, prefix=\"batch\")\n",
    "\n",
    "            lval = loss.clone().detach().cpu().numpy()\n",
    "            gval = grad_norm(list(model.parameters())).clone().detach().cpu().numpy()\n",
    "            if torch.any(torch.isnan(loss)):\n",
    "                raise RuntimeError(\"NaN-value encountered!!\")\n",
    "        logging_time = time() - logging_time\n",
    "\n",
    "        batches.set_postfix(\n",
    "            loss=f\"{lval:.2e}\",\n",
    "            gnorm=f\"{gval:.2e}\",\n",
    "            Δt_forward=f\"{forward_time:.1f}\",\n",
    "            Δt_backward=f\"{backward_time:.1f}\",\n",
    "            Δt_logging=f\"{logging_time:.1f}\",\n",
    "        )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # log optimizer state first !!!\n",
    "        log_optimizer_state(epoch, writer, optimizer, histograms=True)\n",
    "        log_kernel_information(epoch, writer, model.system.kernel, histograms=True)\n",
    "\n",
    "        for name, dataloader in EVALLOADERS[0].items():\n",
    "            y, ŷ = get_all_preds(model, dataloader)\n",
    "            log_metrics(\n",
    "                epoch, writer, metrics=metrics, targets=y, predics=ŷ, prefix=name\n",
    "            )\n",
    "\n",
    "        # Model Checkpoint\n",
    "        torch.jit.save(model, CHECKPOINTDIR.joinpath(f\"{MODEL.__name__}-{epochs.n}\"))\n",
    "        torch.save(\n",
    "            {\n",
    "                \"optimizer\": optimizer,\n",
    "                \"epoch\": epoch,\n",
    "                \"batch\": i,\n",
    "            },\n",
    "            CHECKPOINTDIR.joinpath(f\"{OPTIMIZER.__name__}-{epochs.n}\"),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d7ec35-37d7-4c66-85b2-165f8a34868b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

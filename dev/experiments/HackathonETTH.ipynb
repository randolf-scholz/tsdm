{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc22d517-c76d-4da2-ac57-ab077be3396f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InteractiveShell.ast_node_interactivity='last_expr_or_assign'  # always print last expr.\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "880c03d7-324c-4bc8-ae50-5392d4ff4642",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# enable JIT compilation - must be done before loading torch!\n",
    "os.environ[\"PYTORCH_JIT\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20e1c36b-b316-486d-bf09-724a98b0f477",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tsdm\n",
    "import torch\n",
    "import pandas\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm.auto import trange, tqdm\n",
    "from torch import tensor, Tensor, jit\n",
    "from torch.utils.data import BatchSampler, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from tsdm.losses import LOSSES\n",
    "from tsdm.util import grad_norm, multi_norm\n",
    "from tsdm.datasets import Electricity\n",
    "from tsdm.encoders import time2float\n",
    "\n",
    "from linodenet.models import LinODEnet, LinODECell, LinODE\n",
    "from linodenet.projections import symmetric, skew_symmetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10ccb53e-8b33-45be-902f-575f1ed5afc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\")\n",
    "DTYPE = torch.float32\n",
    "NAN = tensor(float(\"nan\"), dtype=DTYPE, device=DEVICE)\n",
    "BATCH_SIZE = 16\n",
    "PRD_HORIZON = 24\n",
    "OBS_HORIZON = 96\n",
    "SEQLEN = PRD_HORIZON + OBS_HORIZON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32106a95-81de-4df2-872a-4fd60272c2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsdm.tasks import ETDatasetInformer\n",
    "\n",
    "TASK = ETDatasetInformer(\n",
    "    dataset=\"ETTh1\",\n",
    "    forecasting_horizon=24,\n",
    "    observation_horizon=96,\n",
    "    test_metric=\"MSE\",\n",
    "    time_encoder=\"time2float\",\n",
    ")\n",
    "DATASET = TASK.dataset\n",
    "\n",
    "NUM_PTS, NUM_DIM = DATASET.dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3e8ab3-a104-4492-b68a-d7f67e739921",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20388705-69a4-4765-bde4-d27527def516",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit.script\n",
    "def prep_batch(batch: tuple[Tensor, Tensor, Tensor], observation_horizon: int):\n",
    "    T, X, Y = batch\n",
    "    targets = Y[..., observation_horizon:].clone()\n",
    "    Y[..., observation_horizon:] = float(\"nan\")     # mask future\n",
    "    X[..., observation_horizon:, :] = float(\"nan\")  # mask future\n",
    "    inputs = torch.cat([X, Y.unsqueeze(-1)], dim=-1)\n",
    "    return T, inputs, targets\n",
    "\n",
    "\n",
    "\n",
    "def get_all_preds(model, dataloader):\n",
    "    Y, Ŷ = [], []\n",
    "    for batch in tqdm(dataloader, leave=False):\n",
    "        with torch.no_grad():\n",
    "            model.zero_grad()\n",
    "            times, inputs, targets = prep_batch(batch, OBS_HORIZON)\n",
    "            outputs, _ = model(times, inputs)\n",
    "            predics = outputs[:, OBS_HORIZON:, -1]\n",
    "            loss = LOSS(predics, targets)\n",
    "            Y.append(targets)\n",
    "            Ŷ.append(predics)  \n",
    "\n",
    "    return torch.cat(Y, dim=0), torch.cat(Ŷ, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5892b9-c3ad-4b3b-992e-e082b600227c",
   "metadata": {},
   "source": [
    "# logging utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2919d5f-1d1f-4147-aacf-3e50d09230ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_all(i, model, writer, optimizer):\n",
    "    kernel = model.system.kernel.clone().detach().cpu()\n",
    "    log_kernel_information(i, writer, kernel, histograms=True)\n",
    "    log_optimizer_state(i, writer, optimizer, histograms=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfe5c80-2903-4964-a647-ca2dd343f959",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Plotting Kernel Utility Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c3db39e-34df-40e3-a7fb-0769b7f135a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from linodenet.models import LinODEnet\n",
    "from tsdm.util.logging import log_optimizer_state, log_kernel_information, log_model_state, log_metrics\n",
    "\n",
    "MODEL = LinODEnet\n",
    "model = MODEL(input_size=NUM_DIM, hidden_size=32, embedding_type=\"concat\")\n",
    "model.to(device=DEVICE, dtype=DTYPE)\n",
    "LOSS = TASK.test_metric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f560c2e-7842-4a42-905f-0abf73af7ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(), lr=0.0001)\n",
    "TRAINLOADER = TASK.get_dataloader(\"train\", batch_size=64)\n",
    "VALIDLOADER = TASK.get_dataloader(\"train\", batch_size=1024, shuffle=False)\n",
    "TRIALLOADER = TASK.get_dataloader(\"test\",  batch_size=1024, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee6298fa-fd88-4191-9864-2cc58f73f78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# warmup - set all gradients to none\n",
    "y, yhat = model(torch.randn(NUM_DIM).cuda(), torch.randn(1, NUM_DIM).cuda())\n",
    "torch.linalg.norm(y).backward()\n",
    "model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d718219-e9f8-469b-827b-468c9dca0db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_START = tsdm.util.now()\n",
    "CHECKPOINTDIR = Path(f\"model_checkpoints/{RUN_START}/\")\n",
    "CHECKPOINTDIR.mkdir(parents=True, exist_ok=True)\n",
    "writer = SummaryWriter(f\"runs/{MODEL.__name__}/{DATASET.__name__}{RUN_START}\")\n",
    "metrics = {key:LOSSES[key] for key in (\"ND\", \"NRMSE\", \"MSE\", \"MAE\")}\n",
    "assert TASK.test_metric in metrics.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e9b5c3-8da4-4e5b-b4a5-f0dfac9ff450",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    i = -1\n",
    "    y_train, ŷ_train = get_all_preds(model, VALIDLOADER)\n",
    "    y_trial, ŷ_trial = get_all_preds(model, TRIALLOADER)\n",
    "    log_metrics(i, writer, y_train, ŷ_train, metrics, prefix=\"train\")\n",
    "    log_metrics(i, writer, y_trial, ŷ_trial, metrics, prefix=\"test\")\n",
    "    log_kernel_information(i, writer, model.system.kernel, histograms=True)\n",
    "\n",
    "for epoch in (epochs := trange(100)):\n",
    "    for batch in (batches := tqdm(TRAINLOADER)):\n",
    "        # Optimization step\n",
    "        model.zero_grad()\n",
    "        times, inputs, targets = prep_batch(batch, OBS_HORIZON)\n",
    "        outputs, _ = model(times, inputs)\n",
    "        predics = outputs[:, OBS_HORIZON:, -1]\n",
    "        loss = LOSS(predics, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        # batch logging\n",
    "        with torch.no_grad():\n",
    "            i += 1\n",
    "            log_metrics(i, writer, targets, predics, metrics, prefix=\"batch\")\n",
    "            log_optimizer_state(i, writer, optimizer, prefix=\"batch\")\n",
    "\n",
    "            lval = loss.clone().detach().cpu().numpy()\n",
    "            gval = grad_norm(list(model.parameters())).clone().detach().cpu().numpy()\n",
    "            batches.set_postfix(loss=lval, gnorm=gval)\n",
    "\n",
    "            if torch.any(torch.isnan(loss)):\n",
    "                raise RuntimeError(\"NaN-value encountered!!\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # log optimizer state first !!!\n",
    "        log_optimizer_state(epoch, writer, optimizer, histograms=True)\n",
    "        log_kernel_information(epoch, writer, model.system.kernel, histograms=True)\n",
    "\n",
    "        # This computation will make all gradients zero. Why?\n",
    "        y_trial, ŷ_trial = get_all_preds(model, TRIALLOADER)\n",
    "        y_train, ŷ_train = get_all_preds(model, VALIDLOADER)\n",
    "        log_metrics(epoch, writer, y_train, ŷ_train, metrics, prefix=\"train\")\n",
    "        log_metrics(epoch, writer, y_trial, ŷ_trial, metrics, prefix=\"test\")\n",
    "\n",
    "        # Model Checkpoint\n",
    "        torch.jit.save(model, CHECKPOINTDIR.joinpath(f\"{MODEL.__name__}-{epochs.n}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ef77c7-b52d-4fe0-83ff-da669536b49c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc22d517-c76d-4da2-ac57-ab077be3396f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InteractiveShell.ast_node_interactivity='last_expr_or_assign'  # always print last expr.\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880c03d7-324c-4bc8-ae50-5392d4ff4642",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# enable JIT compilation - must be done before loading torch!\n",
    "os.environ[\"PYTORCH_JIT\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e1c36b-b316-486d-bf09-724a98b0f477",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tsdm\n",
    "import torch\n",
    "import pandas\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm.auto import trange, tqdm\n",
    "from torch import tensor, Tensor, jit\n",
    "from torch.utils.data import BatchSampler, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from tsdm.losses import LOSSES\n",
    "from tsdm.util import grad_norm, multi_norm\n",
    "from tsdm.datasets import Electricity\n",
    "from tsdm.encoders import time2float\n",
    "\n",
    "from linodenet.models import LinODEnet, LinODECell, LinODE\n",
    "from linodenet.projections import symmetric, skew_symmetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ccb53e-8b33-45be-902f-575f1ed5afc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\")\n",
    "DTYPE = torch.float32\n",
    "NAN = tensor(float(\"nan\"), dtype=DTYPE, device=DEVICE)\n",
    "BATCH_SIZE = 16\n",
    "PRD_HORIZON = 24\n",
    "OBS_HORIZON = 96\n",
    "SEQLEN = PRD_HORIZON + OBS_HORIZON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32106a95-81de-4df2-872a-4fd60272c2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsdm.tasks import ETDatasetInformer\n",
    "\n",
    "TASK = ETDatasetInformer(\n",
    "    dataset=\"ETTh1\",\n",
    "    forecasting_horizon=24,\n",
    "    observation_horizon=96,\n",
    "    test_metric=\"MSE\",\n",
    "    time_encoder=\"time2float\",\n",
    ")\n",
    "DATASET = TASK.dataset\n",
    "\n",
    "NUM_PTS, NUM_DIM = DATASET.dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3e8ab3-a104-4492-b68a-d7f67e739921",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20388705-69a4-4765-bde4-d27527def516",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit.script\n",
    "def prep_batch(batch: tuple[Tensor, Tensor, Tensor], observation_horizon: int):\n",
    "    T, X, Y = batch\n",
    "    targets = Y[..., observation_horizon:].clone()\n",
    "    Y[..., observation_horizon:] = float(\"nan\")  # mask future\n",
    "    X[..., observation_horizon:, :] = float(\"nan\")  # mask future\n",
    "    inputs = torch.cat([X, Y.unsqueeze(-1)], dim=-1)\n",
    "    return T, inputs, targets\n",
    "\n",
    "\n",
    "def get_all_preds(model, dataloader):\n",
    "    Y, Ŷ = [], []\n",
    "    for batch in tqdm(dataloader, leave=False):\n",
    "        with torch.no_grad():\n",
    "            model.zero_grad()\n",
    "            times, inputs, targets = prep_batch(batch, OBS_HORIZON)\n",
    "            outputs, _ = model(times, inputs)\n",
    "            predics = outputs[:, OBS_HORIZON:, -1]\n",
    "            loss = LOSS(predics, targets)\n",
    "            Y.append(targets)\n",
    "            Ŷ.append(predics)\n",
    "\n",
    "    return torch.cat(Y, dim=0), torch.cat(Ŷ, dim=0)\n",
    "\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    numpy.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5892b9-c3ad-4b3b-992e-e082b600227c",
   "metadata": {},
   "source": [
    "# logging utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e6648e-4d69-426b-9fdc-3bdb1aaa0231",
   "metadata": {},
   "source": [
    "def log_all(i, model, writer, optimizer):\n",
    "    kernel = model.system.kernel.clone().detach().cpu()\n",
    "    log_kernel_information(i, writer, kernel, histograms=True)\n",
    "    log_optimizer_state(i, writer, optimizer, histograms=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfe5c80-2903-4964-a647-ca2dd343f959",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Plotting Kernel Utility Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f05d5d-b98c-48dc-a0dd-328ccd11e9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Logger:\n",
    "    writer: int = field(init=False)\n",
    "    model: int\n",
    "    task: int\n",
    "    optimizer: int = 3\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bca9f1-7ea8-422f-8074-ad31860d139f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Logger(1, 2, 4).writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3db39e-34df-40e3-a7fb-0769b7f135a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from linodenet.models import LinODEnet\n",
    "from tsdm.util.logging import (\n",
    "    log_optimizer_state,\n",
    "    log_kernel_information,\n",
    "    log_model_state,\n",
    "    log_metrics,\n",
    "    compute_metrics,\n",
    ")\n",
    "\n",
    "MODEL = LinODEnet\n",
    "model = MODEL(input_size=NUM_DIM, hidden_size=32, embedding_type=\"concat\")\n",
    "model.to(device=DEVICE, dtype=DTYPE)\n",
    "LOSS = TASK.test_metric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1502fdb0-54ff-439c-a870-0b37eab04409",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = torch.seed() % 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b8dfe2-30e4-4db5-be89-ec3512d2e75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = (\"a\", \"b\", \"c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4006c848-d726-405e-b5ce-35ea22f4863e",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(Literal[l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fafd2b5-eee4-4444-bb10-eaad3df25475",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATOR = torch.Generator()\n",
    "GENERATOR.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36de222-f6d6-4481-bf43-f4b207a34330",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(), lr=0.0001)\n",
    "# dataloader for training\n",
    "TRAINLOADER = TASK.get_dataloader(\"train\", batch_size=64, generator=GENERATOR)\n",
    "# dataloaders for evaluation\n",
    "eval_loaders = {\n",
    "    split: TASK.get_dataloader(split, batch_size=1024, shuffle=False)\n",
    "    for split in (\"train\", \"valid\", \"test\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6298fa-fd88-4191-9864-2cc58f73f78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# warmup - set all gradients to none\n",
    "y, yhat = model(torch.randn(NUM_DIM).cuda(), torch.randn(1, NUM_DIM).cuda())\n",
    "torch.linalg.norm(y).backward()\n",
    "model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d718219-e9f8-469b-827b-468c9dca0db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_START = tsdm.util.now()\n",
    "CHECKPOINTDIR = Path(f\"checkpoints/{RUN_START}/\")\n",
    "CHECKPOINTDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "writer = SummaryWriter(f\"runs/{MODEL.__name__}/{DATASET.__name__}{RUN_START}\")\n",
    "metrics = {key: LOSSES[key] for key in (\"ND\", \"NRMSE\", \"MSE\", \"MAE\")}\n",
    "assert TASK.test_metric in metrics.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed71805-d6dd-43db-b998-14ff5bdedeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Logger:\n",
    "    writer: SummaryWriter\n",
    "    model: Model\n",
    "    optimizer: Optimizer\n",
    "    dataloaders: dict[str, DataLoader]\n",
    "    metrics: dict[key, type[Loss]]\n",
    "    epoch: Optional[int] = None\n",
    "    batch: Optional[int] = None\n",
    "    history: Optional[dict[str, DataFrame]] = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.KEYS = list(dataloaders)\n",
    "        self.batch = 0 if batch is None else batch\n",
    "        self.epoch = 0 if batch is None else batch\n",
    "\n",
    "        if self.history is None:\n",
    "            self.history[\"batch\"] = DataFrame(columns=metrics)\n",
    "            for key in self.KEYS:       \n",
    "                self.history[key] = DataFrame(columns=metrics)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def log_at_batch_end(self, *, targets: Tensor, predics: Tensor):\n",
    "        self.batch += 1\n",
    "        hist = compute_metrics(targets=targets, predics=predics, metrics=self.metrics)\n",
    "        log_metrics(self.batch, self.writer, hist, prefix=\"batch\")\n",
    "        log_optimizer_state(self.batch, self.writer, self.optimizer, prefix=\"batch\")\n",
    "        self.history[\"batch\"].append(self._to_cpu(hist))\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def log_at_epoch_end(self, *, targets: Tensor, predics: Tensor):\n",
    "        self.epoch += 1 \n",
    "        \n",
    "        log_optimizer_state(epoch, writer, optimizer, histograms=True)\n",
    "        log_kernel_information(epoch, writer, model.system.kernel, histograms=True)\n",
    "\n",
    "        for key, dataloader in eval_loaders.items():\n",
    "            y, ŷ = get_all_preds(model, dataloader)\n",
    "            hist = compute_metrics(targets=y, predics=ŷ, metrics=self.metrics)\n",
    "            log_metrics(self.epoch, self.writer, hist, prefix=key)\n",
    "            self.history[key].append(self._to_cpu(hist))\n",
    "    \n",
    "    @staticmethod\n",
    "    def _to_cpu(scalar_dict: dict[str, Tensor])- > dict[str, float]:\n",
    "        return {key:scalar.item() for key, scalar in scalar_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c029e96d-97a8-4c6c-8aed-4e278a7bd9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(batch_hist[\"ND\"].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c4bd73-b030-492e-937c-5495ed2f5298",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2b5c2e-5653-4ac2-9c68-939f824c8297",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b688b6-9b37-4327-99da-8ad4c1f1c550",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.DataFrame(columns=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f5f53a-3836-4d27-ad3e-083978c66684",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.append({k: v.item() for k, v in batch_hist.items()}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305e9d88-06e6-4bd6-8419-abc82f4c4bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.DataFrame.from_dict(\n",
    "    {k: v.cpu() for k, v in batch_hist.items()}, orient=\"columns\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e9b5c3-8da4-4e5b-b4a5-f0dfac9ff450",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     # log optimizer state first !!!\n",
    "#     log_optimizer_state(epoch, writer, optimizer, histograms=True)\n",
    "#     log_kernel_information(epoch, writer, model.system.kernel, histograms=True)\n",
    "\n",
    "#     for name, dataloader in eval_loaders.items():\n",
    "#         y, ŷ = get_all_preds(model, dataloader)\n",
    "#         hist = compute_metrics(targets=y, predics=ŷ, metrics=metrics)\n",
    "#         log_metrics(i, writer, hist, prefix=name)\n",
    "\n",
    "#     # Model Checkpoint\n",
    "#     torch.jit.save(model, CHECKPOINTDIR.joinpath(f\"{MODEL.__name__}-{epochs.n}\"))\n",
    "#     torch.save(\n",
    "#         {\n",
    "#             \"trainloader\" : TRAINLOADER,\n",
    "#             \"optimizer\": optimizer,\n",
    "#             \"epoch\": epoch,\n",
    "#             \"batch\": batch,\n",
    "#         }\n",
    "#     )\n",
    "\n",
    "\n",
    "for epoch in (epochs := trange(100)):\n",
    "    for batch in (batches := tqdm(TRAINLOADER)):\n",
    "        # Optimization step\n",
    "        model.zero_grad()\n",
    "        times, inputs, targets = prep_batch(batch, OBS_HORIZON)\n",
    "        outputs, _ = model(times, inputs)\n",
    "        predics = outputs[:, OBS_HORIZON:, -1]\n",
    "        loss = LOSS(predics, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # batch logging\n",
    "        with torch.no_grad():\n",
    "            i += 1\n",
    "            batch_hist = compute_metrics(\n",
    "                targets=targets, predics=predics, metrics=metrics\n",
    "            )\n",
    "            log_metrics(epoch, writer, batch_hist, prefix=\"batch\")\n",
    "            log_optimizer_state(i, writer, optimizer, prefix=\"batch\")\n",
    "\n",
    "            lval = loss.clone().detach().cpu().numpy()\n",
    "            gval = grad_norm(list(model.parameters())).clone().detach().cpu().numpy()\n",
    "            batches.set_postfix(loss=lval, gnorm=gval)\n",
    "\n",
    "            if torch.any(torch.isnan(loss)):\n",
    "                raise RuntimeError(\"NaN-value encountered!!\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # log optimizer state first !!!\n",
    "        log_optimizer_state(epoch, writer, optimizer, histograms=True)\n",
    "        log_kernel_information(epoch, writer, model.system.kernel, histograms=True)\n",
    "\n",
    "        for name, dataloader in eval_loaders.items():\n",
    "            y, ŷ = get_all_preds(model, dataloader)\n",
    "            hist = compute_metrics(targets=y, predics=ŷ, metrics=metrics)\n",
    "            log_metrics(epoch, writer, hist, prefix=name)\n",
    "\n",
    "        # Model Checkpoint\n",
    "        torch.jit.save(model, CHECKPOINTDIR.joinpath(f\"{MODEL.__name__}-{epochs.n}\"))\n",
    "        torch.save(\n",
    "            {\n",
    "                \"optimizer\": optimizer,\n",
    "                \"epoch\": epoch,\n",
    "                \"batch\": batch,\n",
    "                \"generator\": GENERATOR.get_state(),\n",
    "                \"trainloader\": TRAINLOADER,\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08247a3b-fff0-4111-86f8-840ce239a160",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorboard as tb\n",
    "from tensorboard.backend.event_processing import event_accumulator\n",
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9131876-0c87-432a-9724-1a14b4d4f8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ea = EventAccumulator(\n",
    "    \"/home/rscholz/Projects/KIWI/tsdm/dev/experiments/runs/LinODEnet/ETTh12021-09-29T02:57:42/events.out.tfevents.1632877062.workstation.373922.0\",\n",
    "    size_guidance={  # see below regarding this argument\n",
    "        event_accumulator.COMPRESSED_HISTOGRAMS: 500,\n",
    "        event_accumulator.IMAGES: 4,\n",
    "        event_accumulator.AUDIO: 4,\n",
    "        event_accumulator.SCALARS: 0,\n",
    "        event_accumulator.HISTOGRAMS: 1,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51336fb-3a59-44d4-bb27-c6b10a801d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "ea.Reload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa542481-a93a-49ce-8f23-847e4da467cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator()\n",
    "torch.save(g, \"generator.torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90909633-36a5-4943-ad61-78cf1e519c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.get_rng_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92ae4d0-667a-4708-b5a5-76051f19e390",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.DataFrame(ea.Scalars(\"train:metrics/MSE\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823fef7b-fab5-4c19-970f-0b026001e6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95929e8c-0ad0-4f26-8867-a01c1bd14cc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

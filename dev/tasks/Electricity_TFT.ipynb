{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InteractiveShell.ast_node_interactivity='last_expr_or_assign'  # always print last expr.\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(precision=4, floatmode=\"fixed\", suppress=True)\n",
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"/home/rscholz/Projects/KIWI/Baselines/TemporalFusionTransformer/electricity/data/electricity/hourly_electricity.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_boundary = 1315\n",
    "test_boundary = 1339\n",
    "index = df[\"days_from_start\"]\n",
    "train = df.loc[index < valid_boundary]\n",
    "valid = df.loc[(index >= valid_boundary - 7) & (index < test_boundary)]\n",
    "test = df.loc[index >= test_boundary - 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tsdm\n",
    "\n",
    "DS = tsdm.datasets.Electricity()\n",
    "ds = DS.dataset.resample(\"1h\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds[(\"2014-01-01\" <= ds.index) & (ds.index < \"2014-09-08\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_start = pd.Timestamp(\"2014-01-01\")\n",
    "t_train = pd.Timestamp(\"2014-08-08\")\n",
    "t_valid = pd.Timestamp(\"2014-09-01\")\n",
    "t_score = pd.Timestamp(\"2014-09-08\")\n",
    "\n",
    "train_index = (\"2014-01-01\" <= ds.index) & (ds.index < \"2014-08-08\")\n",
    "valid_index = (\"2014-08-08\" <= ds.index) & (ds.index < \"2014-09-01\")\n",
    "score_index = (\"2014-09-01\" <= ds.index) & (ds.index < \"2014-09-08\")\n",
    "total_index = (\"2014-01-01\" <= ds.index) & (ds.index < \"2014-09-08\")\n",
    "joint_index = train_index | valid_index\n",
    "total_index = train_index | valid_index | score_index\n",
    "\n",
    "assert all(\n",
    "    (train_index.astype(int) + valid_index.astype(int) + score_index.astype(int))\n",
    "    == (train_index | valid_index | score_index)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need Sampler object, that samples indices\n",
    "\n",
    "t_start, t_mid, t_stop\n",
    "\n",
    "Signifying observation and forecasting horizon.\n",
    "Furthermore, we need to know the stride, i.e. how much to advance this window in time.\n",
    "\n",
    "Finally, we need to know what to do with the final slice of the data which may not accomodate a full window.\n",
    "\n",
    "- starting index\n",
    "- stopping index\n",
    "   - alternatively a dataset!\n",
    "\n",
    "- strides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Iterator, Sequence\n",
    "from typing import Any, Optional, overload\n",
    "\n",
    "from tsdm.random.samplers import BaseSampler\n",
    "\n",
    "dt = np.datetime64\n",
    "td = np.timedelta64\n",
    "\n",
    "\n",
    "class SequenceSampler(BaseSampler):\n",
    "    r\"\"\"Samples sequences of length seq_len.\"\"\"\n",
    "\n",
    "    @overload\n",
    "    def __init__(self, xmin: dt, xmax: dt, stride: td, seq_len: td) -> None: ...\n",
    "\n",
    "    @overload\n",
    "    def __init__(self, xmin: int, xmax: int, stride: int, seq_len: int) -> None: ...\n",
    "\n",
    "    @overload\n",
    "    def __init__(\n",
    "        self, xmin: float, xmax: float, stride: float, seq_len: float\n",
    "    ) -> None: ...\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_source: Optional[Sequence] = None,\n",
    "        *,\n",
    "        xmin: Optional = None,\n",
    "        xmax: Optional = None,\n",
    "        stride,\n",
    "        seq_len,\n",
    "        return_mask: bool = False,\n",
    "        shuffle: bool = False,\n",
    "    ) -> None:\n",
    "        super().__init__(data_source)\n",
    "\n",
    "        xmin = xmin if xmin is not None else data_source[0]\n",
    "        xmax = xmax if xmax is not None else data_source[-1]\n",
    "\n",
    "        self.data_source = data_source\n",
    "\n",
    "        self.xmin = xmin if not isinstance(xmin, str) else pd.Timestamp(xmin)\n",
    "        self.xmax = xmax if not isinstance(xmax, str) else pd.Timestamp(xmax)\n",
    "\n",
    "        self.stride = stride if not isinstance(stride, str) else pd.Timedelta(stride)\n",
    "        self.seq_len = (\n",
    "            seq_len if not isinstance(seq_len, str) else pd.Timedelta(seq_len)\n",
    "        )\n",
    "        # k_max = max {k∈ℕ ∣ x_min + seq_len + k⋅stride ≤ x_max}\n",
    "        self.k_max = int((xmax - xmin - seq_len) // stride)\n",
    "        self.return_mask = return_mask\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "        self.samples = np.array([\n",
    "            (\n",
    "                (x <= self.data_source) & (self.data_source < y)\n",
    "                if self.return_mask\n",
    "                else [x, y]\n",
    "            )\n",
    "            for x, y in self._iter_tuples()\n",
    "        ])\n",
    "\n",
    "    def _iter_tuples(self) -> Iterator[tuple[Any, Any]]:\n",
    "        x = self.xmin\n",
    "        y = x + self.seq_len\n",
    "        x, y = min(x, y), max(x, y)  # allows nice handling of negative seq_len\n",
    "        yield x, y\n",
    "\n",
    "        for k in range(len(self)):\n",
    "            x += self.stride\n",
    "            y += self.stride\n",
    "            yield x, y\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return int((self.xmax - self.xmin - self.seq_len) // self.stride)\n",
    "\n",
    "    def __iter__(self) -> Iterator:\n",
    "        if self.shuffle:\n",
    "            perm = np.random.permutation(len(self))\n",
    "        else:\n",
    "            perm = np.arange(len(self))\n",
    "\n",
    "        return iter(self.samples[perm])\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.__class__.__name__}[{self.stride}, {self.seq_len}]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsdm.encoders import Standardizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Standardizer()\n",
    "encoder.fit(ds[train_index])\n",
    "encoded = encoder.encode(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = SequenceSampler(\n",
    "    ds.index,\n",
    "    xmin=t_start,\n",
    "    xmax=t_valid,\n",
    "    seq_len=\"8d\",\n",
    "    stride=\"1d\",\n",
    "    return_mask=True,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "list(sampler);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "e_torch = torch.tensor(encoded.values, dtype=torch.float32)\n",
    "\n",
    "dloader = torch.utils.data.DataLoader(e_torch, sampler=sampler, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(dloader)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tsdm.tasks import BaseTask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElectricityTFT(BaseTask):\n",
    "    ...\n",
    "\n",
    "    def get_dataloader(\n",
    "        self,\n",
    "        key,\n",
    "        /,\n",
    "        shuffle: bool = False,\n",
    "        **dataloader_kwargs: Any,\n",
    "    ) -> DataLoader: ...\n",
    "\n",
    "\n",
    "ElectricityTFT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(\n",
    "    self,\n",
    "    key: KeyType,\n",
    "    /,\n",
    "    shuffle: bool = False,\n",
    "    **dataloader_kwargs: Any,\n",
    ") -> DataLoader:\n",
    "    r\"\"\"Return a dataloader for the given split.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    key: KeyType,\n",
    "    shuffle: bool, default False\n",
    "    dataloader_kwargs: Any,\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    DataLoader\n",
    "    \"\"\"\n",
    "    # Construct the dataset object\n",
    "    dataset = self.encoded_dataset\n",
    "\n",
    "    sampler = SequenceSampler(\n",
    "        dataset.index,\n",
    "        xmin=t_start,\n",
    "        xmax=t_valid,\n",
    "        seq_len=\"8d\",\n",
    "        stride=\"1d\",\n",
    "        return_mask=True,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    return DataLoader(dataset, sampler=sampler, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TFT preproc: social-time + time since start + ...\n",
    "# Crucial here: weekly & daily frequency.\n",
    "# Can't we just use time2vec with 24h / 7d freq?\n",
    "# Probably.\n",
    "\n",
    "# Need many2many FrameEncoder?\n",
    "#\n",
    "\n",
    "# o-time\n",
    "# - social time features (append)\n",
    "# o-time replace with time since start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Tasks\n",
    "\n",
    "A tutorial on how to list and download tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# License: BSD 3-Clause\n",
    "\n",
    "import openml\n",
    "import pandas as pd\n",
    "from openml.tasks import TaskType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tasks are identified by IDs and can be accessed in two different ways:\n",
    "\n",
    "1. In a list providing basic information on all tasks available on OpenML.\n",
    "   This function will not download the actual tasks, but will instead download\n",
    "   meta data that can be used to filter the tasks and retrieve a set of IDs.\n",
    "   We can filter this list, for example, we can only list tasks having a\n",
    "   special tag or only tasks for a specific target such as\n",
    "   *supervised classification*.\n",
    "2. A single task by its ID. It contains all meta information, the target\n",
    "   metric, the splits and an iterator which can be used to access the\n",
    "   splits in a useful manner.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing tasks\n",
    "\n",
    "We will start by simply listing only *supervised classification* tasks:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "tasks = openml.tasks.list_tasks(task_type=TaskType.SUPERVISED_CLASSIFICATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**openml.tasks.list_tasks()** returns a dictionary of dictionaries by default, which we convert\n",
    "into a\n",
    "`pandas dataframe <https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html>`_\n",
    "to have better visualization capabilities and easier access:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "tasks = pd.DataFrame.from_dict(tasks, orient=\"index\")\n",
    "print(tasks.columns)\n",
    "print(f\"First 5 of {len(tasks)} tasks:\")\n",
    "print(tasks.head())\n",
    "\n",
    "# As conversion to a pandas dataframe is a common task, we have added this functionality to the\n",
    "# OpenML-Python library which can be used by passing ``output_format='dataframe'``:\n",
    "tasks_df = openml.tasks.list_tasks(\n",
    "    task_type=TaskType.SUPERVISED_CLASSIFICATION, output_format=\"dataframe\"\n",
    ")\n",
    "print(tasks_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can filter the list of tasks to only contain datasets with more than\n",
    "500 samples, but less than 1000 samples:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "filtered_tasks = tasks.query(\"NumberOfInstances > 500 and NumberOfInstances < 1000\")\n",
    "print(list(filtered_tasks.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Number of tasks\n",
    "print(len(filtered_tasks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can further restrict the tasks to all have the same resampling strategy:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "filtered_tasks = filtered_tasks.query(\n",
    "    'estimation_procedure == \"10-fold Crossvalidation\"'\n",
    ")\n",
    "print(list(filtered_tasks.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Number of tasks\n",
    "print(len(filtered_tasks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resampling strategies can be found on the\n",
    "`OpenML Website <https://www.openml.org/search?type=measure&q=estimation%20procedure>`_.\n",
    "\n",
    "Similar to listing tasks by task type, we can list tasks by tags:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "tasks = openml.tasks.list_tasks(tag=\"OpenML100\", output_format=\"dataframe\")\n",
    "print(f\"First 5 of {len(tasks)} tasks:\")\n",
    "print(tasks.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, we can list tasks based on the dataset id:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "tasks = openml.tasks.list_tasks(data_id=1471, output_format=\"dataframe\")\n",
    "print(f\"First 5 of {len(tasks)} tasks:\")\n",
    "print(tasks.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, a size limit and an offset can be applied both separately and simultaneously:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "tasks = openml.tasks.list_tasks(size=10, offset=50, output_format=\"dataframe\")\n",
    "print(tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OpenML 100**\n",
    "is a curated list of 100 tasks to start using OpenML. They are all\n",
    "supervised classification tasks with more than 500 instances and less than 50000\n",
    "instances per task. To make things easier, the tasks do not contain highly\n",
    "unbalanced data and sparse data. However, the tasks include missing values and\n",
    "categorical features. You can find out more about the *OpenML 100* on\n",
    "`the OpenML benchmarking page <https://docs.openml.org/benchmark/>`_.\n",
    "\n",
    "Finally, it is also possible to list all tasks on OpenML with:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "tasks = openml.tasks.list_tasks(output_format=\"dataframe\")\n",
    "print(len(tasks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Search for the tasks on the 'eeg-eye-state' dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "tasks.query('name==\"eeg-eye-state\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading tasks\n",
    "\n",
    "We provide two functions to download tasks, one which downloads only a\n",
    "single task by its ID, and one which takes a list of IDs and downloads\n",
    "all of these tasks:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "task_id = 31\n",
    "task = openml.tasks.get_task(task_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Properties of the task are stored as member variables:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "ids = [2, 1891, 31, 9983]\n",
    "tasks = openml.tasks.get_tasks(ids)\n",
    "print(tasks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating tasks\n",
    "\n",
    "You can also create new tasks. Take the following into account:\n",
    "\n",
    "* You can only create tasks on *active* datasets\n",
    "* For now, only the following tasks are supported: classification, regression,\n",
    "  clustering, and learning curve analysis.\n",
    "* For now, tasks can only be created on a single dataset.\n",
    "* The exact same task must not already exist.\n",
    "\n",
    "Creating a task requires the following input:\n",
    "\n",
    "* task_type: The task type ID, required (see below). Required.\n",
    "* dataset_id: The dataset ID. Required.\n",
    "* target_name: The name of the attribute you aim to predict. Optional.\n",
    "* estimation_procedure_id : The ID of the estimation procedure used to create train-test\n",
    "  splits. Optional.\n",
    "* evaluation_measure: The name of the evaluation measure. Optional.\n",
    "* Any additional inputs for specific tasks\n",
    "\n",
    "It is best to leave the evaluation measure open if there is no strong prerequisite for a\n",
    "specific measure. OpenML will always compute all appropriate measures and you can filter\n",
    "or sort results on your favourite measure afterwards. Only add an evaluation measure if\n",
    "necessary (e.g. when other measure make no sense), since it will create a new task, which\n",
    "scatters results across tasks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the test server for the rest of this tutorial.\n",
    "\n",
    "<div class=\"alert alert-danger\"><h4>Warning</h4><p>.. include:: ../../test_server_usage_warning.txt</p></div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "openml.config.start_using_configuration_for_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "Let's create a classification task on a dataset. In this example we will do this on the\n",
    "Iris dataset (ID=128 (on test server)). We'll use 10-fold cross-validation (ID=1),\n",
    "and *predictive accuracy* as the predefined measure (this can also be left open).\n",
    "If a task with these parameters exists, we will get an appropriate exception.\n",
    "If such a task doesn't exist, a task will be created and the corresponding task_id\n",
    "will be returned.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    my_task = openml.tasks.create_task(\n",
    "        task_type=TaskType.SUPERVISED_CLASSIFICATION,\n",
    "        dataset_id=128,\n",
    "        target_name=\"class\",\n",
    "        evaluation_measure=\"predictive_accuracy\",\n",
    "        estimation_procedure_id=1,\n",
    "    )\n",
    "    my_task.publish()\n",
    "except openml.exceptions.OpenMLServerException as e:\n",
    "    # Error code for 'task already exists'\n",
    "    if e.code == 614:\n",
    "        # Lookup task\n",
    "        tasks = openml.tasks.list_tasks(data_id=128, output_format=\"dataframe\")\n",
    "        tasks = tasks.query(\n",
    "            'task_type == \"Supervised Classification\" '\n",
    "            'and estimation_procedure == \"10-fold Crossvalidation\" '\n",
    "            'and evaluation_measures == \"predictive_accuracy\"'\n",
    "        )\n",
    "        task_id = tasks.loc[:, \"tid\"].values[0]\n",
    "        print(\"Task already exists. Task ID is\", task_id)\n",
    "\n",
    "# reverting to prod server\n",
    "openml.config.stop_using_configuration_for_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `Complete list of task types <https://www.openml.org/search?type=task_type>`_.\n",
    "* `Complete list of model estimation procedures <https://www.openml.org/search?q=%2520measure_type%3Aestimation_procedure&type=measure>`_.\n",
    "* `Complete list of evaluation measures <https://www.openml.org/search?q=measure_type%3Aevaluation_measure&type=measure>`_.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

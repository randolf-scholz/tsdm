{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%config InteractiveShell.ast_node_interactivity='last_expr_or_assign'\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import logging\n",
    "from collections.abc import *\n",
    "from typing import NamedTuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "np.set_printoptions(precision=4, floatmode=\"fixed\", suppress=True)\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor, nan as NAN\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Sampler as TorchSampler\n",
    "\n",
    "from tsdm.datasets import KiwiDataset, TimeSeriesCollection\n",
    "from tsdm.random.samplers import HierarchicalSampler, SlidingWindowSampler\n",
    "from tsdm.tasks import TimeSeriesSampleGenerator, TimeSeriesTask\n",
    "from tsdm.tasks.base import Batch, Sample, TimeSeriesSampleGenerator, TimeSeriesTask\n",
    "from tsdm.utils.data import folds_as_frame, folds_as_sparse_frame, folds_from_groups\n",
    "from tsdm.utils.types import KeyVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class KiwiSampleGenerator(TimeSeriesSampleGenerator):\n",
    "    r\"\"\"Sample generator for the KIWI dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, dataset):\n",
    "        super().__init__(\n",
    "            dataset,\n",
    "            observables=[\n",
    "                \"Base\",\n",
    "                \"DOT\",\n",
    "                \"Glucose\",\n",
    "                \"OD600\",\n",
    "                \"Acetate\",\n",
    "                \"Fluo_GFP\",\n",
    "                \"Temperature\",\n",
    "                \"pH\",\n",
    "            ],\n",
    "            covariates=[\n",
    "                \"Cumulated_feed_volume_glucose\",\n",
    "                \"Cumulated_feed_volume_medium\",\n",
    "                \"InducerConcentration\",\n",
    "                \"StirringSpeed\",\n",
    "                \"Flow_Air\",\n",
    "                \"Probe_Volume\",\n",
    "            ],\n",
    "            targets=[\"OD600\", \"Fluo_GFP\"],\n",
    "        )\n",
    "\n",
    "\n",
    "class KiwiTask(TimeSeriesTask):\n",
    "    r\"\"\"Task for the KIWI dataset.\"\"\"\n",
    "\n",
    "    # dataset: TimeSeriesCollection = KiwiDataset()\n",
    "    observation_horizon: str = \"2h\"\n",
    "    r\"\"\"The number of datapoints observed during prediction.\"\"\"\n",
    "    forecasting_horizon: str = \"1h\"\n",
    "    r\"\"\"The number of datapoints the model should forecast.\"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        dataset = KiwiDataset()\n",
    "        dataset.timeseries = dataset.timeseries.astype(\"float64\")\n",
    "        super().__init__(dataset=dataset)\n",
    "\n",
    "    @staticmethod\n",
    "    def default_metric(*, targets, predictions):\n",
    "        r\"\"\"TODO: implement this.\"\"\"\n",
    "\n",
    "    def default_collate(self):\n",
    "        r\"\"\"TODO: implement this.\"\"\"\n",
    "\n",
    "    # def make_encoder(self, key: KeyVar, /) -> ModularEncoder:\n",
    "    #     ...\n",
    "\n",
    "    def make_sampler(self, key: KeyVar, /) -> TorchSampler:\n",
    "        split: TimeSeriesCollection = self.splits[key]\n",
    "        subsamplers = {\n",
    "            key: SlidingWindowSampler(tsd.index, horizons=[\"2h\", \"1h\"], stride=\"1h\")\n",
    "            for key, tsd in split.items()\n",
    "        }\n",
    "        return HierarchicalSampler(split, subsamplers, shuffle=False)  # type: ignore[return-value]\n",
    "\n",
    "    def make_folds(self, /) -> DataFrame:\n",
    "        r\"\"\"Group by RunID and color which indicates replicates.\"\"\"\n",
    "        md = self.dataset.metadata\n",
    "        groups = md.groupby([\"run_id\", \"color\"], sort=False).ngroup()\n",
    "        folds = folds_from_groups(\n",
    "            groups, seed=2022, num_folds=5, train=7, valid=1, test=2\n",
    "        )\n",
    "        df = folds_as_frame(folds)\n",
    "        return folds_as_sparse_frame(df)\n",
    "\n",
    "    def make_generator(self, key: KeyVar, /) -> KiwiSampleGenerator:\n",
    "        split = self.splits[key]\n",
    "        return KiwiSampleGenerator(split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "task = KiwiTask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "task.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataloader = task.dataloaders[(0, \"train\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sampler = task.samplers[(0, \"train\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generator = task.generators[(0, \"train\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "task.splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample = batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample.key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Designing Encoder for the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tsdm.encoders import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t = sample.inputs.x.index\n",
    "x = sample.inputs.x\n",
    "t_target = sample.inputs.t_target\n",
    "y = sample.targets.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "VF = task.dataset.value_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "column_encoders = {}\n",
    "\n",
    "for col, scale, lower, upper in VF[[\"scale\", \"lower\", \"upper\"]].itertuples():\n",
    "    encoder = BoundaryEncoder(lower, upper, mode=\"clip\")\n",
    "    match scale:\n",
    "        case \"percent\":\n",
    "            encoder = (\n",
    "                LogitBoxCoxEncoder()\n",
    "                @ LinearScaler(lower, upper)\n",
    "                @ BoundaryEncoder(lower, upper, mode=\"clip\")\n",
    "            )\n",
    "        case \"absolute\":\n",
    "            if upper < np.inf:\n",
    "                encoder = (\n",
    "                    BoxCoxEncoder()\n",
    "                    # @ LinearScaler(lower, upper)\n",
    "                    @ BoundaryEncoder(lower, upper, mode=\"clip\")\n",
    "                )\n",
    "            else:\n",
    "                encoder = BoxCoxEncoder() @ BoundaryEncoder(lower, upper, mode=\"clip\")\n",
    "        case \"linear\":\n",
    "            encoder = IdentityEncoder()\n",
    "        case _:\n",
    "            raise ValueError(f\"{scale=} unknown\")\n",
    "    column_encoders[col] = encoder\n",
    "column_encoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "ts = task.dataset.timeseries.copy()\n",
    "ts[\"dummy\"] = float(\"nan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=5, nrows=3, figsize=(20, 6), constrained_layout=True)\n",
    "ts.hist(ax=ax, density=True, log=True, bins=20)\n",
    "fig.savefig(\"data_original.pdf\")\n",
    "print(list(ts.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plain standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder = Standardizer()\n",
    "encoder.fit(ts)\n",
    "encoded = encoder.encode(ts)\n",
    "fig, ax = plt.subplots(ncols=5, nrows=3, figsize=(20, 6), constrained_layout=True)\n",
    "encoded.hist(ax=ax, density=True, log=True, bins=20)\n",
    "fig.savefig(\"data_encoded_standardizer.pdf\")\n",
    "print(list(encoded.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# With BoxCox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder = Standardizer() @ FrameEncoder(column_encoders)\n",
    "encoder.fit(ts)\n",
    "encoded = encoder.encode(ts)\n",
    "fig, ax = plt.subplots(ncols=5, nrows=3, figsize=(20, 6), constrained_layout=True)\n",
    "encoded.hist(ax=ax, density=True, log=True, bins=20)\n",
    "fig.savefig(\"data_encoded_box_cox.pdf\")\n",
    "print(list(encoded.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## residual error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "decoded = encoder.decode(encoded)\n",
    "assert (encoded.isna() == ts.isna()).all().all()\n",
    "(decoded - ts).abs().mean().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "enc = FrameEncoder(\n",
    "    column_encoders=column_encoders,\n",
    "    index_encoders={\n",
    "        \"run_id\": IdentityEncoder(),\n",
    "        \"experiment_id\": IdentityEncoder(),\n",
    "        \"measurement_time\": MinMaxScaler() @ TimeDeltaEncoder(),\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "enc.fit(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoded = enc.encode(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f2t = Frame2TensorDict(\n",
    "    groups={\"key\": [\"run_id\", \"experiment_id\"], \"T\": [\"measurement_time\"], \"X\": ...},\n",
    "    dtypes={\"T\": \"float32\", \"X\": \"float32\"},\n",
    "    encode_index=True,\n",
    ")\n",
    "\n",
    "f2t.fit(encoded)\n",
    "f2t.encode(encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# single_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder = (\n",
    "    Frame2TensorDict(\n",
    "        groups={\n",
    "            \"key\": [\"run_id\", \"experiment_id\"],\n",
    "            \"T\": [\"measurement_time\"],\n",
    "            \"X\": ...,\n",
    "        },\n",
    "        dtypes={\"T\": \"float32\", \"X\": \"float32\"},\n",
    "        encode_index=True,\n",
    "    )\n",
    "    @ Standardizer()\n",
    "    @ FrameEncoder(\n",
    "        column_encoders=column_encoders,\n",
    "        index_encoders={\n",
    "            # \"run_id\": IdentityEncoder(),\n",
    "            # \"experiment_id\": IdentityEncoder(),\n",
    "            \"measurement_time\": MinMaxScaler() @ TimeDeltaEncoder(),\n",
    "        },\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ts = task.dataset.timeseries\n",
    "encoder.fit(ts)\n",
    "encoded = encoder.encode(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "decoded = encoder.decode(encoded)\n",
    "MAD = (decoded - ts).abs().mean().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying to slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoded = encoder.encode(sample.inputs.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "decoded = encoder.decode(encoded)\n",
    "assert (decoded.isna() == sample.inputs.x.isna()).all().all()\n",
    "MAD = (decoded - sample.inputs.x).abs().mean().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoding Random Data Satisfies Bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rng_data = torch.randn_like(encoded[\"X\"])\n",
    "encoded[\"X\"] = 10 * rng_data  # large std. dev. to ensure that the bounds are violated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "decoded = encoder.decode(encoded)\n",
    "bounds = pd.concat([decoded.min(), decoded.max()], axis=1, keys=[\"lower\", \"upper\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collate_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## collate_fn with encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TX, X = encoder.encode(sample.inputs.x).values()\n",
    "TY, Y = encoder.encode(sample.targets.y).values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert sample.inputs.x.isna().sum().sum() == X.isnan().sum()\n",
    "assert sample.targets.y.isna().sum().sum() == Y.isnan().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now collate it!\n",
    "x_vals = []\n",
    "y_vals = []\n",
    "for sample in batch:\n",
    "    TX, X = encoder.encode(sample.inputs.x).values()\n",
    "    TY, Y = encoder.encode(sample.targets.y).values()\n",
    "    x_vals.append(X)\n",
    "    y_vals.append(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Batch(NamedTuple):\n",
    "    r\"\"\"A single sample of the data.\"\"\"\n",
    "\n",
    "    x_time: Tensor  # B×N:   the input timestamps.\n",
    "    x_vals: Tensor  # B×N×D: the input values.\n",
    "    x_mask: Tensor  # B×N×D: the input mask.\n",
    "\n",
    "    y_time: Tensor  # B×K:   the target timestamps.\n",
    "    y_vals: Tensor  # B×K×D: the target values.\n",
    "    y_mask: Tensor  # B×K×D: teh target mask.\n",
    "\n",
    "    # def __repr__(self) -> str:\n",
    "    #     return repr_namedtuple(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_vals: list[Tensor] = []\n",
    "y_vals: list[Tensor] = []\n",
    "x_time: list[Tensor] = []\n",
    "y_time: list[Tensor] = []\n",
    "x_mask: list[Tensor] = []\n",
    "y_mask: list[Tensor] = []\n",
    "\n",
    "for sample in batch:\n",
    "    tx, x = encoder.encode(sample.inputs.x).values()\n",
    "    ty, y = encoder.encode(sample.targets.y).values()\n",
    "    # create a mask for looking up the target values\n",
    "    x_time.append(tx)\n",
    "    x_vals.append(x)\n",
    "    x_mask.append(x.isfinite())\n",
    "\n",
    "    # y_time.append(t_target)\n",
    "    y_vals.append(y)\n",
    "    y_mask.append(y.isfinite())\n",
    "\n",
    "Batch(\n",
    "    x_time=pad_sequence(x_time, batch_first=True).squeeze(),\n",
    "    x_vals=pad_sequence(x_vals, batch_first=True, padding_value=NAN).squeeze(),\n",
    "    x_mask=pad_sequence(x_mask, batch_first=True).squeeze(),\n",
    "    y_time=None,\n",
    "    y_vals=pad_sequence(y_vals, batch_first=True, padding_value=NAN).squeeze(),\n",
    "    y_mask=pad_sequence(y_mask, batch_first=True).squeeze(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch: list[Sample]) -> Batch:\n",
    "    r\"\"\"Collate tensors into batch.\n",
    "\n",
    "    Transform the data slightly: t, x, t_target → T, X where X[t_target:] = NAN\n",
    "    \"\"\"\n",
    "    x_vals: list[Tensor] = []\n",
    "    y_vals: list[Tensor] = []\n",
    "    x_time: list[Tensor] = []\n",
    "    y_time: list[Tensor] = []\n",
    "    x_mask: list[Tensor] = []\n",
    "    y_mask: list[Tensor] = []\n",
    "\n",
    "    for sample in batch:\n",
    "        t = sample.inputs.x.index\n",
    "        x = sample.inputs.x.values\n",
    "        t_target = sample.inputs.t_target\n",
    "        y = sample.targets.y\n",
    "\n",
    "        # get whole time interval\n",
    "        time = torch.cat((t, t_target))\n",
    "        sorted_idx = torch.argsort(time)\n",
    "\n",
    "        # pad the x-values\n",
    "        x_padding = torch.full(\n",
    "            (t_target.shape[0], x.shape[-1]), fill_value=NAN, device=x.device\n",
    "        )\n",
    "        values = torch.cat((x, x_padding))\n",
    "\n",
    "        # create a mask for looking up the target values\n",
    "        mask_y = y.isfinite()\n",
    "        mask_pad = torch.zeros_like(x, dtype=torch.bool)\n",
    "        mask_x = torch.cat((mask_pad, mask_y))\n",
    "\n",
    "        x_vals.append(values[sorted_idx])\n",
    "        x_time.append(time[sorted_idx])\n",
    "        x_mask.append(mask_x[sorted_idx])\n",
    "\n",
    "        y_time.append(t_target)\n",
    "        y_vals.append(y)\n",
    "        y_mask.append(mask_y)\n",
    "\n",
    "    return Batch(\n",
    "        x_time=pad_sequence(x_time, batch_first=True).squeeze(),\n",
    "        x_vals=pad_sequence(x_vals, batch_first=True, padding_value=NAN).squeeze(),\n",
    "        x_mask=pad_sequence(x_mask, batch_first=True).squeeze(),\n",
    "        y_time=pad_sequence(y_time, batch_first=True).squeeze(),\n",
    "        y_vals=pad_sequence(y_vals, batch_first=True, padding_value=NAN).squeeze(),\n",
    "        y_mask=pad_sequence(y_mask, batch_first=True).squeeze(),\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InteractiveShell.ast_node_interactivity='last_expr_or_assign'  # always print last expr.\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(precision=4, floatmode=\"fixed\", suppress=True)\n",
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsdm.datasets import KIWI_RUNS\n",
    "from tsdm.tasks import KIWI_RUNS_TASK\n",
    "\n",
    "task = KIWI_RUNS_TASK()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, MultiIndex, Series, Timedelta, Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "task.dataset.timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = task.split_idx_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import cached_property\n",
    "from types import SimpleNamespace\n",
    "from typing import Any, Literal, Union\n",
    "\n",
    "from pandas import Timedelta\n",
    "\n",
    "from tsdm.tasks import BaseTask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "self = SimpleNamespace()\n",
    "\n",
    "target: Literal[\"OD600\", \"Fluo_GFP\"] = \"Fluo_GFP\"\n",
    "t_min: Union[str, Timedelta] = \"0.6h\"\n",
    "delta_t: Union[str, Timedelta] = \"5m\"\n",
    "eval_batch_size: int = 128\n",
    "train_batch_size: int = 32\n",
    "\n",
    "self.target = target\n",
    "self.delta_t = Timedelta(delta_t)\n",
    "self.t_min = Timedelta(t_min)\n",
    "self.eval_batch_size = eval_batch_size\n",
    "self.train_batch_size = train_batch_size\n",
    "\n",
    "# setup dataset\n",
    "self.dataset = KIWI_RUNS()\n",
    "self.dataset.timeseries = self.dataset.timeseries.drop([355, 482])\n",
    "self.dataset.metadata = self.dataset.metadata.drop([355, 482])\n",
    "self.units: DataFrame = self.dataset.units\n",
    "self.metadata: DataFrame = self.dataset.metadata\n",
    "self.timeseries: DataFrame = self.dataset.timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = self.dataset.timeseries\n",
    "md = self.dataset.metadata\n",
    "\n",
    "columns = [\"delta_t\", \"t_min\", \"t_induction\", \"t_final\", \"y_final\"]\n",
    "df = DataFrame(index=md.index, columns=columns)\n",
    "\n",
    "df[\"t_min\"] = self.t_min\n",
    "df[\"delta_t\"] = self.delta_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in tqdm(df.index):\n",
    "    s = df.loc[idx]\n",
    "\n",
    "    t_induction = get_induction_time(ts.loc[idx])\n",
    "    t_final = get_final_time(ts.loc[idx])\n",
    "    assert t_induction < t_final\n",
    "\n",
    "    df.loc[idx, \"t_induction\"] = t_induction\n",
    "    df.loc[idx, \"t_final\"] = t_final\n",
    "    df.loc[idx, \"y_final\"] = ts.loc[idx].loc[t_final, target]\n",
    "    # = t_final\n",
    "    # s[[\"t_prefinal\", \"t_final\"]] = get_final_time(ts.loc[idx])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The sampling\n",
    "\n",
    "for each time-series, we create a sampler that creates timeslices.\n",
    "\n",
    "\n",
    "\n",
    "### IntervalSampler\n",
    "\n",
    "Returns all intervals `[a, b]` such that\n",
    "\n",
    "- `a = tâ‚€ + iâ‹…sâ‚–`\n",
    "- `b = tâ‚€ + iâ‹…sâ‚– + Î”tâ‚–`\n",
    "- `i, k âˆˆ â„¤`\n",
    "- `a â‰¥ t_min`\n",
    "- `b â‰¤ t_max`\n",
    "- `sâ‚–` is the stride corresponding to intervals of size `Î”tâ‚–`\n",
    "- interval sizes can be provided by one of:\n",
    "   - single value -> `Î”tâ‚–` will be integer multiples of it\n",
    "   - `Sequence[type]`\n",
    "   - `Mapping[int, type]`\n",
    "   - `Callable[[int], type]`\n",
    "- stride sizes can be provided via one of:\n",
    "   - single value -> `sâ‚–` will be integer multiples of it\n",
    "   - `Sequence[type]`\n",
    "   - `Mapping[int, type]`\n",
    "   - `Callable[[int], type]`\n",
    "\n",
    "**Mandatory Inputs**\n",
    "\n",
    "- `t_min: Timestamp`\n",
    "- `t_max: Timestamp`\n",
    "\n",
    "\n",
    "**Optional: Exactly one of the following**\n",
    "- `num_slices: int`\n",
    "- `delta_t: TimeDelta` \n",
    "- `grid: Sequence[Timestamp]`\n",
    "\n",
    "**Optional Inputs**\n",
    "- `t_offset: Timestamp = t_min` The basepoint for the grid. Can also be randomly generated, if required.\n",
    "- `min_length: TimeDelta | int = 0`\n",
    "  If int, the minimum multiple of `Î”t` allowed.\n",
    "  If TimeDelta, then the lower bound for multiples of `Î”t`\n",
    "- `max_length: TimeDelta | int = t_max-t_min`\n",
    "  If int, the maximum multiple of `Î”t` allowed.\n",
    "  If TimeDelta, then the upper bound for multiples of `Î”t`\n",
    "- `shuffle: bool = True` Whether to randomly order the generated slices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import Interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = ts.loc[idx]\n",
    "t_min = s.index[100]\n",
    "t_max = s.index[200]\n",
    "t_0 = t_min\n",
    "delta_t = Timedelta(\"5m\")\n",
    "stride = Timedelta(\"5m\")\n",
    "t_0, t_min, t_max, delta_t, stride"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper function\n",
    "\n",
    "Return all integers `k` for which\n",
    "\n",
    "`t_min â‰¤ t_0 + kâ‹…Î”t â‰¤ t_max`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Callable, Mapping, Sequence, Iterator\n",
    "from itertools import count\n",
    "from typing import Optional, TypeVar\n",
    "\n",
    "TimedeltaLike = TypeVar(\"TimedeltaLike\", int, float, Timedelta)\n",
    "TimestampLike = TypeVar(\"TimestampLike\", int, float, Timestamp)\n",
    "\n",
    "\n",
    "def grid(\n",
    "    xmin: TimestampLike,\n",
    "    xmax: TimestampLike,\n",
    "    delta: TimedeltaLike,\n",
    "    xoffset: Optional[TimestampLike] = None,\n",
    ") -> list[int]:\n",
    "    \"\"\"Computes `\\{kâˆˆâ„¤âˆ£ xâ‚˜áµ¢â‚™ â‰¤ xâ‚€+kâ‹…Î” â‰¤ xâ‚˜â‚â‚“\\}`.\n",
    "\n",
    "    Special case: if Î”=0, returns [0]\n",
    "    \"\"\"\n",
    "\n",
    "    xo = xmin if xoffset is None else xoffset\n",
    "    zero = type(delta)(0)\n",
    "\n",
    "    if delta == zero:\n",
    "        return [0]\n",
    "\n",
    "    assert delta > zero, \"Assumption delta>0 violated!\"\n",
    "    assert xmin <= xoffset <= xmax, \"Assumption: xminâ‰¤xoffsetâ‰¤xmax violated!\"\n",
    "\n",
    "    a = xmin - xoffset\n",
    "    b = xmax - xoffset\n",
    "    kmax = b // delta\n",
    "    kmin = a // delta\n",
    "\n",
    "    assert xmin <= xo + kmin * delta\n",
    "    assert xmin > xo + (kmin - 1) * delta\n",
    "    assert xmax >= xo + kmax * delta\n",
    "    assert xmax < xo + (kmax + 1) * delta\n",
    "\n",
    "    return list(range(kmin, kmax + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = TypeVar(\"V\")\n",
    "\n",
    "Boxed = Union[\n",
    "    Sequence[V],\n",
    "    Mapping[int, V],\n",
    "    Callable[[int], V],\n",
    "]\n",
    "\n",
    "dt_type = Union[\n",
    "    TimedeltaLike,\n",
    "    Sequence[TimedeltaLike],\n",
    "    Mapping[int, TimedeltaLike],\n",
    "    Callable[[int], TimedeltaLike],\n",
    "]\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import Sampler\n",
    "\n",
    "class IntervalSampler(Sampler, ):\n",
    "    \"\"\"Returns all intervals `[a, b]` such that:\n",
    "\n",
    "    - `a = tâ‚€ + iâ‹…sâ‚–`\n",
    "    - `b = tâ‚€ + iâ‹…sâ‚– + Î”tâ‚–`\n",
    "    - `i, k âˆˆ â„¤`\n",
    "    - `a â‰¥ t_min`\n",
    "    - `b â‰¤ t_max`\n",
    "    - `sâ‚–` is the stride corresponding to intervals of size `Î”tâ‚–`\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_value(obj: Union[V, Boxed[V]], k: int) -> V:\n",
    "        if isinstance(obj, Callable):\n",
    "            return obj(k)\n",
    "        if isinstance(obj, Sequence):\n",
    "            return obj[k]\n",
    "        # Fallback: multiple!\n",
    "        return obj\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        xmin,\n",
    "        xmax,\n",
    "        deltax: dt_type,\n",
    "        stride: Optional[dt_type] = None,\n",
    "        levels: Optional[Sequence[int]] = None,\n",
    "        offset: Optional[dt_type] = None,\n",
    "        multiples: bool = True,\n",
    "        shuffle: bool = True,\n",
    "    ) -> None:\n",
    "\n",
    "        # set stride and offset\n",
    "        zero = 0 * (xmax - xmin)\n",
    "        stride = zero if stride is None else stride\n",
    "        offset = xmin if offset is None else offset\n",
    "\n",
    "        # validate bounds\n",
    "        assert xmin <= offset <= xmax, \"Assumption: xminâ‰¤xoffsetâ‰¤xmax violated!\"\n",
    "\n",
    "        # determine delta_max\n",
    "        delta_max = max(offset - xmin, xmax - offset)\n",
    "\n",
    "        # determine levels\n",
    "        if levels is None:\n",
    "            if isinstance(deltax, Mapping):\n",
    "                levels = [k for k in deltax.keys() if deltax[l] <= delta_max]\n",
    "            elif isinstance(deltax, Sequence):\n",
    "                levels = [k for k in range(len(deltax)) if deltax[k] <= delta_max]\n",
    "            elif isinstance(deltax, Callable):\n",
    "                levels = []\n",
    "                for k in count():\n",
    "                    dt = self._get_value(deltax, k)\n",
    "                    if dt == zero:\n",
    "                        continue\n",
    "                    if dt > delta_max:\n",
    "                        break\n",
    "                    levels.append(k)\n",
    "            else:\n",
    "                levels = [0]\n",
    "        else:\n",
    "            levels = [k for k in levels if self._get_value(deltax, k) <= delta_max]\n",
    "            \n",
    "            \n",
    "        # validate levels\n",
    "        assert all(self._get_value(deltax, k) <= delta_max for k in levels)\n",
    "\n",
    "        # compute valid intervals\n",
    "        intervals: list[Interval] = []\n",
    "\n",
    "        for k in levels:\n",
    "            dt = self._get_value(deltax, k)\n",
    "            st = self._get_value(stride, k)\n",
    "            x0 = self._get_value(offset, k)\n",
    "            stridesa = grid(xmin, xmax, st, x0)\n",
    "            stridesb = grid(xmin, xmax, st, x0 + dt)\n",
    "            valid_strides = set.intersection(set(stridesa), set(stridesb))\n",
    "            if not valid_strides:\n",
    "                break\n",
    "\n",
    "            intervals.extend(\n",
    "                [(x0 + i * st, x0 + i * st + dt, dt, st) for i in valid_strides]\n",
    "            )\n",
    "            \n",
    "        # set variables\n",
    "        \n",
    "        self.offset = offset\n",
    "        self.deltax = deltax\n",
    "        self.stride = stride\n",
    "        self.shuffle = shuffle\n",
    "        self.intervals = DataFrame(\n",
    "            intervals, columns=[\"left\", \"right\", \"delta\", \"stride\"]\n",
    "        )\n",
    "    \n",
    "    def __iter__(self) -> Iterator:\n",
    "        if self.shuffle:\n",
    "            perm = np.random.permutation(len(self))\n",
    "        else:\n",
    "            perm = np.arange(len(self))\n",
    "\n",
    "        for k in perm:\n",
    "            yield self.loc[k, \"left\"], self.loc[k, \"right\"]\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.intervals)\n",
    "\n",
    "    def __getattr__(self, key):\n",
    "        return self.intervals.__getattr__(key)\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        return self.intervals[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = IntervalSampler(\n",
    "    xmin=t_min,\n",
    "    xmax=t_max,\n",
    "    offset=t_0,\n",
    "    deltax=lambda k: k*delta_t,\n",
    "    stride=None,\n",
    ")\n",
    "\n",
    "sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = dict(enumerate([1, 2, 3, 4, 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "l.__getitem__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid(t_min, t_max, delta_t, t_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_min, t_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_0 + 11 * delta_t < t_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = t_min - t_0\n",
    "b = t_max - t_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "b // delta_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slices = []\n",
    "\n",
    "a, b = t_0 = t_0 + delta_t\n",
    "\n",
    "while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = Interval(s.index[100], s.index[200], closed=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.iloc[100:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[I.left : I.right]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_induction_time(s: Series) -> Timestamp:\n",
    "    # Compute the induction time\n",
    "    s = ts.loc[run_id, exp_id]\n",
    "    inducer = s[\"InducerConcentration\"]\n",
    "    total_induction = inducer[-1] - inducer[0]\n",
    "\n",
    "    if pd.isna(total_induction) or total_induction == 0:\n",
    "        return pd.NA\n",
    "\n",
    "    inductions = inducer[inducer.diff() != 0.0]\n",
    "    assert len(inductions) == 1, \"Multiple Inductions occur!\"\n",
    "    return inductions.first_valid_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_time(s: Series) -> Timestamp:\n",
    "    # Final and target times\n",
    "    targets = s[target]\n",
    "    mask = pd.notna(targets)\n",
    "    targets = targets[mask]\n",
    "    assert len(targets) >= 1, f\"not enough target observations {targets}\"\n",
    "    return targets.index[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KIWI_FINAL_PRODUCT(BaseTask):\n",
    "    \"\"\"Predict the final Biomass.\n",
    "\n",
    "    The goal ist to forecast the final product/biomass value only.\n",
    "    This means the problem can both be viewed as a time-series forecasting,\n",
    "    and as a time-series regression task if one ignores the final time stamp.\n",
    "\n",
    "    The evluation protocol consists of considering initial segments of the time-series `TS[tâ‰¤k*Î”t]`\n",
    "    where `k` ranges over all integers satisfying `t_{min} â‰¤ k*Î”t â‰¤ t_{max}`.\n",
    "\n",
    "    Here, `t_{min}` is a global constant (0.6h by defaut), `t_{max}` is chosen on a per-time-series basis\n",
    "\n",
    "    - If there was induction, `t_{max} = t_{induction}`.\n",
    "    - Else, `t_{max} = \\max\\{ t < t_{final}\\}`.\n",
    "\n",
    "    Thus, for each time-series one obtains a set of admissible slices\n",
    "\n",
    "    .. math::\n",
    "        J_i = \\{ kâˆˆâ„¤ âˆ£ t_{min}(TS_i) â‰¤ k*Î”t â‰¤ t_{max}(TS_i) \\}\n",
    "        S_i = \\{ TS_i[tâ‰¤k*Î”t] âˆ£ kâˆˆJ_i \\}\n",
    "\n",
    "    The target metric is averaged over these slices, and each time-series weight is normalized by the number of slices.\n",
    "\n",
    "    .. math::\n",
    "        â„’(Î¸) = ð”¼_i ð”¼_{SâˆˆS_i} â„“(Â Ì‚y(S, Î¸), y(S)Â )\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        target: Literal[\"OD600\", \"Fluo_GFP\"] = \"Fluo_GFP\",\n",
    "        t_min: Union[str, Timedelta] = \"0.6h\",\n",
    "        delta_t: Union[str, Timedelta] = \"5m\",\n",
    "        eval_batch_size: int = 128,\n",
    "        train_batch_size: int = 32,\n",
    "    ) -> None:\n",
    "        self.target = target\n",
    "        self.delta_t = Timedelta(delta_t)\n",
    "        self.t_min = Timedelta(t_min)\n",
    "        self.eval_batch_size = eval_batch_size\n",
    "        self.train_batch_size = train_batch_size\n",
    "\n",
    "        # setup dataset\n",
    "        self.dataset: Dataset = KIWI_RUNS()\n",
    "        self.units: DataFrame = self.dataset.units\n",
    "        self.metadata: DataFrame = self.dataset.metadata.drop([355, 482])\n",
    "        self.timeseries: DataFrame = self.dataset.timeseries.drop([355, 482])\n",
    "\n",
    "        # compute t_max, t_induction and t_final for each time series\n",
    "\n",
    "    @cached_property\n",
    "    def index(self) -> None:\n",
    "        ...\n",
    "\n",
    "    @cached_property\n",
    "    def split_idx(self) -> DataFrame:\n",
    "        splitter = ShuffleSplit(n_splits=5, random_state=0, test_size=0.25)\n",
    "        groups = self.metadata.groupby([\"color\", \"run_id\"])\n",
    "        group_idx = groups.ngroup()\n",
    "\n",
    "        splits = DataFrame(index=self.metadata.index)\n",
    "        for i, (train, _) in enumerate(splitter.split(groups)):\n",
    "            splits[i] = group_idx.isin(train).map({False: \"test\", True: \"train\"})\n",
    "\n",
    "        splits.columns.name = \"split\"\n",
    "        return splits.astype(\"string\").astype(\"category\")\n",
    "\n",
    "    @cached_property\n",
    "    def splits(self) -> dict[Any, tuple[DataFrame, DataFrame]]:\n",
    "        ...\n",
    "\n",
    "    def get_dataloader():\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

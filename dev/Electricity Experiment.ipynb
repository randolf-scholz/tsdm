{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc22d517-c76d-4da2-ac57-ab077be3396f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InteractiveShell.ast_node_interactivity='last_expr_or_assign'  # always print last expr.\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880c03d7-324c-4bc8-ae50-5392d4ff4642",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"PYTORCH_JIT\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e1c36b-b316-486d-bf09-724a98b0f477",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas\n",
    "import torch\n",
    "from torch import Tensor, jit, tensor\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tsdm\n",
    "from tsdm.datasets import Electricity\n",
    "from tsdm.encoders import time2float\n",
    "\n",
    "ℵ = np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb70fb9-a08b-44e4-9769-14a5baefa36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import BatchSampler\n",
    "\n",
    "from linodenet.projections import skew_symmetric, symmetric\n",
    "from tsdm.utils.samplers import SliceSampler\n",
    "\n",
    "\n",
    "def now():\n",
    "    return datetime.now().isoformat(timespec=\"seconds\")\n",
    "\n",
    "\n",
    "def plot_spectrum(kernel):\n",
    "    eigs = torch.linalg.eigvals(kernel).detach().cpu()\n",
    "    fig, ax = plt.subplots(figsize=(12, 6), tight_layout=True)\n",
    "    ax.set_xlim([-2.5, +2.5])\n",
    "    ax.set_ylim([-2.5, +2.5])\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.set_xlabel(\"real part\")\n",
    "    ax.set_ylabel(\"imag part\")\n",
    "    ax.scatter(eigs.real, eigs.imag)\n",
    "    return fig\n",
    "\n",
    "\n",
    "def symmpart(kernel):\n",
    "    return torch.mean(symmetric(kernel) ** 2) / torch.mean(kernel**2)\n",
    "\n",
    "\n",
    "def skewpart(kenerl):\n",
    "    return torch.mean(skew_symmetric(kernel) ** 2) / torch.mean(kernel**2)\n",
    "\n",
    "\n",
    "def collate_tensor(tensors: list[tensor]) -> tensor:\n",
    "    return torch.stack(tensors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062fd404-3a56-4d34-bf98-e9303f65104b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Electricity.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549e6730-f83f-4cb9-bbdf-2dc469a08ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\")\n",
    "DTYPE = torch.float32\n",
    "NAN = tensor(float(\"nan\"), dtype=DTYPE, device=DEVICE)\n",
    "DATASET = Electricity.dataset\n",
    "NPTS, NDIM = DATASET.shape\n",
    "SEQLEN = 48\n",
    "PRD_HORIZON = 24\n",
    "OBS_HORIZON = SEQLEN - PRD_HORIZON\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2c5c87-df10-47d7-b439-db00102cbd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing cf. NBEATS-paper\n",
    "# resample hourly\n",
    "ds = ds.resample(pandas.Timedelta(\"1h\"), label=\"right\").sum()\n",
    "# remove first year\n",
    "ds = ds.loc[pandas.Timestamp(\"2012-01-01\") :]\n",
    "ds_train, ds_test = ds.iloc[:-PRD_HORIZON], ds.iloc[-PRD_HORIZON:]  # 168=7*24\n",
    "t_train, t_test = time2float(ds_train.index), time2float(ds_test.index)\n",
    "t_train, t_test = t_train / t_train.max(), t_test / t_test.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c916c83-9b4d-45f1-bfbd-e46f8f840af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45510dd1-08a5-4984-a077-8a60c27b5e15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4621fa8e-e5f6-457e-b5f9-78a13a4406ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torch.cat(\n",
    "    [\n",
    "        tensor(t_train, device=DEVICE, dtype=DTYPE).unsqueeze(-1),\n",
    "        tensor(ds_train.values, device=DEVICE, dtype=DTYPE),\n",
    "    ],\n",
    "    axis=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444a16d6-beaa-4187-a334-cbc8644736cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = SliceSampler(train, slice_sampler=SEQLEN)\n",
    "sampler = BatchSampler(sampler, batch_size=BATCH_SIZE, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3db39e-34df-40e3-a7fb-0769b7f135a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "from linodenet.models import LinODEnet\n",
    "from tsdm.metrics.functional import nd, nrmse\n",
    "\n",
    "model = LinODEnet(NDIM, 512, embedding_type=\"concat\")\n",
    "model.to(device=DEVICE, dtype=DTYPE)\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "batch = collate_tensor(next(iter(sampler)))\n",
    "t, x = batch[:, :, 0], batch[:, :, 1:]\n",
    "writer = SummaryWriter(f\"runs/LinODEnet/{now()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9a3e2a-8ac5-4ef5-b5ed-d76704d80608",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# batch = collate_tensor(next(iter(sampler)))\n",
    "# t, x = batch[:, :, 0], batch[:, :, 1:]\n",
    "# writer.add_graph(model, (t, x), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23811b5-31cc-48f7-bbcf-48292f946de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit.script\n",
    "def grad_norm(tensors: list[Tensor]) -> Tensor:\n",
    "    n = len(tensors)\n",
    "    # initializing s this way instead of s=tensor(0) automatically gets the dtype and device correct\n",
    "    s = torch.sum(tensors.pop().grad ** 2)\n",
    "    for x in tensors:\n",
    "        s += torch.sum(x.grad**2)\n",
    "    return s / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985c99de-3faa-439a-8541-9c3d3247fcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit.script\n",
    "def prep(\n",
    "    batch: Tensor, OBS_HORIZON: int = OBS_HORIZON, NAN: Tensor = NAN\n",
    ") -> tuple[Tensor, Tensor, Tensor]:\n",
    "    t, x = batch[:, :, 0], batch[:, :, 1:]\n",
    "    t_obs, t_pred = t[:, :OBS_HORIZON], t[:, OBS_HORIZON:]\n",
    "    x_obs = x.detach().clone()\n",
    "    x_obs[:, OBS_HORIZON:, :] = NAN\n",
    "    return t, x, x_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bf8818-3403-467e-ab25-6f36c2790763",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit.script\n",
    "def multi_norm(\n",
    "    tensors: list[Tensor], p: float = 2, q: float = 2, normalize: bool = True\n",
    ") -> Tensor:\n",
    "    r\"\"\"Return the (scaled) p-q norm of the gradients.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tensors: list[Tensor]\n",
    "    p: float = 2.0\n",
    "    q: float = 2.0\n",
    "    normalize: bool = True\n",
    "        If true, accumulate with mean instead of sum\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tensor\n",
    "    \"\"\"\n",
    "    # TODO: implement special cases p,q = ±∞\n",
    "    if normalize:\n",
    "        # initializing s this way instead of s=tensor(0) automatically gets the dtype and device correct\n",
    "        s = torch.mean(tensors.pop() ** p) ** (q / p)\n",
    "        for x in tensors:\n",
    "            s += torch.mean(x**p) ** (q / p)\n",
    "        return (s / (1 + len(tensors))) ** (1 / q)\n",
    "    # else\n",
    "    s = torch.sum(tensors.pop() ** p) ** (q / p)\n",
    "    for x in tensors:\n",
    "        s += torch.sum(x**p) ** (q / p)\n",
    "    return s ** (1 / q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4894656-6073-4a1d-87f6-99af80ec012a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7890426e-ff39-4978-ba43-c7cf1ae091e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3bff02-61dd-4697-842d-fa573b125fbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee59c83-989e-455b-9796-9777a8798a53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9617afad-8cd1-4858-9396-7f08643f63c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in (pbar := tqdm(sampler)):\n",
    "    batch = collate_tensor(batch)\n",
    "    t, x, x_obs = prep(batch)\n",
    "    x_hat = model(t, x_obs)\n",
    "    loss = torch.mean(nd(x, x_hat))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pbar.set_postfix(loss=f\"{loss:.2e}\")\n",
    "        kernel = model.system.kernel.detach().cpu()\n",
    "\n",
    "        # Log Loss functions\n",
    "        writer.add_scalar(\"train/nd\", loss, pbar.n)\n",
    "        writer.add_scalar(\"train/nrmse\", torch.mean(nrmse(x, x_hat)), pbar.n)\n",
    "        writer.add_scalar(\"test/nd\", loss, pbar.n)\n",
    "        writer.add_scalar(\"test/nrmse\", torch.mean(nrmse(x, x_hat)), pbar.n)\n",
    "\n",
    "        # Log Optimizer State\n",
    "        variables = list(optimizer.state.keys())\n",
    "        gradients = [w.grad for w in variables]\n",
    "        moments_1 = [d[\"exp_avg\"] for d in optimizer.state.values()]\n",
    "        moments_2 = [d[\"exp_avg_sq\"] for d in optimizer.state.values()]\n",
    "\n",
    "        for i, (w, g, a, b) in enumerate(\n",
    "            zip(variables, gradients, moments_1, moments_2)\n",
    "        ):\n",
    "            writer.add_histogram(f\"optim/variables/{i}\", w, pbar.n)\n",
    "            writer.add_histogram(f\"optim/gradients/{i}\", g, pbar.n)\n",
    "            writer.add_histogram(f\"optim/moments_1/{i}\", a, pbar.n)\n",
    "            writer.add_histogram(f\"optim/moments_2/{i}\", b, pbar.n)\n",
    "\n",
    "        writer.add_scalar(\"optim/norm/variables\", multi_norm(variables), pbar.n)\n",
    "        writer.add_scalar(\"optim/norm/gradients\", multi_norm(gradients), pbar.n)\n",
    "        writer.add_scalar(\"optim/norm/moments_1\", multi_norm(moments_1), pbar.n)\n",
    "        writer.add_scalar(\"optim/norm/moments_2\", multi_norm(moments_2), pbar.n)\n",
    "\n",
    "        # Log Kernel State\n",
    "        writer.add_histogram(\"kernel/histogram\", model.system.kernel, pbar.n)\n",
    "        writer.add_image(\"kernel/values\", model.system.kernel, pbar.n, dataformats=\"HW\")\n",
    "        writer.add_figure(\"kernel/spectrum\", plot_spectrum(kernel), pbar.n)\n",
    "\n",
    "        writer.add_scalar(\"kernel/skewpart\", skewpart(kernel), pbar.n)\n",
    "        writer.add_scalar(\"kernel/symmpart\", symmpart(kernel), pbar.n)\n",
    "        writer.add_scalar(\"kernel/det\", torch.linalg.det(kernel), pbar.n)\n",
    "        writer.add_scalar(\"kernel/rank\", torch.linalg.matrix_rank(kernel), pbar.n)\n",
    "        writer.add_scalar(\"kernel/trace\", torch.trace(kernel), pbar.n)\n",
    "        writer.add_scalar(\"kernel/cond\", torch.linalg.cond(kernel), pbar.n)\n",
    "        writer.add_scalar(\"kernel/logdet\", torch.linalg.slogdet(kernel)[-1], pbar.n)\n",
    "\n",
    "        # various norms\n",
    "        writer.add_scalar(\n",
    "            \"kernel/norm/fro\", torch.linalg.matrix_norm(kernel, ord=\"fro\"), pbar.n\n",
    "        )\n",
    "        writer.add_scalar(\n",
    "            \"kernel/norm/nuc\", torch.linalg.matrix_norm(kernel, ord=\"nuc\"), pbar.n\n",
    "        )\n",
    "        writer.add_scalar(\n",
    "            \"kernel/norm/-∞\",\n",
    "            torch.linalg.matrix_norm(kernel, ord=-float(\"inf\")),\n",
    "            pbar.n,\n",
    "        )\n",
    "        writer.add_scalar(\n",
    "            \"kernel/norm/-2\", torch.linalg.matrix_norm(kernel, ord=-2), pbar.n\n",
    "        )\n",
    "        writer.add_scalar(\n",
    "            \"kernel/norm/-1\", torch.linalg.matrix_norm(kernel, ord=-1), pbar.n\n",
    "        )\n",
    "        writer.add_scalar(\n",
    "            \"kernel/norm/ 0\", torch.sum(kernel != 0) / kernel.numel(), pbar.n\n",
    "        )\n",
    "        writer.add_scalar(\n",
    "            \"kernel/norm/+1\", torch.linalg.matrix_norm(kernel, ord=+1), pbar.n\n",
    "        )\n",
    "        writer.add_scalar(\n",
    "            \"kernel/norm/+2\", torch.linalg.matrix_norm(kernel, ord=+2), pbar.n\n",
    "        )\n",
    "        writer.add_scalar(\n",
    "            \"kernel/norm/+∞\",\n",
    "            torch.linalg.matrix_norm(kernel, ord=+float(\"inf\")),\n",
    "            pbar.n,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b84d00-4e53-4b72-9491-4b635629a843",
   "metadata": {},
   "source": [
    "# plots\n",
    "\n",
    "- scatter plot spectrum\n",
    "- ratio norm(A)/norm(A+Aᵀ/2)  and  norm(A)/norm(A-Aᵀ/2) (measure symmetry/asymmetry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126f4d07-a38b-43a4-828c-a44f25ebe82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit.script\n",
    "def f(x: list[int]) -> int:\n",
    "    return sum(x)\n",
    "\n",
    "\n",
    "@jit.script\n",
    "def f(x: tuple[int, ...]) -> int:\n",
    "    return sum(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62aa4821-cc4f-4292-937b-21f51d8590bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Union\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "def scaled_norm(\n",
    "    x: torch.Tensor,\n",
    "    dim: Optional[Union[int, tuple[int, ...]]] = None,\n",
    "    p: float = 2.0,\n",
    "    keepdim: bool = False,\n",
    ") -> torch.Tensor:\n",
    "    return torch.mean(x**p, dim=dim, keepdim=keepdim) ** (1 / p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c48d83-30ec-46d9-8f07-0159e76a781d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_norm(\n",
    "    xs: tuple[torch.Tensor, ...],\n",
    "    p: float = 2.0,\n",
    ") -> torch.Tensor:\n",
    "    sum(torch.mean(x**p, keepdim=false) for x in xs) ** 1 / p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88792d91-c859-4e47-80b9-240224dfcb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Union\n",
    "\n",
    "\n",
    "@jit.script\n",
    "def _torch_scaled_norm(\n",
    "    x: Tensor,\n",
    "    axis: tuple[int, ...] == (),\n",
    "    p: float = 2,\n",
    "    keepdims: bool = False,\n",
    ") -> Tensor:\n",
    "    axis = () if axis is None else axis\n",
    "\n",
    "    #     if not _torch_is_float_dtype(x):\n",
    "    #         x = x.to(dtype=torch.float)\n",
    "    #     x = torch.abs(x)\n",
    "\n",
    "    #     if p == 0:\n",
    "    #         # https://math.stackexchange.com/q/282271/99220\n",
    "    #         return torch.exp(torch.mean(torch.log(x), dim=axis, keepdim=keepdims))\n",
    "    #     if p == 1:\n",
    "    #         return torch.mean(x, dim=axis, keepdim=keepdims)\n",
    "    #     if p == 2:\n",
    "    #         return torch.sqrt(torch.mean(x ** 2, dim=axis, keepdim=keepdims))\n",
    "    #     if p == float(\"inf\"):\n",
    "    #         return torch.amax(x, dim=axis, keepdim=keepdims)\n",
    "    #     # other p\n",
    "    return torch.mean(x**p, dim=axis, keepdim=keepdims) ** (1 / p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04356694-b5d1-487d-8353-16a1afad00f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcbada4-7bda-4a9f-84dc-0e4605b6ebe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit.script\n",
    "def summed(x: list[Tensor]) -> Tensor:\n",
    "    return torch.sum(torch.cat(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab77dbf0-8675-4041-9230-a2fe0ac7e702",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_scaled_norm([torch.randn(2, 5) for _ in range(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd19e2f-a9a6-4e2c-92f3-f47c780cd762",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.randn(1, 2, 3, 4).numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef86ba9-d1bb-4460-8dbd-2ced219e3c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit.script\n",
    "def torch_scaled_norm(\n",
    "    x: Tensor,\n",
    "    axis: list[int],\n",
    "    p: float = 2.0,\n",
    ") -> Tensor:\n",
    "    return torch.mean(x**p, dim=axis) ** (1 / p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c8e0eb-63cd-4e8c-83d5-4c8cc3ca41bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit.script\n",
    "def torch_scaled_norm(\n",
    "    x: Tensor,\n",
    "    p: float = 2,\n",
    "    #     axis: Optional[Union[int, tuple[int, ...]]] = None,\n",
    "    axis: list[int] = (),\n",
    "    keepdims: bool = False,\n",
    ") -> Tensor:\n",
    "    #     axis = () if axis is None else axis\n",
    "\n",
    "    #     if not _torch_is_float_dtype(x):\n",
    "    #         x = x.to(dtype=torch.float)\n",
    "    #     x = torch.abs(x)\n",
    "\n",
    "    #     if p == 0:\n",
    "    #         # https://math.stackexchange.com/q/282271/99220\n",
    "    #         return torch.exp(torch.mean(torch.log(x), dim=axis, keepdim=keepdims))\n",
    "    #     if p == 1:\n",
    "    #         return torch.mean(x, dim=axis, keepdim=keepdims)\n",
    "    #     if p == 2:\n",
    "    #         return torch.sqrt(torch.mean(x ** 2, dim=axis, keepdim=keepdims))\n",
    "    #     if p == float(\"inf\"):\n",
    "    #         return torch.amax(x, dim=axis, keepdim=keepdims)\n",
    "    # other p\n",
    "    return torch.mean(x**p, dim=axis, keepdim=keepdims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce09cb9e-a293-448c-9626-79522fce1719",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tsdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30b6bde-31cb-470e-889d-324330899acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsdm.utils.scaled_norm(torch.randn(2, 3, 4, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43853b59-f98b-4071-a963-e26758c939ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc3e4f4-b617-4710-b561-8a1c3d69dfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "grad_norm = sum(w.grad.detach().norm(p=2) for w in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc4816a-e63c-41d2-9c5f-276448a16cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "grad_norm = sum(torch.sum(w.grad**2) for w in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47fdd36-d760-497f-990c-b72857dabc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit.script\n",
    "def average_grad_norm(tensors: list[Tensor]) -> Tensor:\n",
    "    s = torch.tensor(0, device=torch.device(\"cuda\"), dtype=torch.float32)\n",
    "    for x in tensors:\n",
    "        s += torch.sum(x.grad**2)\n",
    "    return s / len(tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf939da-fd78-4b0f-9e74-5fa6a5b5f785",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit.script\n",
    "def m_norm(tensors: list[Tensor]) -> Tensor:\n",
    "    n = len(tensors)\n",
    "    # initializing s this way instead of s=tensor(0) automatically gets the dtype and device correct\n",
    "    s = torch.sum(tensors.pop() ** 2)\n",
    "    for x in tensors:\n",
    "        s += torch.sum(x**2)\n",
    "    return s / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559feac1-b348-4416-b487-ad90926ad290",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "m_norm([x.grad for x in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ab689a-80ac-48fe-92a4-ce6c21e1aabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit.script\n",
    "def grad_norm(tensors: list[Tensor]) -> Tensor:\n",
    "    n = len(tensors)\n",
    "    # initializing s this way instead of s=tensor(0) automatically gets the dtype and device correct\n",
    "    s = torch.sum(tensors.pop().grad ** 2)\n",
    "    for x in tensors:\n",
    "        s += torch.sum(x.grad**2)\n",
    "    return s / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295bb072-cad8-4f47-8e9e-a19181c2d376",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "average_grad_norm(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6545052c-c55a-48f3-b5db-9e27564804c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_MSE([tensor(2) for _ in range(3)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

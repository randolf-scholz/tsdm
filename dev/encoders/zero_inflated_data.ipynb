{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21fc2997-e0ab-4c2a-8977-afb8299062c8",
   "metadata": {},
   "source": [
    "# IDEA: How to transform zero-inflated variables?\n",
    "\n",
    "https://stats.stackexchange.com/questions/1444/how-should-i-transform-non-negative-data-including-zeros\n",
    "\n",
    "Given a random variable $x$ supported on $[0,∞)$ such that zero values occur potentially often.\n",
    "\n",
    "Transform $x⟼\\log(x+c)$, with $c>0$, ([Box-Cox-Transformation\n",
    "](https://de.wikipedia.org/wiki/Box-Cox-Transformation)) idea. How to choose $c$? Many suggestions have been made:\n",
    "\n",
    "- Half of the smallest non-zero parameter\n",
    "- Square of the first quartile divided by the third quartile (Statistische Datenanalyse Eine Einführung für Naturwissenschaftler)\n",
    "\n",
    "We suggest another approach specifically for Machine Learning. The goal is transforming the data in a way that makes it look as Like a standard Normal distribution. (which can be considered as a preconditioning step)\n",
    "\n",
    "We consider the problem:\n",
    "\n",
    "$$ α^*, β^*, γ^* =  \\operatorname*{arg\\,min}_{α>0, β, γ>0} D_{ᴋʟ}(ϕ(p^\\text{emp}), 𝓝(0,1))\n",
    "\\qquad ϕ(x) = α⋅\\log(x+γ)+β\n",
    "$$\n",
    "\n",
    "I.e. we combine the log transform with a simple linear/affine transform.\n",
    "\n",
    "Note that the parameter restrictions make $ϕ$ strictly monotonically increasing. In this case the transformed density is simply\n",
    "\n",
    "\n",
    "$$ p_Y = p_X(ϕ^{-1}(y)) \\frac{∂ϕ^{-1}(y)}{∂y} $$\n",
    "\n",
    "\n",
    "Note that the inverse is $ϕ^{-1}(y) = \\exp(\\frac{y-β}{α}) - γ$. It might be simpler to \n",
    "\n",
    "\n",
    "**Alternative:** Consider a linear-log-linear transform $x⟼σ⋅\\log(αx+β)+μ$ with $α>0, σ>0, β>0$.\n",
    "One may simply estimate $μ, σ$ from the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d18dbf-3b75-4085-9dcd-1c8272069947",
   "metadata": {},
   "source": [
    "The result of the transforming an empirical distribution is again an empirical distribution.\n",
    "\n",
    "Note that, given a empirical distribution $p^\\text{emp} = \\frac{1}{N}\\sum_{n=1}^{N}δ(x_n)$, the KL-divergence is\n",
    "\n",
    "$$ 𝐃_{ᴋʟ}(p^\\text{emp}, q) = 𝐇(p^\\text{emp}) + \\frac{1}{N}\\sum_{n=1}^{N}-\\log(q(x_n)) $$\n",
    "\n",
    "Note that the entropy term is infinite, hence minimizing the divergence restricts to the second term. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a1f404-c7c2-49cb-ae00-6446ec761834",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Comparing to Normal Distribution\n",
    "\n",
    "Given a Gaussian distribution $q=𝓝(μ,σ²)$, we have\n",
    "\n",
    "$$\n",
    "ℓ(μ, σ) = \\frac{1}{N}\\sum_{n=1}^{N}-\\log(q(x_n)) \n",
    "= \\frac{1}{N}\\sum_{n=1}^{N} \\frac{1}{2}\\Big(\\log(2πσ^2) + \\big(\\frac{x_n-μ}{σ}\\big)^2 \\Big)\n",
    "$$\n",
    "\n",
    "Which is of course just the negative log-likelihood of the Gaussian. The optimal choice for $μ$ and $σ$ are hence the estimated mean and standard deviation.\n",
    "\n",
    "$$\\begin{aligned}\n",
    "   0 &= \\frac|{∂ℓ}{∂μ} = \\frac{1}{N}\\sum_{n=1}^{N}\\frac{μ-x_n}{σ^2}\n",
    "& ⇝ μ &=  \\frac{1}{N}\\sum_{n=1}^{N}x_n\n",
    "\\\\ 0 &= \\frac{∂ℓ}{∂σ} = \\frac{1}{N}\\sum_{n=1}^{N}\\Big( \\frac{1}{σ} - \\frac{(x_n-μ)^2}{σ^3}\\Big)\n",
    "& ⇝ σ^2 &=  \\frac{1}{N}\\sum_{n=1}^{N}(x_n-μ)^2\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e90b9c-0d59-49f6-a3cb-541b4696ac0e",
   "metadata": {},
   "source": [
    "## Normal Distribution with built in transform to standard normal\n",
    "\n",
    "\n",
    "\n",
    "Given $Y = ψ(X)$, with $X∼𝓝(0,1)$ and $ψ(x)=σx+μ$, then $q(y) = p(ψ^{-1})\\frac{∂ψ^{-1}}{∂ψ} = \\frac{1}{\\sqrt{2πσ^2}}e^{-(\\frac{x-μ}{σ})^2}$\n",
    "\n",
    "$$ 𝐃_{ᴋʟ}(p_y^\\text{emp}, )) ∼ \\frac{1}{N}∑_{n=1}^{N} \\log(p()) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cb4a2c-7ae3-48e1-8311-3a646f7d645b",
   "metadata": {},
   "source": [
    "## Comparing to Uniform Distribution\n",
    "\n",
    "Given a Uniform distribution $q=𝓤(a,b)$, we have\n",
    "\n",
    "$$\n",
    "ℓ(a, b) = \\frac{1}{N}\\sum_{n=1}^{N}-\\log(q(x_n)) \n",
    "= \\frac{1}{N}\\sum_{n=1}^{N}\\log(b-a)\n",
    "$$\n",
    "\n",
    "The issue here is that it is independent of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d57e8bc-f1ef-463f-8d9c-f73c51cf0605",
   "metadata": {},
   "source": [
    "# Idea: Wasserstein distances!\n",
    "\n",
    "\n",
    "In 1d, we can make use of the fact that \n",
    "\n",
    "$$  W_{p}(\\mu _{1},\\mu _{2})=\\left(\\int _{0}^{1}\\left|F_{1}^{-1}(q)-F_{2}^{-1}(q)\\right|^{p}\\,\\mathrm {d} q\\right)^{1/p}\n",
    "\\qquad\\text{and}\\qquad  W_{1}(\\mu _{1},\\mu _{2})=\\int _{\\mathbb {R} }\\left|F_{1}(x)-F_{2}(x)\\right|\\,\\mathrm {d} x\n",
    "$$\n",
    "\n",
    "Given that $μ_1$ is an empirical distribution, i.e. $F_1 = \\frac{1}{N}∑_{n=1}^N H(x-x_n)$, with the Heaviside step function $H$, we have, using $x_0=-∞$ and $x_{N+1}=+∞$. \n",
    "\n",
    "WLOG assume $x_1 ≤ x_2 ≤ … ≤ x_n$. The quantile function is a step function as well and can be expressed as\n",
    "\n",
    "$$F_1^{-1}(q) = \\max\\{x_n ∣ x_n < q\\} = x_1 + ∑_{k≤Nq}(x_{k+1}-x_{k}) = x_1 + ∑_{k=1}^{N-1} (x_{k+1}-x_k) H(q-\\tfrac{k}{N}) = x_{\\max\\{n∣n<Nq\\}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1afceee-d72e-43af-ac3e-3eba0e66998b",
   "metadata": {},
   "source": [
    "Plugging this back into the equation we obtain\n",
    "\n",
    "$$\\begin{aligned}\n",
    "W_{p}(p^\\text{emp}, μ)^p \n",
    "&= \\int _{0}^{1} \\Big| x_1 +\\sum_{k=1}^{N-1} (x_{k+1}-x_k) H(q-\\tfrac{k}{N})   -F^{-1}(q) \\Big|^{p} dq\n",
    "\\\\ &=∑_{k=1}^N ∫_{\\tfrac{k-1}{N}}^{\\tfrac{k}{N}} \\Big| x_k  - F^{-1}(q) \\Big|^{p} dq\n",
    "\\end{aligned}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f5ed47-385c-44dd-bf17-b020cf551164",
   "metadata": {},
   "source": [
    "$$ {\\displaystyle W_{1}(\\mu _{1},\\mu _{2})=\\int _{\\mathbb {R} }\\left|F_{1}(x)-F_{2}(x)\\right|\\,\\mathrm {d} x}  = … = ∑_{n=0}^N ∫_{x_n}^{x_{n+1}} |\\tfrac{n}{N} - F(x) | dx $$\n",
    "\n",
    "\n",
    "\n",
    "$$ W_{p}(\\mu _{1},\\mu _{2})^p =\\int _{0}^{1}\\left|F_{1}^{-1}(q)-F_{2}^{-1}(q)\\right|^{p}\\,\\mathrm {d} q\n",
    "=  ∑_{k=1}^{N} ∫_{\\frac{k-1}{N}}^{\\frac{k}{N}} |x_k - F^{-1}(q)|^p 𝖽 q\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafe7163-e9bb-4891-9a6b-7434f0c5b69a",
   "metadata": {},
   "source": [
    "## Case p=2\n",
    "\n",
    "\n",
    "This case is special because it allows us to get rid of the absolute value:\n",
    "$$\\begin{aligned} W_{2}(\\mu _{1},\\mu _{2})^2 \n",
    "&=  ∑_{k=1}^{N} ∫_{\\frac{k-1}{N}}^{\\frac{k}{N}} |x_k - F^{-1}(q)|^2 𝖽 q\n",
    "\\\\ &=  ∑_{k=1}^{N} ∫_{\\frac{k-1}{N}}^{\\frac{k}{N}} x_k^2 - 2 x_k F^{-1}(q) + F^{-1}(q)^2 𝖽 q\n",
    "\\\\ &=  ∑_{k=1}^{N} \\Big[  \\frac{1}{N}x_k^2 - 2\\Big(∫_{\\frac{k-1}{N}}^{\\frac{k}{N}} F^{-1}(q) dq\\Big)x_k   + ∫_{\\frac{k-1}{N}}^{\\frac{k}{N}}F^{-1}(q)^2 𝖽 q \\Big]\n",
    "\\\\ &= \\frac{1}{N}∑_{k=1}^{N} \\Big[ x_k^2 - 2 N \\Big(∫_{\\frac{k-1}{N}}^{\\frac{k}{N}} F^{-1}(q) dq\\Big)x_k\\Big] + ∫_{0}^{1} F^{-1}(q)^2 𝖽 q\n",
    "\\\\ &=\\frac{1}{N}∑_{k=1}^{N} \\Big[ x_k^2 - 2N \\Big(∫_{\\frac{k-1}{N}}^{\\frac{k}{N}} F^{-1}(q) dq\\Big) x_k  + ∫_{0}^{1} F^{-1}(q)^2 𝖽 q \\Big]\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20e8f89-90e2-4230-b0b3-21c2cb9b5ad5",
   "metadata": {},
   "source": [
    "## Uniform distribution\n",
    "\n",
    "Consider the case when q is a uniform distribution. Then the CDF is $\\frac{x_{[a,b]}-a}{b-a}$. the quantile function is therefore $F^{-1}(q) = a+(b-a)q$. Thus:\n",
    "\n",
    "\n",
    "$$\\begin{aligned}\n",
    "∫_{x_{\\min}}^{x_{\\max}} F^{-1}(q) dq \n",
    "&= ∫_{x_{\\min}}^{x_{\\max}} (a+(b-a)q) dq \n",
    "= (a + (b-a)\\overline{x}){∆x}\n",
    "\\\\ ∫_{x_{\\min}}^{x_{\\max}} F^{-1}(q)^2 dq \n",
    "&= ∫_{x_{\\min}}^{x_{\\max}} (a+(b-a)q)^2 dq \n",
    "= \\tfrac{(a+(b-a)x_{\\max})^3 - (a+(b-a)x_{\\min})^3}{3{∆x}}\n",
    "\\\\ ∫_{0}^{1} F^{-1}(q)^2 dq \n",
    "&= (a^2 + ab + b^2)/3\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce7a000-50ef-4caf-ac44-991169c8d7c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa43cf3e-5ace-4c24-bece-d655ce543eec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "918ca669-c176-4ae8-92a8-41fef01738dc",
   "metadata": {},
   "source": [
    "Using this quantile function, we can write down the Wasserstein metric explicitly:\n",
    "\n",
    "$$\\begin{aligned} W_2(p^\\text{emp}, U(a,b))^2 \n",
    "&=\\frac{1}{N}∑_{k=1}^{N} \\Big[ x_k^2 - 2N \\Big(∫_{\\frac{k-1}{N}}^{\\frac{k}{N}} F^{-1}(q) dq\\Big) x_k  + ∫_{0}^{1} F^{-1}(q)^2 𝖽 q \\Big]\n",
    "\\\\ &= \\frac{1}{N}∑_{k=1}^N \\Big[ x_k^2\n",
    "- 2 N\\Big(  \\big(a + (b-a)\\tfrac{2k-1}{2N})\\big)\\tfrac{1}{N}  \\Big) x_k \n",
    "+ \\tfrac{1}{3}(a^2 + ab + b^2)\n",
    "\\Big]\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b90938-6726-422c-b65b-0d88696861df",
   "metadata": {},
   "source": [
    "In particular, if we choose the mean-0, variance-1 uniform distribution:\n",
    "\n",
    "$$\\begin{aligned} W_2(p^\\text{emp}, U(-√3,+√3))^2 \n",
    " &= \\frac{1}{N}∑_{k=1}^N \\Big[ x_k^2\n",
    "- 2 N\\Big(  \\big(a + (b-a)\\tfrac{2k-1}{2N})\\big)\\tfrac{1}{N}  \\Big) x_k \n",
    "+ \\tfrac{1}{3}(a^2 + ab + b^2)\n",
    "\\Big]\n",
    "\\\\ &= \\frac{1}{N}∑_{k=1}^N x_k^2\n",
    "+\\frac{2}{N}∑_{k=1}^N x_k (1 - \\tfrac{2k-1}{N})\\sqrt{3} + 1\n",
    "\\\\ &= \\frac{1}{N}∑_{k=1}^N \\Big[x_k^2 + 2\\sqrt{3}\\underbrace{(1 - \\tfrac{2k-1}{N})}_{∈(-1, +1)} x_k + 1   \\Big]\n",
    "%\\\\ &= \\frac{1}{N}∑_{k=1}^N \\Big[\\Big(x_k^2 - 2\\sqrt{3}x_k + 3 \\Big) + 2\\sqrt{3}(2 - \\tfrac{2k-1}{N})x_k \\Big]\n",
    "%\\\\ &= \\frac{1}{N}∑_{k=1}^N \\Big[\\underbrace{(x_k - \\sqrt{3})^2}_{≥0} + 2\\sqrt{3}(2 - \\tfrac{2k-1}{N})x_k\\Big]\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edca0c47-bf4e-45e1-a469-c49290af3fa3",
   "metadata": {},
   "source": [
    "**Problem: Need to prove non-negativity:** Each term is of the form $x^2 + 2\\sqrt{3}ax + 1$. This expression is guaranteed to be non-negative if and only if $\\sqrt{3}a∈[-1, +1]$, which is not guaranteed since $1 - \\tfrac{2k-1}{N}$ ranges from $1 - \\tfrac{2⋅1-1}{N} = 1 - \\tfrac{1}{N} <1$ for $k=1$ to  $1 - \\tfrac{2⋅N-1}{N} = -1 + \\tfrac{1}{N}>-1$ for $k=N$.\n",
    "\n",
    "\n",
    "**Solution:** This is actually easy. Notice that the function $f(x) = x^2 - 2ax + 1$ attains its minimum at $x=-a$, $f(x) = 1 - a^2$. Performing this inequality term-by-term and plugging the result back into the equation we have that \n",
    "\n",
    "\n",
    "$$\\begin{aligned} \n",
    "W_2(p^\\text{emp}, U(-√3,+√3))^2 \n",
    "   &≥ \\frac{1}{N}∑_{k=1}^N 1 - 3(1 - \\tfrac{2k-1}{N})^2\n",
    "\\\\ &= 1 - \\frac{3}{N} ∑_{k=1}^N  \\Big[1 -  \\frac{4k-2}{N} + \\frac{4k^2 - 4k + 1}{N^2}\\Big]\n",
    "\\\\ &= 1 - \\frac{3}{N} \\frac{N^2-1}{3N}\n",
    "\\\\ &= \\frac{1}{N^2}\n",
    "\\end{aligned}$$\n",
    "\n",
    "**Note that this inequality is sharp if indeed the $x_k$ are placed exactly at the locations.**\n",
    "\n",
    "**Problem 3: Can we prove (quasi-) convexity of the objective function?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcdc7fe-ce35-4ec0-b97f-a5e9a49946e9",
   "metadata": {},
   "source": [
    "## Gaussian Distribution\n",
    "\n",
    "$\\newcommand{\\erf}{\\operatorname{erf}}$\n",
    "\n",
    "given $p(x)=𝓝(x ∣ μ, Σ)$, hence $F(x) = \\tfrac{1}{2}(1+\\erf(\\frac{x-μ}{σ\\sqrt{2}}))$ and $F^{-1}(q)=μ+σ\\sqrt{2}\\erf^{-1}(2q-1)$\n",
    "\n",
    "$$\\begin{aligned}\n",
    "∫_{x_{\\min}}^{x_{\\max}} F^{-1}(q) dq \n",
    "&= ∫_{x_{\\min}}^{x_{\\max}} μ+σ\\sqrt{2}\\erf^{-1}(2q-1) dq \n",
    "= \\frac{1}{\\sqrt{2π}} \\Big( e^{-\\erf^{-1}(2a-1)^2} - e^{-\\erf^{-1}(2b-1)^2}   \\Big)\n",
    "\\\\ ∫_{x_{\\min}}^{x_{\\max}} F^{-1}(q)^2 dq \n",
    "&= ∫_{x_{\\min}}^{x_{\\max}} \\big(μ+σ\\sqrt{2}\\erf^{-1}(2q-1)\\big)^2 dq \n",
    "= (b-a) + \\frac{1}{\\sqrt{π}}\\Big( \\erf^{-1}(2a-1)e^{-\\erf^{-1}(2a-1)^2} - \\erf^{-1}(2b-1)e^{-\\erf^{-1}(2b-1)^2}   \\Big)\n",
    "\\\\ ∫_{0}^{1} F^{-1}(q)^2 dq \n",
    "&= μ^2 + σ^2\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652b618c-1f96-4f1d-aa7c-8632c61ff402",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy as sp\n",
    "\n",
    "n, k = sp.symbols(\"n k\")\n",
    "s = sp.summation((1 - (2 * k - 1) / n) ** 2, (k, 1, n))\n",
    "s.simplify()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fa9813-e1ec-448c-a363-03822ab921a5",
   "metadata": {},
   "source": [
    "## With duplicate Measurements\n",
    "\n",
    "Let $μ$ be an empirical distribution $\\frac{1}{N}∑_{n=1}^N δ(x-x_n)$. We assume that we have a **multi-set** $\\{x_k:μ_k∣k=1…m\\}$, i.e. $$\\frac{1}{N}∑_{n=1}^N δ(x-x_n) = ∑_k \\tfrac{μ_k}{∑_i μ_i} δ(x-x_k) = ∑_k α_k δ(x-x_k)$$\n",
    "\n",
    "In this case, the CDF is $F(x) = ∑_k α_k H(x-x_k)$ and the consequently, the quantile function is, assuming wlog $x_1 < x_2 < … < x_m$,\n",
    "\n",
    "$$ F^{-1}(q) = x_1 +  ∑_{k=1}^{m-1} (x_{k+1}-x_k) H(q - ∑_{l=1}^k α_l) = x_1 +  ∑_{k=1}^{m-1} {∆x_k} H(q - a_k)$$\n",
    "\n",
    "Plugging this back into the $W_2$ we get\n",
    "\n",
    "$$\\begin{aligned}\n",
    "W_2^2(p^\\text{emp}，p) \n",
    "   &= ∫_0^1 (G^{-1}(q) - F^{-1}(q))^2 dq\n",
    "\\\\ &= ∫_0^1 G^{-1}(q)^2 dq - 2∫_0^1 G^{-1}(q)F^{-1}(q) dq +  ∫_0^1 F^{-1}(q)^2 dq\n",
    "\\end{aligned}$$\n",
    "\n",
    "Consider the first term\n",
    "$$\\begin{aligned}\n",
    "∫_0^1 G^{-1}(q)^2 dq\n",
    " &= ∫_0^1 (x_1 +  ∑_{k=1}^{m-1} {∆x_k} H(q - a_k))^2 dq\n",
    "\\\\ &=\n",
    "∑_{l=1}^m ∫_{a_{l-1}}^{a_l}  (x_1 +  ∑_{k=1}^{m-1} {∆x_k} H(q - a_k))^2 dq\n",
    "\\\\ &= ∑_{l=1}^m ∫_{a_{l-1}}^{a_l}  x_l^2 dq\n",
    "\\\\ &= ∑_{l=1}^m α_l x_l^2 dq\n",
    "\\end{aligned}$$\n",
    "\n",
    "\n",
    "\n",
    "Consider the second term\n",
    "$$\\begin{aligned}\n",
    "∫_0^1 G^{-1}(q)F^{-1}(q) dq\n",
    " &= ∫_0^1 (x_1 +  ∑_{k=1}^{m-1} {∆x_k} H(q - a_k))F^{-1}(q) dq\n",
    "\\\\ &=\n",
    "∑_{l=1}^m ∫_{a_{l-1}}^{a_l}  (x_1 +  ∑_{k=1}^{m-1} {∆x_k} H(q - a_k))F^{-1}(q) dq\n",
    "\\\\ &= ∑_{l=1}^m ∫_{a_{l-1}}^{a_l}  x_l F^{-1}(q) dq\n",
    "\\\\ &= ∑_{l=1}^m \\Big(∫_{a_{l-1}}^{a_l}  F^{-1}(q) dq\\Big) x_l\n",
    "\\\\ &= ∑_{l=1}^m β_l x_l\n",
    "\\end{aligned}$$\n",
    "\n",
    "Consider the third term\n",
    "$$\\begin{aligned}\n",
    "∫_0^1 F^{-1}(q)^2 dq\n",
    "= ∑_{l=1}^m α_l ∫_0^1 F^{-1}(q)^2 dq\n",
    "= ∑_{l=1}^m α_l C\n",
    "\\end{aligned}$$\n",
    "\n",
    "Combining these results we obtain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd38d68-b3cb-4fe5-b716-48570816f5c4",
   "metadata": {},
   "source": [
    "$$W_2^2(p^\\text{emp}，p) = ∑_{l=1}^m \\Big[ α_l x_l^2  -2 β_l x_l + α_l C \\Big] \n",
    "\\qquad \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38551885-30fc-4de5-9cf4-06c8993b4095",
   "metadata": {},
   "source": [
    "$$W_2^2(p^\\text{emp}，p) = ∑_{l=1}^m \\Big[ α_l x_l^2  -2 β_l x_l + α_l C \\Big] \n",
    "\\qquad αₖ = \\frac{μ_k}{∑_{i}μ_i} \\qquad  β_k =  \\int_{a_{k-1}}^{a_k} F^{-1}(q)dq \\qquad C = \\int_0^1 F^{-1}(q)^2 dq \\qquad γ_k = α_k C\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee8a943-4eb0-4398-9aec-50d028705b68",
   "metadata": {},
   "source": [
    "## Case p: Uniform $[a,b]$\n",
    "\n",
    "In this case the quantile function is the very simple $F^{-1}(q) = a + (b-a)q$.\n",
    "\n",
    "Then:\n",
    "\n",
    "- $∫_{x_{\\min}}^{x_{\\max}} F^{-1}(q) dq = \\big(a + (b-a)\\frac{x_{\\max} + x_{\\min}}{2}\\big)(x_{\\max} - x_{\\min})$\n",
    "- Thus $β_l= \\big(a + (b-a)\\frac{a_{l} + a_{l-1}}{2}\\big) α_l$\n",
    "- $C = ∫_{0}^{q} F^{-1}(q)^2 dq = \\tfrac{1}{3}(a^2 + ab + b^2)$\n",
    "\n",
    "In particular, when $a=-\\sqrt{3}$ and $b=+\\sqrt{3}$:\n",
    "\n",
    "- $C = \\tfrac{1}{3}(3 -3 + 3) = 1$\n",
    "- $β_k = \\big(-\\sqrt{3} + (\\sqrt{3}-(-\\sqrt{3}))\\frac{a_{l} + a_{l-1}}{2}\\big) α_k = -α_k\\sqrt{3}(1- (a_{k} + a_{k-1}))$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190a8e14-bd19-4e29-85ef-8100c62eefbc",
   "metadata": {},
   "source": [
    "Plugging these back in:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "W_2^2(p^\\text{emp}，p) \n",
    "   &= ∑_{k=1}^m \\Big[ α_k x_k^2  -2 β_k x_k + α_k C \\Big]\n",
    "\\\\ &= ∑_{k=1}^m \\Big[ α_k x_k^2  +2 α_k\\sqrt{3}(1- (a_{k} + a_{k-1})) x_k + α_k  \\Big]\n",
    "\\\\ &= ∑_{k=1}^m α_k\\Big[  x_k^2  + 2 \\sqrt{3}\\underbrace{(1- (a_{k} + a_{k-1}))}_{∈(-1, +1)} x_k + 1 \\Big]\n",
    "\\\\ &= ∑_{k=1}^m α_k\\Big[  x_k^2  + 2 \\sqrt{3}γ_k x_k + 1 \\Big]\n",
    "\\end{aligned}$$\n",
    "\n",
    "Here, $x_1<…<x_m$ are arbitrary real values, $α_k$ are positive weights that sum to 1. $a_k = ∑_{j=1}^k α_j$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224fda16-3b98-432b-8d91-1f63a70f0bd6",
   "metadata": {},
   "source": [
    "$$ γ_k = 1-a_k - a_{k-1} = ∑_{j=1}^{n} ε_{jk}α_j$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0e61b6-43c5-4e48-87ae-95ebcc6f0230",
   "metadata": {},
   "source": [
    "Individually, each term becomes minimal if $x_k = -a = -√{3}γ_k$, in which case the minimum attained is $1-a^2 = 1-3γ_k^2$\n",
    "\n",
    "\n",
    "$$\\begin{aligned}\n",
    "W_2^2(p^\\text{emp}，p) \n",
    "   &= ∑_{k=1}^m α_k\\Big[  x_k^2  + 2 \\sqrt{3}γ_k x_k + 1 \\Big]\n",
    "\\\\ &≥ ∑_{k=1}^m α_k (1-3γ_k^2)\n",
    "\\\\ &= 1 - 3 ∑_{k=1}^m α_k γ_k^2\n",
    "\\\\ &= 1 - 3 ∑_{k=1}^m α_k \\big(1 - α_k - 2∑_{j=1}^{k-1}α_j\\big)^2\n",
    "\\\\ &= 1 - 3 ∑_{k=1}^m α_k \\big(∑_{j=k+1}^{n}α_j - ∑_{j=1}^{k-1}α_j\\big)^2\n",
    "\\\\ &= 1 - 3 ∑_{k=1}^m α_k \\big(∑_{j=1}^{n}ε_{jk}α_j\\big)^2 \n",
    "\\qquadε_{jk}=\\begin{cases}+1:&j<k\\\\\\hfill 0:&j=k\\\\-1:&j>k\\end{cases}\n",
    "\\\\ &= 1 - 3 ∑_{k=1}^m α_k ∑_{ij}ε_{ik}ε_{jk}α_iα_j\n",
    "\\\\ &= 1 - 3 ∑_{ijk}ε_{ik}ε_{jk} α_iα_j α_k \n",
    "\\\\ &= 1 - 3 ⟨E∣α^{⊗3}⟩\n",
    "\\qquad E_{ijk}=\\begin{cases}+1:& (i<k∧j<k) ∨ (i>k∧j>k) \\\\\\hfill 0:& i=k ∨ j=k & \\\\-1:& (i>k∧j<k)∨ (i<k∧j>k)\\end{cases}\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd6e452-1fab-4799-835f-46088c01c213",
   "metadata": {},
   "source": [
    "The very nice property of representing the sum this way is that now we have\n",
    "\n",
    "\n",
    "$$ \\frac{d}{dα_k} ∑_{k} α_k \\big(∑_{j=1}^{n}ε_{jk}α_j\\big)^2 = \\big(∑_{j=1}^{n}ε_{jk}α_j\\big)^2\n",
    "$$\n",
    "\n",
    "since $ε_{kk}=0$. Consequently, setting the gradient equal to zero we have\n",
    "\n",
    "$$ 0 \\overset{!}{=} \\big(∑_{j=1}^{n}ε_{jk}α_j\\big)^2 \n",
    "⟺ 0 = ∑_{j=1}^{n}ε_{jk}α_j \\quad\\text{for all k}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cdfda7-6b93-4bf1-8ea4-31848b2f41f8",
   "metadata": {},
   "source": [
    "This has $α=0$ as a solution which is not allowed. However, we can instead consider the Lagrangian of the constrained problem\n",
    "\n",
    "$$ \\max_α ∑_{k} α_k \\big(∑_{j=1}^{n}ε_{jk}α_j\\big)^2 \\qquad α≥0 \\qquad ∑ α_k = 1$$\n",
    "\n",
    "**IDEA: SHOW PERMUTATION INVERIANCE + (SCHUR-) CONVEXITY ⟹ OPTIMUM ON DIAGONAL**\n",
    "\n",
    "Then\n",
    "\n",
    "$$ 𝓛(α, λ, μ): -∇f(𝛂) + λ⋅𝟏 - 𝛍 = 𝟎 \\qquad 𝛍≥0$$\n",
    "\n",
    "In particular, by multiplying with $𝟏^⊤$ we obtain:\n",
    "\n",
    "$$λ = \\frac{1}{n}∑μ_i + \\frac{1}{n}1^⊤∇f(𝛂)$$\n",
    "\n",
    "Hence\n",
    "\n",
    "$$ ∇f(𝛂)- \\overline{∇f(𝛂)}𝟏 = \\boldsymbol{\\mu} - \\overline{\\boldsymbol{\\mu}}𝟏 $$\n",
    "\n",
    "$$ -\\Big(∑_{j=1}^{n}ε_{jk}α_j\\Big)^2 + λ- μ_k = 0 \\qquad\\text{for all k}$$\n",
    "\n",
    "Show: $α_k = \\frac{1}{n}$. In this case:$\\Big(∑_{j=1}^{n}ε_{jk}α_j\\Big)^2 = \\frac{((n-1)-2k)^2}{n^2} $ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49f53f9-6668-4e38-8cf4-7338979bb3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def E(n):\n",
    "    E = np.ones((n, n), dtype=int)\n",
    "    return np.triu(E) - np.triu(E).T\n",
    "\n",
    "\n",
    "E(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a491592a-f75c-4166-8d36-11d2ca1608ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.matrix_rank(E(9))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ea935a-9528-4ff0-8de8-3e53c5d8bd5a",
   "metadata": {},
   "source": [
    "The latter sum we can again maximize over $α∈Δ^{n-1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99eb42f2-b328-47bf-acdb-824cdbe8c987",
   "metadata": {},
   "source": [
    "## Combining with log-transform\n",
    "\n",
    "Assume we have $y = ψ(x) = \\log(x+c)$ with $c>0$ and are given $x∼p^\\text{emp}$ with $p^\\text{emp}(x) = \\tfrac{1}{N}∑δ(x-x_n)$\n",
    "\n",
    "Note that $x=ψ^{-1}(y) = e^{y} - c$ with $\\frac{∂ψ^{-1} }{∂y} = e^{y}$\n",
    "\n",
    "Then the transformed density has the distribution\n",
    "\n",
    "$$p(y) = p^\\text{emp}(e^{y}-c)|𝐃ψ^{-1}(y)| = e^y \\tfrac{1}{N}∑δ(ψ^{-1}(y)-x_n)$$\n",
    "\n",
    "Note that $ψ^{-1}(y)-x_n = 0$ if and only if $y = ψ(x_n) = y_n$. Note that $δ(g(x)) = ∑_{z: g(z)=0} \\frac{δ(x-z)}{|g'(z)|}$, hence, using $g(y) = ψ^{-1}(y)-x_n)$, which has a single root at $y_n=ψ(x_n)$, we have $δ(g(y)) = \\frac{δ(y-y_n)}{|g'(y_n)|} = e^{-y_n} δ(y-y_n)$\n",
    "\n",
    "Plugging this back into the equation we have:\n",
    "\n",
    "$$p(y) = p^\\text{emp}(e^{y}-c)|𝐃ψ^{-1}(y)| = \\tfrac{1}{N}∑ e^{y-y_n} δ(y-y_n)$$\n",
    "\n",
    "Note that since $δ(y-y_n) = 0$ if $y≠y_n$, this distribution is equivalent to\n",
    "\n",
    "$$p(y) = \\tfrac{1}{N}∑ e^{y_n-y_n} δ(y-y_n) = \\tfrac{1}{N}∑ δ(y-y_n)$$\n",
    "\n",
    "I.e. simply the empirical distribution of the $y_n$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87216fce-cca6-4fcc-bfd6-c0df322c1743",
   "metadata": {},
   "source": [
    "### Plugging into the Wasserstein formula\n",
    "\n",
    "Assuming $x_1<…<x_n$, then also $y_1<…<y_n$, with $y_k = \\log(x_n + c)$. Then\n",
    "\n",
    "$$\\begin{aligned} W_2(p^\\text{emp}, U(-√3,+√3))^2 \n",
    "&= ∑_{k=1}^m α_k\\Big[  \\log(x_k + c)^2  + 2 \\sqrt{3}γ_k \\log(x_k + c) + 3 \\Big]\n",
    "\\\\ &= ∑_{k=1}^m α_k\\Big[ y_k^2  + 2 \\sqrt{3}γ_k y_k + 3 \\Big]\n",
    "\\\\ ⟹ ∇ℓ(c) &= 2∑_{k=1}^m α_k\\frac{\\log(x_k + c)+\\sqrt{3}γ_k}{x_k+c}\n",
    "\\\\ &= 2∑_{k=1}^m α_k\\frac{y_k+\\sqrt{3}γ_k}{e^{y_k}}\n",
    "\\\\ ⟹ ∇²ℓ(c) &= 2∑_{k=1}^m α_k \\frac{1 -\\log(x_k + c)-\\sqrt{3}γ_k}{(x_k+c)^2}\n",
    "\\\\ &= 2∑_{k=1}^m α_k \\frac{1 -y_k-\\sqrt{3}γ_k}{e^{2y_k}}\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d458f5b-1312-49cf-bfe0-a85fa042df14",
   "metadata": {},
   "source": [
    "**Theorem:** If there exists a $ω≥0$ such that $𝐌(x, ω) ≔ ∇²ℓ(x) + ω∇ℓ(x)∇ℓ(x)^⊤$ is non-negative for all $x$, then $f(x)$ is pseudoconvex."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edac5bcf-03da-444e-8bee-247db515b80b",
   "metadata": {},
   "source": [
    "### Case n=1\n",
    "\n",
    "$$\\begin{aligned}\n",
    "𝐌(c, ω) &=  ∇²ℓ(c) + ω∇ℓ(c)∇ℓ(c)^⊤\n",
    "\\\\ &= 2\\frac{1 -\\log(x + c)-\\sqrt{3}γ}{(x+c)^2} + ω \\Big(2\\frac{\\log(x + c)+\\sqrt{3}γ}{x+c}\\Big)^2\n",
    "\\\\ ⟹ 0\\overset{!}{=} ∇_ω 𝐌(c, ω) &= 2\\Big(\\frac{\\log(x + c)+\\sqrt{3}γ}{x+c}\\Big)^2\n",
    "\\\\ ⟹ c &= e^{\\sqrt{3}γ} - x\n",
    "\\\\ ⟹ 𝐌(e^{\\sqrt{3}γ} - x, ω) &=  \\frac{2 -4 \\sqrt{3}γ}{e^{2\\sqrt{3}γ}} + ω \\frac{48γ^2}{e^{2\\sqrt{3}γ}   }\n",
    "\\\\ &=  2\\frac{1 -2 \\sqrt{3}γ + ω24γ^2}{e^{2\\sqrt{3}γ}}\n",
    "%\\\\ &= \\frac{1-\\sqrt{3}γ+3ωγ^2  + (2ω\\sqrt{3}γ -1 )\\log(x + c) + ω\\log(x + c)^2  }{\\frac{1}{2}(x+c)^2}\n",
    "%\\\\ &= \\frac{1-\\sqrt{3}γ + 3ωγ^2  + (2ω\\sqrt{3}γ -1 )\\log(x + c) + ω\\log(x + c)^2  }{\\frac{1}{2}(x+c)^2}\n",
    "\\end{aligned}$$\n",
    "\n",
    "Which is indeed guaranteed non-negative if $ω$ is sufficiently large.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ee7958-f719-4fb0-91d8-b4b0da3b0b51",
   "metadata": {},
   "source": [
    "### Case n\n",
    "\n",
    "$$\\begin{aligned}\n",
    "𝐌(c, ω) &=  ∇²ℓ(c) + ω∇ℓ(c)∇ℓ(c)^⊤\n",
    "\\\\ &=  ∑_{k=1}^m 2 α_k \\frac{1 -y_k-\\sqrt{3}γ_k}{e^{2y_k}} \n",
    "      + ω\\Big(∑_{k=1}^m 2 α_k\\frac{y_k+\\sqrt{3}γ_k}{e^{y_k}} \\Big)^2\n",
    "\\\\ &≥  ∑_{k=1}^m \\frac{2α_k}{e^{2y_k}}\\Big(1 -y_k-\\sqrt{3}γ_k + 2α_kω(y_k+\\sqrt{3}γ_k)^2\\Big)\n",
    "%\n",
    "\\\\ &≥  ∑_{k=1}^m \\frac{2α_k}{e^{2y_k}}\\Big[\n",
    "            \\underbrace{\\big(\\tfrac{1}{4} -\\sqrt{3}γ_k + 3γ_k^2\\big)}_{\\text{$≥0$}} \n",
    "            + \\underbrace{3(2αₖω-1)γ_k^2}_{\\text{$≥0$ if $ω≥\\tfrac{1}{2α_k}$}}\n",
    "          + \\big(\\tfrac{3}{4} - (1 - 4\\sqrt{3}γ_kα_k ω)y_k +  2α_kωy_k^2 \\big)\\Big]\n",
    "\\\\ &≥  ∑_{k=1}^m \\frac{2α_k}{e^{2y_k}}\\Big[\n",
    "            \\underbrace{\\big(\\tfrac{1}{2} -\\sqrt{3}γ_k\\big)^2}_{\\text{$≥0$}} \n",
    "            + \\underbrace{3(2αₖω-1)γ_k^2}_{\\text{$≥0$ if $ω≥\\tfrac{1}{2α_k}$}}\n",
    "            + \\underbrace{\\big(\\tfrac{1}{4} -y_k + y_k^2 \\big)}_{≥0}\n",
    "          + \\big(\\tfrac{1}{2} + 4\\sqrt{3}γ_kα_k ω y_k +  (2α_kω-1)y_k^2 \\big)\\Big]\n",
    "\\\\ &≥  ∑_{k=1}^m \\frac{2α_k}{e^{2y_k}}\\Big[\n",
    "    \\underbrace{\\big(\\tfrac{1}{2} -\\sqrt{3}γ_k\\big)^2}_{\\text{$≥0$}} \n",
    "    + \\underbrace{3(2αₖω-1)γ_k^2}_{\\text{$≥0$ if $ω≥\\tfrac{1}{2α_k}$}}\n",
    "    + \\underbrace{\\big(\\tfrac{1}{2} -y_k\\big)^2}_{≥0}\n",
    "    + \\underbrace{\\big(\\tfrac{1}{2} + 4\\sqrt{3}γ_kα_k ω y_k + 192γ_k^2α_k^2ω^2 y_k^2\\big)}_{≥0}\n",
    "    +  (2α_kω-1)y_k^2 - 192γ_k^2α_k^2ω^2 y_k^2 \\Big]\n",
    "\\\\ &≥  ∑_{k=1}^m \\frac{2α_k}{e^{2y_k}}\\Big[\n",
    "    \\underbrace{\\big(\\tfrac{1}{2} -\\sqrt{3}γ_k\\big)^2}_{\\text{$≥0$}} \n",
    "    + \\underbrace{\\big(\\tfrac{1}{2} -y_k\\big)^2}_{≥0}\n",
    "    + \\underbrace{\\big(\\tfrac{1}{4} + 8\\sqrt{3}γ_kα_k ω y_k\\big)^2}_{≥0}\n",
    "    + \\underbrace{3(2αₖω-1)γ_k^2}_{\\text{$≥0$ if $ω≥\\tfrac{1}{2α_k}$}}\n",
    "    +  (- 192γ_k^2α_k^2ω^2 + 2α_kω-1)y_k^2 \\Big]\n",
    "%\\\\ ⟹  0\\overset{!}{=} ∇_ω 𝐌(c, ω) &= ∑_{k=1}^m \\frac{2 α_k (\\log(x_k + c)+\\sqrt{3}γ_k)^2}{(x_k + c)^2}\n",
    "%\\\\ &=   ∑_{k=1}^m α_k \\frac{1}{(x_k+c)^2}\n",
    "%       - ∑_{k=1}^m α_k \\frac{\\log(x_k + c)+\\sqrt{3}γ_k}{(x_k+c)^2} \n",
    "%       + 2ω\\Big(∑_{k=1}^m α_k\\frac{\\log(x_k + c)+\\sqrt{3}γ_k}{x_k+c} \\Big)^2\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3defb7f-d96b-403a-8198-63aeeeec2f6c",
   "metadata": {},
   "source": [
    "Solve the min-max problem\n",
    "\n",
    "$$ \\max_{ω}\\min_{y_k} L(ω, y_k) ≔ 1-(1-4\\sqrt{3}α_kγ_kω)y_k + 2α_kωy_k^2 $$\n",
    "\n",
    "\n",
    "The minimum is obtained when\n",
    "\n",
    "$$\\begin{aligned}\n",
    "0 = ∇_{y_k}L(ω, y_k) = -(1-4\\sqrt{3}α_kγ_kω) + 4α_k ω y_k \n",
    "⟺ y_k = \\frac{1-4\\sqrt{3}α_kγ_kω}{4α_k ω}\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9addc0db-7a3b-41be-88b2-3fb9d08aefb2",
   "metadata": {},
   "source": [
    "Hence\n",
    "\n",
    "$$\\begin{aligned}\n",
    "L(ω, y_k^*) &= 1 - (1-4\\sqrt{3}α_kγ_kω)\\frac{1-4\\sqrt{3}α_kγ_kω}{4α_k ω} + 2α_kω\\Big(\\frac{1-4\\sqrt{3}α_kγ_kω}{4α_k ω}\\Big)^2\n",
    "\\\\ &= 1 - \\frac{(1-4\\sqrt{3}α_kγ_kω)^2}{4α_k ω} +\\frac{1}{2}\\frac{(1-4\\sqrt{3}α_kγ_kω)^2}{4α_k ω}\n",
    "\\\\ &= 1 - \\frac{(1-4\\sqrt{3}α_kγ_kω)^2}{8α_k ω}\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6363e8e9-d2da-4e38-b700-29a6ae89d008",
   "metadata": {},
   "source": [
    "#### Maximization step\n",
    "\n",
    "We need $L(ω, y_k^*) ≥0$, which is equivalently:\n",
    "\n",
    "\n",
    "$$\\begin{aligned}\n",
    "1 - \\frac{(1-4\\sqrt{3}α_kγ_kω)^2}{8α_k ω} &≥ 0 \n",
    "\\\\ ⟺ 8α_k ω - (1-4\\sqrt{3}α_kγ_kω)^2 &≥ 0\n",
    "\\\\ ⟺ 48α_k^2γ_k^2ω^2 - 8α_k(1-\\sqrt{3}γ_k)ω + 1 &≤ 0 \n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06219901-e7ed-4dd1-81cc-3fad0e7ef9be",
   "metadata": {},
   "source": [
    "#### Maximization step\n",
    "\n",
    "$$ 0 = ∇_ω L(ω, y_k^*) = \\frac{1-48α_k^2γ_k^2ω^2}{8α_kω^2}\n",
    "⟺ ω = ±\\frac{1}{4\\sqrt{3}α_k |γ_k|}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832e33b2-fb0f-4994-8ed2-079ef5bfb818",
   "metadata": {},
   "source": [
    "Optimal value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f09cbe-056e-49a0-9597-2c040aad024c",
   "metadata": {},
   "source": [
    "The last term is negative for too large $ω$. Its maximum is attained when\n",
    "\n",
    "$$ 0\\overset{!}{=} ∇_ω- 192γ_k^2α_k^2ω^2 + 2α_kω-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4eebef-77e3-4449-bec0-2fdbfeafab68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f8360d8-361a-4c64-a67c-e9b826db0cfd",
   "metadata": {},
   "source": [
    "We need to show that there exists a $ω≥0$ such that $𝐌(c, ω)≥0$ for all $c$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43b9b5f-b807-4758-9d13-be905f8ddcd5",
   "metadata": {},
   "source": [
    "Note that, for each term:\n",
    "\n",
    "$$\n",
    "2\\frac{\\log(x_k + c)}{x+c}  + 2 \\frac{\\sqrt{3}γ_k}{x_k + c} \n",
    "= 0 ⟺ \\log(x_k + c) = \\sqrt{3}γ_k\n",
    "$$\n",
    "\n",
    "For a single term, the derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06441ee4-0552-4dcf-b219-7a63e9cdcb1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ce6b68a-6581-4fcf-b76d-ab665ab45651",
   "metadata": {},
   "source": [
    "# Numerical Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cb1dcd-1bfa-4790-a7b8-eb4917b7213c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InteractiveShell.ast_node_interactivity='last_expr_or_assign'  # always print last expr.\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf0412f-a4a3-40a3-bd25-de7a4a9393f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from jax.config import config\n",
    "\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "config.update(\"jax_platform_name\", \"cpu\")\n",
    "import jax.numpy as np\n",
    "from jax import grad, jacfwd, vmap\n",
    "from numpy import pi as π"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0f30f5-ffe3-48c4-b65b-3895f3f58030",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsdm.datasets import KIWI_RUNS\n",
    "\n",
    "dataset = KIWI_RUNS()\n",
    "\n",
    "ts = dataset.timeseries\n",
    "\n",
    "data = np.array(ts.Glucose[pd.notna(ts.Glucose)].astype(float))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089ba673-e501-4792-b7d5-37cfaa800ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wasserstein_uniform(x):\n",
    "    N = len(x)\n",
    "    n = np.arange(1, N + 1)\n",
    "    r = x**2 + 2 * np.sqrt(3) * (1 - (2 * n - 1) / N) * x + 3\n",
    "    return np.mean(r)\n",
    "\n",
    "\n",
    "def loss(p):\n",
    "    return -np.mean(np.log(p))\n",
    "\n",
    "\n",
    "def pdf_gaussian(x, μ=0.0, σ=1.0):\n",
    "    return np.exp(-(((x - μ) / σ) ** 2) / 2) / np.sqrt(2 * π * σ**2)\n",
    "\n",
    "\n",
    "def pdf_uniform(x, a=-np.sqrt(3), b=+np.sqrt(3)):\n",
    "    m = (x >= a) & (x <= b)\n",
    "    return np.where(m, 1 / (b - a), 0)\n",
    "\n",
    "\n",
    "def h_uniform(lb=-np.sqrt(3), ub=+np.sqrt(3)):\n",
    "    return np.log(ub - lb)\n",
    "\n",
    "\n",
    "def h_gaussian(μ=0.0, σ=1.0):\n",
    "    return 0.5 + np.log(2 * π * σ**2) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48ce261-2561-44c5-a4fa-639b5da054f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x, θ):\n",
    "    x = np.sort(x)\n",
    "    a, b = θ\n",
    "    y = np.log(a * x + b)\n",
    "    # return y\n",
    "    μ = np.mean(y)\n",
    "    σ = np.std(y)\n",
    "    return (y - μ) / σ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0c9479-8708-459b-9e54-352d2dfe701e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from scipy.optimize import LinearConstraint, minimize\n",
    "\n",
    "constr = LinearConstraint(np.eye(2), 0, ub=np.inf)\n",
    "\n",
    "\n",
    "def f(θ):\n",
    "    return wasserstein_uniform(model(data, θ))\n",
    "\n",
    "\n",
    "x0 = np.array([1.0, 1.0])\n",
    "sol = minimize(\n",
    "    f, x0, method=\"Nelder-Mead\", jac=grad(f), bounds=[(0, np.inf), (0, np.inf)]\n",
    ")\n",
    "sol.x, sol.fun, sol.success, sol.status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6a389a-15ca-4f80-a4f5-6e50a602edbb",
   "metadata": {},
   "source": [
    "## Plot the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a459c0a-20c6-4125-bfa7-310094bc64bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = np.linspace(0, 10, 1024)\n",
    "# b = np.linspace(0, 10, 1024)\n",
    "a = np.logspace(-6, 2, 512)\n",
    "b = np.logspace(-6, 2, 512)\n",
    "A, B = np.meshgrid(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294f8ee7-0a1d-4eea-8575-7223d2842f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = np.stack([A, B], axis=-1)\n",
    "Z = vmap(vmap(f))(C)  # this can take a bit of time\n",
    "np.nanmin(Z), np.nanmax(Z), np.isnan(Z).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0573bc-0d49-4bd9-a164-c6fc1e1fe68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "zmin = np.nanmin(Z)\n",
    "zmax = np.nanmax(Z)\n",
    "C = -np.log((Z - zmin) / (zmax - zmin))\n",
    "vmin = 0\n",
    "vmax = C[np.isfinite(C)].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9172a132-f7ed-4a78-8858-108c4667ea5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "im = ax.contourf(\n",
    "    A, B, C, vmin=vmin, vmax=vmax, levels=100, antialiased=True, cmap=\"plasma\"\n",
    ")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_aspect(\"equal\", \"box\")\n",
    "ax.set_xlabel(\"a\")\n",
    "ax.set_ylabel(\"b\")\n",
    "fig.colorbar(im)\n",
    "fig.savefig(\"solution.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f7a501-1190-4974-aed6-20551739fe99",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We can clearly see a straight line in the log-log plot, notifying the existence of a power law:\n",
    "\n",
    "$$ \\log(b) = m⋅\\log(a) + c ⟺  b = c⋅a^m $$\n",
    "\n",
    "This signifies redundancy in our parametrization:\n",
    "\n",
    "$$  \\log(a x + b)  = \\log(ax + ca^m) = \\log(a(x+ca^{m-1})) = \\log(a) + \\log(x+ca^{m-1})$$\n",
    "\n",
    "In essence, it will be enough to do either $\\log(x+c)$ or $\\log(1+αx)$. Note that both approaches are equivalent since\n",
    "\n",
    "$$\\log(x+c) = \\log(c(1+\\tfrac{1}{c}x)) = \\log(c) + \\log(1+\\tfrac{1}{c}x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb23c37-cd79-4863-8062-ed511d0159c6",
   "metadata": {},
   "source": [
    "# 1D apporach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a31bc4-69c0-40c2-a4ae-ecf999f66432",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_a(x, θ):\n",
    "    x = np.sort(x)\n",
    "    y = np.log(1 + θ * x)\n",
    "    μ = np.mean(y)\n",
    "    σ = np.std(y)\n",
    "    return (y - μ) / σ\n",
    "\n",
    "\n",
    "def model_c(x, θ):\n",
    "    x = np.sort(x)\n",
    "    y = np.log(x + θ)\n",
    "    μ = np.mean(y)\n",
    "    σ = np.std(y)\n",
    "    return (y - μ) / σ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6f756a-27b1-4a70-a1aa-843980f5abeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# from jax.scipy.optimize import minimize\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "def f(θ):\n",
    "    return wasserstein_uniform(model_c(data, θ))\n",
    "\n",
    "\n",
    "jac = grad(f)\n",
    "hess = jacfwd(jac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b71fec4-efbd-458f-8061-bbfe18c90bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hess(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4957f53-fec1-49ae-82c9-0061cf52532c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x0 = np.array([1.0])\n",
    "sol = minimize(\n",
    "    f,\n",
    "    x0,\n",
    "    method=\"trust-constr\",\n",
    "    jac=jac,\n",
    "    hess=hess,\n",
    "    bounds=[(0, np.inf)],\n",
    "    options={\"disp\": True},\n",
    ")\n",
    "sol.x, sol.fun, sol.success, sol.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf622818-c710-4377-a6a6-0dd9f86c3857",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.logspace(-6, 6, 1024)\n",
    "z = vmap(f)(t)\n",
    "plt.loglog(t, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0a9db5-f053-4fd5-8f07-9083dd2defa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = [\n",
    "    data[data > 0].min() / 2,\n",
    "    np.quantile(data, 0.25) ** 2 / np.quantile(data, 0.75),\n",
    "    np.quantile(data, 0.25) ** 2 / np.quantile(data, 0.75) ** 2,\n",
    "    sol.x,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e768967-273b-4508-8530-e9efd247fb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from scipy.stats import uniform\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    ncols=len(values),\n",
    "    constrained_layout=True,\n",
    "    figsize=(3 * len(values), 3),\n",
    "    sharey=True,\n",
    "    sharex=True,\n",
    ")\n",
    "\n",
    "t = np.linspace(-3, +3, 1024)\n",
    "for val, ax in zip(values, axes):\n",
    "    ax.hist(model_c(data, val), density=True, bins=20)\n",
    "    ax.plot(t, uniform.pdf(t, loc=-np.sqrt(3), scale=2 * np.sqrt(3)))\n",
    "    ax.set_yscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66689931-fe38-429a-96e5-b2288838b805",
   "metadata": {},
   "source": [
    "# Observation\n",
    "\n",
    "- distribution skewed if not normalized\n",
    "- values at center are positive, values at outside negative as expected\n",
    "- idea: combine pairs x[1] and x[1/2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3570188-8d73-4d5a-82c6-9b27dd1dfa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "y = np.log(np.sort(data) + 0.071)\n",
    "y = (y - y.mean()) / y.std()\n",
    "N = len(y)\n",
    "n = np.arange(1, N + 1)\n",
    "r = y**2 + 2 * np.sqrt(3) * (1 - (2 * n - 1) / N) * y + 1\n",
    "plt.plot(n, r), np.mean(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284bd11c-e220-46cc-b525-12dfbb977944",
   "metadata": {},
   "outputs": [],
   "source": [
    "um = np.arange(N) >= N // 2\n",
    "lm = np.arange(N) < N // 2\n",
    "\n",
    "uy = r.copy()\n",
    "uy = uy.at[um].set(0)\n",
    "uy = uy.at[lm].set(y[lm][::-1])\n",
    "ly = r.copy()\n",
    "ly = ly.at[lm].set(0)\n",
    "ly = ly.at[um].set(y[um][::-1])\n",
    "\n",
    "\n",
    "plt.plot(n, uy + ly)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
